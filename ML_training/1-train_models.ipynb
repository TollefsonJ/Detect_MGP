{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvtVyNKKiXL0"
   },
   "source": [
    "# First, set up the training images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdAOVtxXiXL5"
   },
   "source": [
    "## Import data\n",
    "Replace `<path_to_data>` with the path to where you placed the NPY training files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = <path_to_data>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HbPt5qCSiXL_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "X = np.load(path+'X.npy')\n",
    "y = np.load(path+'y.npy')\n",
    "file = np.load(path+'file.npy')\n",
    "\n",
    "# set numpy seed for model\n",
    "np.random.seed(0) # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6gHXmgA73DN"
   },
   "outputs": [],
   "source": [
    "# convert to grayscale\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "X = rgb2gray(X)\n",
    "# Reshape to match CNN model requirements\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmQnZWLfiXNu"
   },
   "source": [
    "# Define CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCt0sV5UiXNw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIE7FnXLiXN4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Convolutional Neural Network\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, AveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "input_shape = (X.shape[1], X.shape[2], X.shape[3])\n",
    "\n",
    "nClasses = 2\n",
    "\n",
    "def createModel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(nClasses, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fD3_SHtGrxIZ",
    "outputId": "cd0fb941-8827-44b3-8580-f6be283b6eee"
   },
   "outputs": [],
   "source": [
    "######### train test split ###############\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "# set up k-fold cross-val\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X, y)\n",
    "for in1, in2 in skf.split(X, y):\n",
    "  print(len(in1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RRBw8y2UN0x"
   },
   "source": [
    "# Define MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUVGJ2TxUPpU"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# define and fit scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "\n",
    "################## define and run model itself, after you've found good params ########\n",
    "mlp = MLPClassifier(hidden_layer_sizes= (100, 50),\n",
    "                    activation = 'relu',\n",
    "                    solver = 'lbfgs',\n",
    "                    alpha = 1e-5,\n",
    "                    learning_rate = 'constant',\n",
    "                    random_state = 0, max_iter=5000)\n",
    "\n",
    "pipe = Pipeline(steps =[('scaler',scaler) , ('MLPClassifier', mlp)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cmOQL2F5qDG"
   },
   "source": [
    "# Split train/test and train CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZ8OZyWU5qDI",
    "outputId": "74a7cf48-5b12-4f1e-b0f1-95ade5242f7b"
   },
   "outputs": [],
   "source": [
    "######### train test split ###############\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# set up k-fold cross-val\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "######################\n",
    "# Set training process params, class weights (get class weights from the train/test split, below)\n",
    "batch_size = 64\n",
    "epochs = 80\n",
    "\n",
    "number_models= 5\n",
    "\n",
    "###################\n",
    "# construct metrics\n",
    "metrics = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "###################\n",
    "\n",
    "\n",
    "# full list of models and histories\n",
    "models=list()\n",
    "histories=list()\n",
    "histories_all = list()\n",
    "\n",
    "# outcomes divided by fold\n",
    "y_test_byfold = list()\n",
    "y_train_byfold = list()\n",
    "X_test_byfold = list()\n",
    "X_train_byfold = list()\n",
    "file_test_byfold = list()\n",
    "file_train_byfold = list()\n",
    "file_val_byfold = list()\n",
    "\n",
    "# lists for CNN models\n",
    "histories_byfold = list()\n",
    "models_byfold = list()\n",
    "\n",
    "# list for MLP models\n",
    "pipes_byfold = list()\n",
    "#####################\n",
    "# construct \"fold\" counter to save data\n",
    "fold = 0\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(fold)\n",
    "\n",
    "    # reset model and history counter\n",
    "    models = list()\n",
    "    histories = list()\n",
    "\n",
    "    # split data\n",
    "    X1, X_test = X[train_index], X[test_index]\n",
    "    y1, y_test = y[train_index], y[test_index]\n",
    "    file1, file_test = file[train_index], file[test_index]\n",
    "\n",
    "    # construct validation set\n",
    "    X_train, X_val, y_train, y_val, file_train, file_val = train_test_split(X1, y1, file1, stratify = y1, test_size=0.15, random_state=0)\n",
    "    \n",
    "    # append all data to lists, to save for later\n",
    "    y_train_byfold.append(y_train)\n",
    "    y_test_byfold.append(y_test)\n",
    "\n",
    "    X_test_byfold.append(X_test)\n",
    "    X_train_byfold.append(X_train)\n",
    "\n",
    "    file_test_byfold.append(file_test)\n",
    "    file_train_byfold.append(file_train)\n",
    "    file_val_byfold.append(file_val)\n",
    "\n",
    "\n",
    "##################### ##################### ##################### \n",
    "    # CNN MODEL\n",
    "##################### ##################### ##################### \n",
    "\n",
    "    # compute class weights an assign to variable for model below\n",
    "    class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train),y_train)\n",
    "    weight = {0: class_weights[0], 1: class_weights[1]}\n",
    "    print(weight)\n",
    "\n",
    "    # scale Xs and convert Ys to categorical\n",
    "    X_train, X_val, X_test = X_train/255, X_val/255, X_test/255\n",
    "    y_train, y_val, y_test = to_categorical(y_train), to_categorical(y_val), to_categorical(y_test)\n",
    "\n",
    "\n",
    "\n",
    "    # run ensemble CNN model for each kfold\n",
    "    for i in range(0,number_models):\n",
    "      print(i)\n",
    "      model = createModel()\n",
    "      model.compile(optimizer='adamax', loss=keras.losses.BinaryCrossentropy(), metrics=metrics)\n",
    "      history = model.fit(X_train, y_train,\n",
    "                          batch_size=batch_size, \n",
    "                          epochs=epochs, verbose=1, class_weight = weight,\n",
    "                          validation_data = (X_val, y_val),\n",
    "                          # callbacks=[early_stopping], # this stops the training when the metric listed in model.compile has stopped improving\n",
    "                          shuffle=False)\n",
    "      \n",
    "      # append to revolving models and histories list, in order to later append to full list of models and history\n",
    "      models.append(model)\n",
    "      histories.append(history.history)\n",
    "      # append all histories for each model in each fold, to plot later\n",
    "      histories_all.append(history.history)\n",
    "\n",
    "    histories_byfold.append(histories)\n",
    "    models_byfold.append(models)\n",
    "\n",
    "    # iterate \"fold\" counter plus one\n",
    "    \n",
    "    fold = fold + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-4zjuDp2rhu",
    "outputId": "20ad8792-733c-49a6-d18f-c5545ae08c1d"
   },
   "outputs": [],
   "source": [
    "# save testing data, histories, and models\n",
    "\n",
    "import pickle\n",
    "for fold in range(0,5):\n",
    "  for model in range(0,5):\n",
    "    path = 'saved_models/ensemblemodel_' + str(fold) + '-' + str(model)\n",
    "    models_byfold[fold][model].save(path)\n",
    "\n",
    "  path = \"saved_models/X_test_\" + str(fold) + \".dat\"\n",
    "  with open(path, \"wb\") as f:\n",
    "    pickle.dump(X_test_byfold[fold], f)\n",
    "  \n",
    "  path = \"saved_models/Y_test_\" + str(fold) + \".dat\"\n",
    "  with open(path, \"wb\") as f:\n",
    "    pickle.dump(y_test_byfold[fold], f)\n",
    "\n",
    "with open(\"saved_models/ensemblemodel_histories_byfold.dat\", \"wb\") as f:\n",
    "  pickle.dump(histories_byfold, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0n51vNWWLA0"
   },
   "outputs": [],
   "source": [
    "# save the models\n",
    "import pickle as pkl\n",
    "\n",
    "path  = '/Users/jtollefs/Documents/SOCIOLOGY/github/MGP_circle_detection/ML_training/saved_models/'\n",
    "file = path+'mlp_models_byfold.pkl'\n",
    "with open(file, 'wb') as f:\n",
    "    pkl.dump(pipes_byfold, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################################\n",
    "###### Train MLP model ######\n",
    "####################################\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# define and fit scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "\n",
    "################## define and run model itself, after you've found good params ########\n",
    "mlp = MLPClassifier(hidden_layer_sizes= (100, 50),\n",
    "                    activation = 'relu',\n",
    "                    solver = 'lbfgs',\n",
    "                    alpha = 1e-5,\n",
    "                    learning_rate = 'constant',\n",
    "                    random_state = 0, max_iter=5000)\n",
    "\n",
    "pipe = Pipeline(steps =[('scaler',scaler) , ('MLPClassifier', mlp)])\n",
    "\n",
    "\n",
    "# split train/test\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "# reshape X array to 2-dimensions\n",
    "nsamples, nx, ny = X.shape\n",
    "X = X.reshape((nsamples, nx*ny))\n",
    "\n",
    "\n",
    "fold = 0\n",
    "pipes = list()\n",
    "pipes_byfold = list()\n",
    "y_true_byfold = list()\n",
    "X_test_byfold = list()\n",
    "\n",
    "\n",
    "# run K-fold loop\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    file_train, file_test = file[train_index], file[test_index]\n",
    "    \n",
    "    # resample training data\n",
    "    over = SMOTE(sampling_strategy = .1)\n",
    "    under = RandomUnderSampler(sampling_strategy=1)\n",
    "    X_train, y_train = over.fit_resample(X_train, y_train)\n",
    "    X_train, y_train = under.fit_resample(X_train, y_train)\n",
    "    \n",
    "    from collections import Counter\n",
    "    print(\"Y train array: \")\n",
    "    print(sorted(Counter(y_train).items()))\n",
    "\n",
    "    print(\"Y test array: \")\n",
    "    print(sorted(Counter(y_test).items()))\n",
    "    # run it\n",
    "    \n",
    "    for i in range(0,5):\n",
    "        \n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        pipes.append(pipe)\n",
    "    \n",
    "    pipes_byfold.append(pipes)\n",
    "    y_true_byfold.append(y_test)\n",
    "    X_test_byfold.append(X_test)\n",
    "\n",
    "    fold = fold + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the MLP models\n",
    "import pickle as pkl\n",
    "\n",
    "file = 'saved_models/MLP/mlp_models_byfold.pkl'\n",
    "with open(file, 'wb') as f:\n",
    "    pkl.dump(pipes_byfold, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5RRBw8y2UN0x",
    "zqf7m78Gs0EQ",
    "mekxD7tfHmQr",
    "bPUYPMWrJ4CT",
    "8fuZXJA6KACm"
   ],
   "name": "k-fold_cnn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
