{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXNv-yfdZk2N"
   },
   "source": [
    "# Import models\n",
    "Download models and place in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path\n",
    "path = <path_to_data>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7vY0XUvYxks"
   },
   "outputs": [],
   "source": [
    "# import CNN models\n",
    "import tensorflow as tf\n",
    "models_byfold = list()\n",
    "for fold in range(0,5):\n",
    "    models = list()\n",
    "    for model in range(0,5):\n",
    "        path = path + '/saved_models/ensemblemodel_' + str(fold) + '-' + str(model)\n",
    "        model = tf.keras.models.load_model(path)\n",
    "        models.append(model)\n",
    "    models_byfold.append(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uT3lajwjadEH",
    "outputId": "368e8772-a1ad-4961-924f-58db8db077a0"
   },
   "outputs": [],
   "source": [
    "# import MLP models\n",
    "import pickle as pkl\n",
    "file = open(path+'MLP/mlp_models_byfold.pkl', 'rb')\n",
    "pipes_byfold = pkl.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgigZ4zZZ3kG"
   },
   "source": [
    "# Import testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrgoiKAUZ43P"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "# import train and test data\n",
    "path = '/content/drive/MyDrive/COLAB/saved_models/'\n",
    "\n",
    "file_test = np.load(path + 'file_test_byfold.npy', allow_pickle=True)\n",
    "\n",
    "X_test_cnn = list()\n",
    "X_test_mlp = list()\n",
    "y_true_mlp = list()\n",
    "y_true_cnn = list()\n",
    "\n",
    "for i in range(0,5):\n",
    "    Xtestcnn = np.load(path+'X_test_' + str(i) + '.dat', allow_pickle=True)\n",
    "    nsamples, nx, ny, nz = Xtestcnn.shape\n",
    "    Xtestmlp = Xtestcnn.reshape((nsamples, nx*ny*nz))*255\n",
    "\n",
    "    ytruemlp = np.load(path+'Y_true_' + str(i) + '.dat', allow_pickle=True)\n",
    "    ytruecnn = to_categorical(ytruemlp)\n",
    "\n",
    "    file = np.load(path+'Y_true_' + str(i) + '.dat', allow_pickle=True)\n",
    "    \n",
    "    X_test_cnn.append(Xtestcnn)\n",
    "    X_test_mlp.append(Xtestmlp)\n",
    "\n",
    "    y_true_mlp.append(ytruemlp)\n",
    "    y_true_cnn.append(ytruecnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgSlP8muaWPW"
   },
   "source": [
    "# Evaluate and get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jO0tAHf1cALS",
    "outputId": "62068158-c787-40ce-921f-f1fa41f36157"
   },
   "outputs": [],
   "source": [
    "threshold_cnn = 0.2\n",
    "threshold_mlp = 0.9\n",
    "y_preds_cnn = list()\n",
    "y_preds_mlp = list()\n",
    "\n",
    "for fold in range(0,5):\n",
    "\n",
    "    print(fold)\n",
    "\n",
    "    y_p_mlp = [pipe.predict_proba(X_test_mlp[fold])[:,1] for pipe in pipes_byfold[fold]]\n",
    "    y_p_mlp = np.array(y_p_mlp)\n",
    " \n",
    "    y_p_cnn = [model.predict(X_test_cnn[fold])[:,1] for model in models_byfold[fold]]\n",
    "    y_p_cnn = np.array(y_p_cnn)\n",
    "\n",
    "    y_preds_cnn.append(y_p_cnn)\n",
    "    y_preds_mlp.append(y_p_mlp) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3k09zelaqYY8"
   },
   "outputs": [],
   "source": [
    "# combine CNN and MLP predictions, scaled according to optimal threshold (calculated from ROC curves)\n",
    "y_preds_all=list()\n",
    "y_preds_mlp_mean = list()\n",
    "y_preds_cnn_mean = list()\n",
    "\n",
    "MLPthresh = 0.9\n",
    "CNNthresh = 0.2\n",
    "\n",
    "for fold in range(0,5):\n",
    "    outs_cnn = np.mean(y_preds_cnn[fold], axis=0)\n",
    "    outs_mlp = np.mean(y_preds_mlp[fold], axis=0)\n",
    "    \n",
    "    ypa = (outs_cnn*MLPthresh/CNNthresh + outs_mlp*CNNthresh/MLPthresh)\n",
    "\n",
    "    y_preds_all.append(ypa)\n",
    "    y_preds_mlp_mean.append(outs_mlp)\n",
    "    y_preds_cnn_mean.append(outs_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrn0gfpJeLC-",
    "outputId": "5ab22a22-2907-49b1-fa9b-62e816aa1fbc"
   },
   "outputs": [],
   "source": [
    "cm_mean = []\n",
    "\n",
    "# get threshold from calculations below\n",
    "threshold = 1.2\n",
    "\n",
    "for fold in range(0,5):\n",
    "\n",
    "   # cm_mlp = tf.math.confusion_matrix(labels=y_true_mlp[fold], predictions=y_preds_mlp[fold]).numpy()\n",
    "    #cm_cnn = tf.math.confusion_matrix(labels=y_true_mlp[fold], predictions=y_preds_cnn[fold]).numpy()\n",
    "    y_preds_int = (y_preds_all[fold] > threshold).astype('int32')\n",
    "    \n",
    "    cm = tf.math.confusion_matrix(labels=y_true_mlp[fold], predictions=y_preds_int).numpy()\n",
    "    cm_mean.append(cm)\n",
    "    print(fold)\n",
    "   # print(cm_mlp)\n",
    "   # print(cm_cnn)\n",
    "    print(cm)\n",
    "    print('')\n",
    "\n",
    "print('Mean cm: ')\n",
    "cm_mean = np.mean(cm_mean, axis=0)\n",
    "print(cm_mean)\n",
    "\n",
    "reduction = 1 - ( (cm_mean[0][1] + cm_mean[1][1] )/ np.sum(cm_mean))\n",
    "print('reduction in candidate circles = ', reduction)\n",
    "\n",
    "recall = cm_mean[1][1] / (cm_mean[1][0] + cm_mean[1][1])\n",
    "print('recall = ', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "id": "wuqA2mpWZTXn",
    "outputId": "1a97cd28-0f1c-417b-ce4a-b36cf17a1709"
   },
   "outputs": [],
   "source": [
    "# this cell prints a chart with ROC curves, and also calculates optimal threshold for each fold\n",
    "# print CMs and ROC curves for each fold\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import tensorflow as tf\n",
    "\n",
    "threshold = 0.2\n",
    "\n",
    "cm_byfold = list()\n",
    "thresh_byfold = list()\n",
    "\n",
    "# fig size\n",
    "mpl.rcParams['figure.figsize'] = (3.1, 3.1)\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "colors = ['magenta', 'blue', 'red', 'green', 'gray']\n",
    "\n",
    "# add all curves for full model\n",
    "for fold in range(0,5):\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true_mlp[fold], y_preds_all[fold])\n",
    "    print(len(tpr))\n",
    "    aucurve = auc(fpr, tpr)\n",
    "\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    print(\"Threshold value is:\", optimal_threshold)\n",
    "\n",
    "    thresh_byfold.append(optimal_threshold)\n",
    "    plt.plot(fpr, tpr, label='Fold ' + str(fold+1) + ' (area = {:.3f})'.format(aucurve), color=colors[fold])\n",
    "\n",
    "\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curves by training fold')\n",
    "plt.legend(loc='best')    \n",
    "plt.show()\n",
    "\n",
    "fig.savefig('/content/drive/MyDrive/COLAB/figs/roc_curves_by_fold_MLP_CNN.jpg',\n",
    "            format='jpg',\n",
    "            dpi=600,\n",
    "            bbox_inches='tight')\n",
    "\n",
    "\n",
    "##print('mean CM using threshold: ')\n",
    "#meancm = np.mean(cm_byfold, axis=0)\n",
    "#print(meancm)\n",
    "\n",
    "mean_thresh = np.mean(thresh_byfold)\n",
    "print('mean threshold: ', mean_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puODGbXb3UH-"
   },
   "source": [
    "# Aggregate map pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vlwi04l43VVE"
   },
   "outputs": [],
   "source": [
    "# select data for analysis. run this cell to select unfiltered data\n",
    "import pandas as pd\n",
    "dfs = list()\n",
    "\n",
    "for fold in range(0,5):\n",
    "  df = pd.DataFrame()\n",
    "\n",
    "  y_p = (y_preds_all[fold] > 1.2).astype('int32')\n",
    "\n",
    "  df['filenames'] = file_test[fold]\n",
    "  df['true'] = y_true_mlp[fold]\n",
    "  df['pred'] = y_p\n",
    "\n",
    "  dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34oBnAEbzvM3",
    "outputId": "76f3791b-e7a3-495e-8eba-d5d3a260fca0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from random import random\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (6.5, 20)\n",
    "\n",
    "\n",
    "# aggregate map pages and return list of true pos and false pos, etc\n",
    "cms = list()\n",
    "map_num=list()\n",
    "maps_cm = list()\n",
    "\n",
    "for fold in range(0,5):\n",
    "  print(fold)\n",
    "  df = dfs[fold]\n",
    "  df['file'] = df['filenames'].str.rstrip('.jpg').astype(str)\n",
    "  df['map'] = df['filenames'].str.split('-').str[0] + '-' + df['filenames'].str.split('-').str[1]\n",
    "  df['volume'] = df['map'].str.split('-').str[0]\n",
    "  df['city'] = df['file'].str.split('_').str[0]\n",
    "  df['year'] = df['file'].str.split('-').str[0]\n",
    "  df['year'] = df['year'].str.split('_').str[-1]\n",
    "  df['cityyear'] = df['city'] + '_' + df['year']\n",
    "\n",
    "  # full dfs, split\n",
    "  df_tp = df.loc[(df['pred'] == 1) & (df['true'] == 1)]\n",
    "  df_fp = df.loc[(df['pred'] == 1) & (df['true'] == 0)]\n",
    "  df_tn = df.loc[(df['pred'] == 0) & (df['true'] == 0)]\n",
    "  df_fn = df.loc[(df['pred'] == 0) & (df['true'] == 1)]\n",
    "\n",
    "  # get num maps\n",
    "  maps = np.unique(df['map'])\n",
    "  map_num = len(maps)\n",
    "\n",
    "  # get unique values from each list of maps\n",
    "  tp = set(np.unique(df_tp['map']))\n",
    "  fp = set(np.unique(df_fp['map']))\n",
    "  fn = set(np.unique(df_fn['map']))\n",
    "  tn = set(np.unique(df_tn['map']))\n",
    "\n",
    "\n",
    "  tp_fp_fn_tn = []\n",
    "  tp_fp_fn    = []\n",
    "  fp_fn_tn    = []\n",
    "  tp_fp       = []\n",
    "  tp_fn       = []\n",
    "  tp_tn       = []\n",
    "  fp_fn       = []\n",
    "  fp_tn       = []\n",
    "  fn_tn       = []\n",
    "  tp_only = []\n",
    "  fp_only = []\n",
    "  tn_only = []\n",
    "  fn_only = []\n",
    "\n",
    "  # sort maps based on intersections\n",
    "  for map in np.unique(df['map']):\n",
    "    if map in tp&fp&fn&tn:\n",
    "      tp_fp_fn_tn.append(map)\n",
    "    elif map in tp&fp&fn:\n",
    "      tp_fp_fn.append(map)\n",
    "    elif map in fp&fn&tn:\n",
    "      fp_fn_tn.append(map)\n",
    "    elif map in tp&fp:\n",
    "      tp_fp.append(map)\n",
    "    elif map in tp&fn:\n",
    "      tp_fn.append(map)\n",
    "    elif map in tp&tn:\n",
    "      tp_tn.append(map)\n",
    "    elif map in fp&fn:\n",
    "      fp_fn.append(map)\n",
    "    elif map in fn&tn:\n",
    "      fp_tn.append(map)\n",
    "    elif map in fn&tn:\n",
    "      fn_tn.append(map)\n",
    "    elif map in tp:\n",
    "      tp_only.append(map)\n",
    "    elif map in fp:\n",
    "      fp_only.append(map)\n",
    "    elif map in tn:\n",
    "      tn_only.append(map)\n",
    "    elif map in fn:\n",
    "      fn_only.append(map)\n",
    "        \n",
    "  # construct final values. TP = any map with TP. FP = any map with FP but no TP. FN = any map with FN. TN = all TN-only maps.\n",
    "  tp_final = tp_only + tp_fp_fn_tn + tp_fp_fn + tp_fp + tp_fn + tp_tn + fp_fn + fp_fn_tn\n",
    "  fp_final = fp_only + fp_tn\n",
    "  fn_final = fn_only + fn_tn\n",
    "  tn_final = tn_only\n",
    " \n",
    "  print(fn_final)\n",
    "\n",
    "  print('cm of just the number of maps in each category: ')\n",
    "  map_cm = np.array([[len(tn), len(fp)], [len(fn), len(tp)]])\n",
    "  maps_cm.append(map_cm)\n",
    "  print(map_cm)\n",
    "  \n",
    "\n",
    "  cm_final = np.array([[len(tn_final), len(fp_final)], [len(fn_final), len(tp_final)]])\n",
    "  print('final cm after accounting for recovered maps: ')\n",
    "  print(cm_final)\n",
    "  cms.append(cm_final)\n",
    "\n",
    "cms = np.array(cms)\n",
    "final_cm = np.sum(cms, axis=0)\n",
    "print('final cm total, adding all CMS above: ')\n",
    "print(final_cm)\n",
    "\n",
    "print('mean number of maps per fold: ', np.mean(np.array(map_num)))\n",
    "\n",
    "print('Mean total map cm: ')\n",
    "maps_mean = np.mean(maps_cm, axis=0)\n",
    "print(maps_mean)\n",
    "\n",
    "\n",
    "print('Mean final cm, after accounting for recovered maps: ')\n",
    "cm_mean = np.mean(cms, axis=0)\n",
    "print(cm_mean)\n",
    "\n",
    "reduction = 1 - ( (cm_mean[0][1] + cm_mean[1][1] )/ np.sum(cm_mean))\n",
    "print('reduction in candidate maps = ', reduction)\n",
    "\n",
    "recall = cm_mean[1][1] / (cm_mean[1][0] + cm_mean[1][1])\n",
    "print('recall = ', recall)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "WzofQtNbzyOs",
    "YYK6becJtwAY"
   ],
   "name": "evaluate_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
