{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvtVyNKKiXL0"
   },
   "source": [
    "# First, set up the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RulgKgstigzv",
    "outputId": "6d9fce91-68d7-46c4-9a87-07bea4e8c48e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdAOVtxXiXL5"
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "HbPt5qCSiXL_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "path = \"ML_training/training_data/\"\n",
    "X = np.load(path+'X.npy')\n",
    "y = np.load(path+'y.npy')\n",
    "file = np.load(path+'file.npy')\n",
    "\n",
    "# set numpy seed for model\n",
    "np.random.seed(0) # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "T6gHXmgA73DN"
   },
   "outputs": [],
   "source": [
    "# convert to grayscale (if you want)\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "X = rgb2gray(X)\n",
    "Xmlp = X\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmQnZWLfiXNu"
   },
   "source": [
    "# Define CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PCt0sV5UiXNw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WIE7FnXLiXN4"
   },
   "outputs": [],
   "source": [
    "# Convolutional Neural Network https://machinelearningmastery.com/keras-functional-api-deep-learning/\n",
    "\n",
    "# Convolutional Neural Network\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, AveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "input_shape = (X.shape[1], X.shape[2], X.shape[3])\n",
    "\n",
    "nClasses = 2\n",
    "\n",
    "def createModel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#    model.add(Dropout(0.25))\n",
    "\n",
    "#    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#    model.add(Dropout(0.25))\n",
    "\n",
    "#    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#    model.add(Dropout(0.25))\n",
    "\n",
    "#    model.add(Conv2D(64, (1, 1), padding='same', activation='relu'))\n",
    " #   model.add(Conv2D(64, (1, 1), activation='relu'))\n",
    " #   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    " #   model.add(Dense(1032, activation='relu', kernel_regularizer='l2'))\n",
    "  #  model.add(Dropout(0.5))\n",
    "    model.add(Dense(nClasses, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# plot_model(model, to_file='convolutional_neural_network.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MgJeHSdsUMkR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RRBw8y2UN0x"
   },
   "source": [
    "# Define MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NUVGJ2TxUPpU"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# define and fit scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "\n",
    "################## define and run model itself, after you've found good params ########\n",
    "mlp = MLPClassifier(hidden_layer_sizes= (100, 50),\n",
    "                    activation = 'relu',\n",
    "                    solver = 'lbfgs',\n",
    "                    alpha = 1e-5,\n",
    "                    learning_rate = 'constant',\n",
    "                    random_state = 0, max_iter=5000)\n",
    "\n",
    "pipe = Pipeline(steps =[('scaler',scaler) , ('MLPClassifier', mlp)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cmOQL2F5qDG"
   },
   "source": [
    "# Train CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YZ8OZyWU5qDI",
    "outputId": "e184ba5e-568d-4519-dc3f-3cf1f4cba836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.5263862633900441, 1: 9.974626865671642}\n",
      "0\n",
      "Epoch 1/80\n",
      "89/89 [==============================] - 3s 22ms/step - loss: 0.6011 - tp: 2379.9111 - fp: 699.1111 - tn: 2211.8222 - fn: 531.0222 - accuracy: 0.7851 - precision: 0.7640 - recall: 0.8376 - auc: 0.8587 - val_loss: 0.6428 - val_tp: 598.0000 - val_fp: 416.0000 - val_tn: 587.0000 - val_fn: 405.0000 - val_accuracy: 0.5907 - val_precision: 0.5897 - val_recall: 0.5962 - val_auc: 0.7371\n",
      "Epoch 2/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4506 - tp: 2054.0667 - fp: 868.9222 - tn: 2042.0111 - fn: 856.8667 - accuracy: 0.7124 - precision: 0.7115 - recall: 0.7145 - auc: 0.8331 - val_loss: 0.5830 - val_tp: 614.0000 - val_fp: 400.0000 - val_tn: 603.0000 - val_fn: 389.0000 - val_accuracy: 0.6067 - val_precision: 0.6055 - val_recall: 0.6122 - val_auc: 0.7543\n",
      "Epoch 3/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4506 - tp: 2033.4889 - fp: 890.9667 - tn: 2019.9667 - fn: 877.4444 - accuracy: 0.6936 - precision: 0.6927 - recall: 0.6958 - auc: 0.8228 - val_loss: 0.6226 - val_tp: 606.0000 - val_fp: 406.0000 - val_tn: 597.0000 - val_fn: 397.0000 - val_accuracy: 0.5997 - val_precision: 0.5988 - val_recall: 0.6042 - val_auc: 0.7467\n",
      "Epoch 4/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.4448 - tp: 2065.4111 - fp: 850.2556 - tn: 2060.6778 - fn: 845.5222 - accuracy: 0.7061 - precision: 0.7058 - recall: 0.7070 - auc: 0.8278 - val_loss: 0.6035 - val_tp: 624.0000 - val_fp: 384.0000 - val_tn: 619.0000 - val_fn: 379.0000 - val_accuracy: 0.6196 - val_precision: 0.6190 - val_recall: 0.6221 - val_auc: 0.7585\n",
      "Epoch 5/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.4379 - tp: 2083.6556 - fp: 829.0889 - tn: 2081.8444 - fn: 827.2778 - accuracy: 0.7147 - precision: 0.7146 - recall: 0.7153 - auc: 0.8340 - val_loss: 0.5912 - val_tp: 636.0000 - val_fp: 371.0000 - val_tn: 632.0000 - val_fn: 367.0000 - val_accuracy: 0.6321 - val_precision: 0.6316 - val_recall: 0.6341 - val_auc: 0.7676\n",
      "Epoch 6/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.4328 - tp: 2104.9667 - fp: 817.8667 - tn: 2093.0667 - fn: 805.9667 - accuracy: 0.7200 - precision: 0.7188 - recall: 0.7227 - auc: 0.8378 - val_loss: 0.5834 - val_tp: 651.0000 - val_fp: 355.0000 - val_tn: 648.0000 - val_fn: 352.0000 - val_accuracy: 0.6476 - val_precision: 0.6471 - val_recall: 0.6491 - val_auc: 0.7745\n",
      "Epoch 7/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.4272 - tp: 2115.6222 - fp: 800.8222 - tn: 2110.1111 - fn: 795.3111 - accuracy: 0.7251 - precision: 0.7246 - recall: 0.7263 - auc: 0.8418 - val_loss: 0.5721 - val_tp: 663.0000 - val_fp: 347.0000 - val_tn: 656.0000 - val_fn: 340.0000 - val_accuracy: 0.6575 - val_precision: 0.6564 - val_recall: 0.6610 - val_auc: 0.7831\n",
      "Epoch 8/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4219 - tp: 2133.2444 - fp: 780.8556 - tn: 2130.0778 - fn: 777.6889 - accuracy: 0.7327 - precision: 0.7325 - recall: 0.7330 - auc: 0.8460 - val_loss: 0.5601 - val_tp: 677.0000 - val_fp: 333.0000 - val_tn: 670.0000 - val_fn: 326.0000 - val_accuracy: 0.6715 - val_precision: 0.6703 - val_recall: 0.6750 - val_auc: 0.7920\n",
      "Epoch 9/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4160 - tp: 2143.2778 - fp: 768.1111 - tn: 2142.8222 - fn: 767.6556 - accuracy: 0.7369 - precision: 0.7370 - recall: 0.7367 - auc: 0.8510 - val_loss: 0.5457 - val_tp: 696.0000 - val_fp: 313.0000 - val_tn: 690.0000 - val_fn: 307.0000 - val_accuracy: 0.6909 - val_precision: 0.6898 - val_recall: 0.6939 - val_auc: 0.8017\n",
      "Epoch 10/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.4101 - tp: 2160.7778 - fp: 747.3222 - tn: 2163.6111 - fn: 750.1556 - accuracy: 0.7449 - precision: 0.7452 - recall: 0.7442 - auc: 0.8556 - val_loss: 0.5361 - val_tp: 707.0000 - val_fp: 303.0000 - val_tn: 700.0000 - val_fn: 296.0000 - val_accuracy: 0.7014 - val_precision: 0.7000 - val_recall: 0.7049 - val_auc: 0.8090\n",
      "Epoch 11/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.4045 - tp: 2183.8778 - fp: 731.5333 - tn: 2179.4000 - fn: 727.0556 - accuracy: 0.7516 - precision: 0.7513 - recall: 0.7524 - auc: 0.8598 - val_loss: 0.5299 - val_tp: 713.0000 - val_fp: 290.0000 - val_tn: 713.0000 - val_fn: 290.0000 - val_accuracy: 0.7109 - val_precision: 0.7109 - val_recall: 0.7109 - val_auc: 0.8144\n",
      "Epoch 12/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3989 - tp: 2190.1778 - fp: 718.3111 - tn: 2192.6222 - fn: 720.7556 - accuracy: 0.7540 - precision: 0.7542 - recall: 0.7535 - auc: 0.8639 - val_loss: 0.5189 - val_tp: 717.0000 - val_fp: 290.0000 - val_tn: 713.0000 - val_fn: 286.0000 - val_accuracy: 0.7129 - val_precision: 0.7120 - val_recall: 0.7149 - val_auc: 0.8221\n",
      "Epoch 13/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3930 - tp: 2204.6778 - fp: 698.5333 - tn: 2212.4000 - fn: 706.2556 - accuracy: 0.7587 - precision: 0.7594 - recall: 0.7572 - auc: 0.8672 - val_loss: 0.5160 - val_tp: 720.0000 - val_fp: 285.0000 - val_tn: 718.0000 - val_fn: 283.0000 - val_accuracy: 0.7168 - val_precision: 0.7164 - val_recall: 0.7178 - val_auc: 0.8264\n",
      "Epoch 14/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3884 - tp: 2214.2222 - fp: 699.2667 - tn: 2211.6667 - fn: 696.7111 - accuracy: 0.7610 - precision: 0.7608 - recall: 0.7614 - auc: 0.8706 - val_loss: 0.5095 - val_tp: 727.0000 - val_fp: 283.0000 - val_tn: 720.0000 - val_fn: 276.0000 - val_accuracy: 0.7213 - val_precision: 0.7198 - val_recall: 0.7248 - val_auc: 0.8295\n",
      "Epoch 15/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3858 - tp: 2206.1889 - fp: 697.3111 - tn: 2213.6222 - fn: 704.7444 - accuracy: 0.7591 - precision: 0.7599 - recall: 0.7576 - auc: 0.8703 - val_loss: 0.5141 - val_tp: 725.0000 - val_fp: 279.0000 - val_tn: 724.0000 - val_fn: 278.0000 - val_accuracy: 0.7223 - val_precision: 0.7221 - val_recall: 0.7228 - val_auc: 0.8293\n",
      "Epoch 16/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3808 - tp: 2221.5444 - fp: 691.3333 - tn: 2219.6000 - fn: 689.3889 - accuracy: 0.7624 - precision: 0.7619 - recall: 0.7635 - auc: 0.8741 - val_loss: 0.4972 - val_tp: 737.0000 - val_fp: 268.0000 - val_tn: 735.0000 - val_fn: 266.0000 - val_accuracy: 0.7338 - val_precision: 0.7333 - val_recall: 0.7348 - val_auc: 0.8393\n",
      "Epoch 17/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3757 - tp: 2228.4778 - fp: 680.7444 - tn: 2230.1889 - fn: 682.4556 - accuracy: 0.7667 - precision: 0.7669 - recall: 0.7662 - auc: 0.8780 - val_loss: 0.5001 - val_tp: 739.0000 - val_fp: 266.0000 - val_tn: 737.0000 - val_fn: 264.0000 - val_accuracy: 0.7358 - val_precision: 0.7353 - val_recall: 0.7368 - val_auc: 0.8407\n",
      "Epoch 18/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3723 - tp: 2231.3778 - fp: 677.0111 - tn: 2233.9222 - fn: 679.5556 - accuracy: 0.7689 - precision: 0.7691 - recall: 0.7686 - auc: 0.8797 - val_loss: 0.4841 - val_tp: 749.0000 - val_fp: 257.0000 - val_tn: 746.0000 - val_fn: 254.0000 - val_accuracy: 0.7453 - val_precision: 0.7445 - val_recall: 0.7468 - val_auc: 0.8487\n",
      "Epoch 19/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3663 - tp: 2246.0889 - fp: 664.6889 - tn: 2246.2444 - fn: 664.8444 - accuracy: 0.7727 - precision: 0.7724 - recall: 0.7732 - auc: 0.8832 - val_loss: 0.4939 - val_tp: 744.0000 - val_fp: 261.0000 - val_tn: 742.0000 - val_fn: 259.0000 - val_accuracy: 0.7408 - val_precision: 0.7403 - val_recall: 0.7418 - val_auc: 0.8464\n",
      "Epoch 20/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3642 - tp: 2243.7444 - fp: 662.0222 - tn: 2248.9111 - fn: 667.1889 - accuracy: 0.7730 - precision: 0.7735 - recall: 0.7721 - auc: 0.8843 - val_loss: 0.4852 - val_tp: 742.0000 - val_fp: 260.0000 - val_tn: 743.0000 - val_fn: 261.0000 - val_accuracy: 0.7403 - val_precision: 0.7405 - val_recall: 0.7398 - val_auc: 0.8499\n",
      "Epoch 21/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3596 - tp: 2254.1333 - fp: 655.9111 - tn: 2255.0222 - fn: 656.8000 - accuracy: 0.7750 - precision: 0.7749 - recall: 0.7750 - auc: 0.8862 - val_loss: 0.4805 - val_tp: 748.0000 - val_fp: 252.0000 - val_tn: 751.0000 - val_fn: 255.0000 - val_accuracy: 0.7473 - val_precision: 0.7480 - val_recall: 0.7458 - val_auc: 0.8541\n",
      "Epoch 22/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3550 - tp: 2265.6778 - fp: 646.3889 - tn: 2264.5444 - fn: 645.2556 - accuracy: 0.7786 - precision: 0.7783 - recall: 0.7791 - auc: 0.8893 - val_loss: 0.4758 - val_tp: 753.0000 - val_fp: 249.0000 - val_tn: 754.0000 - val_fn: 250.0000 - val_accuracy: 0.7512 - val_precision: 0.7515 - val_recall: 0.7507 - val_auc: 0.8580\n",
      "Epoch 23/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3510 - tp: 2278.5556 - fp: 636.0000 - tn: 2274.9333 - fn: 632.3778 - accuracy: 0.7830 - precision: 0.7822 - recall: 0.7844 - auc: 0.8913 - val_loss: 0.4658 - val_tp: 759.0000 - val_fp: 243.0000 - val_tn: 760.0000 - val_fn: 244.0000 - val_accuracy: 0.7572 - val_precision: 0.7575 - val_recall: 0.7567 - val_auc: 0.8631\n",
      "Epoch 24/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3457 - tp: 2286.3222 - fp: 627.3667 - tn: 2283.5667 - fn: 624.6111 - accuracy: 0.7851 - precision: 0.7846 - recall: 0.7859 - auc: 0.8946 - val_loss: 0.4898 - val_tp: 746.0000 - val_fp: 252.0000 - val_tn: 751.0000 - val_fn: 257.0000 - val_accuracy: 0.7463 - val_precision: 0.7475 - val_recall: 0.7438 - val_auc: 0.8548\n",
      "Epoch 25/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3444 - tp: 2292.0778 - fp: 617.8667 - tn: 2293.0667 - fn: 618.8556 - accuracy: 0.7873 - precision: 0.7873 - recall: 0.7874 - auc: 0.8940 - val_loss: 0.4583 - val_tp: 768.0000 - val_fp: 235.0000 - val_tn: 768.0000 - val_fn: 235.0000 - val_accuracy: 0.7657 - val_precision: 0.7657 - val_recall: 0.7657 - val_auc: 0.8684\n",
      "Epoch 26/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3372 - tp: 2301.1444 - fp: 609.0778 - tn: 2301.8556 - fn: 609.7889 - accuracy: 0.7900 - precision: 0.7900 - recall: 0.7899 - auc: 0.8990 - val_loss: 0.4611 - val_tp: 768.0000 - val_fp: 234.0000 - val_tn: 769.0000 - val_fn: 235.0000 - val_accuracy: 0.7662 - val_precision: 0.7665 - val_recall: 0.7657 - val_auc: 0.8685\n",
      "Epoch 27/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3343 - tp: 2306.9444 - fp: 603.3556 - tn: 2307.5778 - fn: 603.9889 - accuracy: 0.7916 - precision: 0.7917 - recall: 0.7915 - auc: 0.9000 - val_loss: 0.4511 - val_tp: 775.0000 - val_fp: 230.0000 - val_tn: 773.0000 - val_fn: 228.0000 - val_accuracy: 0.7717 - val_precision: 0.7711 - val_recall: 0.7727 - val_auc: 0.8737\n",
      "Epoch 28/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3291 - tp: 2316.8556 - fp: 592.4778 - tn: 2318.4556 - fn: 594.0778 - accuracy: 0.7953 - precision: 0.7957 - recall: 0.7946 - auc: 0.9034 - val_loss: 0.4488 - val_tp: 774.0000 - val_fp: 230.0000 - val_tn: 773.0000 - val_fn: 229.0000 - val_accuracy: 0.7712 - val_precision: 0.7709 - val_recall: 0.7717 - val_auc: 0.8757\n",
      "Epoch 29/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3245 - tp: 2332.5222 - fp: 577.7889 - tn: 2333.1444 - fn: 578.4111 - accuracy: 0.7994 - precision: 0.7997 - recall: 0.7990 - auc: 0.9053 - val_loss: 0.4834 - val_tp: 764.0000 - val_fp: 240.0000 - val_tn: 763.0000 - val_fn: 239.0000 - val_accuracy: 0.7612 - val_precision: 0.7610 - val_recall: 0.7617 - val_auc: 0.8618\n",
      "Epoch 30/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3240 - tp: 2333.0000 - fp: 580.2222 - tn: 2330.7111 - fn: 577.9333 - accuracy: 0.7983 - precision: 0.7982 - recall: 0.7986 - auc: 0.9043 - val_loss: 0.4511 - val_tp: 774.0000 - val_fp: 233.0000 - val_tn: 770.0000 - val_fn: 229.0000 - val_accuracy: 0.7697 - val_precision: 0.7686 - val_recall: 0.7717 - val_auc: 0.8767\n",
      "Epoch 31/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3167 - tp: 2350.9111 - fp: 564.0556 - tn: 2346.8778 - fn: 560.0222 - accuracy: 0.8040 - precision: 0.8037 - recall: 0.8046 - auc: 0.9087 - val_loss: 0.4502 - val_tp: 775.0000 - val_fp: 231.0000 - val_tn: 772.0000 - val_fn: 228.0000 - val_accuracy: 0.7712 - val_precision: 0.7704 - val_recall: 0.7727 - val_auc: 0.8779\n",
      "Epoch 32/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3131 - tp: 2358.0556 - fp: 552.8778 - tn: 2358.0556 - fn: 552.8778 - accuracy: 0.8067 - precision: 0.8068 - recall: 0.8066 - auc: 0.9104 - val_loss: 0.4641 - val_tp: 765.0000 - val_fp: 234.0000 - val_tn: 769.0000 - val_fn: 238.0000 - val_accuracy: 0.7647 - val_precision: 0.7658 - val_recall: 0.7627 - val_auc: 0.8727\n",
      "Epoch 33/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3116 - tp: 2368.0889 - fp: 546.2444 - tn: 2364.6889 - fn: 542.8444 - accuracy: 0.8082 - precision: 0.8080 - recall: 0.8087 - auc: 0.9104 - val_loss: 0.4469 - val_tp: 782.0000 - val_fp: 225.0000 - val_tn: 778.0000 - val_fn: 221.0000 - val_accuracy: 0.7777 - val_precision: 0.7766 - val_recall: 0.7797 - val_auc: 0.8813\n",
      "Epoch 34/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3045 - tp: 2381.0111 - fp: 532.7556 - tn: 2378.1778 - fn: 529.9222 - accuracy: 0.8123 - precision: 0.8120 - recall: 0.8130 - auc: 0.9148 - val_loss: 0.4658 - val_tp: 765.0000 - val_fp: 230.0000 - val_tn: 773.0000 - val_fn: 238.0000 - val_accuracy: 0.7667 - val_precision: 0.7688 - val_recall: 0.7627 - val_auc: 0.8740\n",
      "Epoch 35/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.3034 - tp: 2385.5111 - fp: 526.7222 - tn: 2384.2111 - fn: 525.4222 - accuracy: 0.8131 - precision: 0.8132 - recall: 0.8129 - auc: 0.9144 - val_loss: 0.4407 - val_tp: 788.0000 - val_fp: 222.0000 - val_tn: 781.0000 - val_fn: 215.0000 - val_accuracy: 0.7822 - val_precision: 0.7802 - val_recall: 0.7856 - val_auc: 0.8859\n",
      "Epoch 36/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2970 - tp: 2400.0111 - fp: 507.3444 - tn: 2403.5889 - fn: 510.9222 - accuracy: 0.8183 - precision: 0.8189 - recall: 0.8173 - auc: 0.9183 - val_loss: 0.4482 - val_tp: 784.0000 - val_fp: 226.0000 - val_tn: 777.0000 - val_fn: 219.0000 - val_accuracy: 0.7782 - val_precision: 0.7762 - val_recall: 0.7817 - val_auc: 0.8836\n",
      "Epoch 37/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2932 - tp: 2402.6111 - fp: 503.9222 - tn: 2407.0111 - fn: 508.3222 - accuracy: 0.8186 - precision: 0.8194 - recall: 0.8174 - auc: 0.9199 - val_loss: 0.4462 - val_tp: 785.0000 - val_fp: 227.0000 - val_tn: 776.0000 - val_fn: 218.0000 - val_accuracy: 0.7782 - val_precision: 0.7757 - val_recall: 0.7827 - val_auc: 0.8855\n",
      "Epoch 38/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.2872 - tp: 2429.1000 - fp: 479.2222 - tn: 2431.7111 - fn: 481.8333 - accuracy: 0.8270 - precision: 0.8277 - recall: 0.8259 - auc: 0.9235 - val_loss: 0.4550 - val_tp: 783.0000 - val_fp: 225.0000 - val_tn: 778.0000 - val_fn: 220.0000 - val_accuracy: 0.7782 - val_precision: 0.7768 - val_recall: 0.7807 - val_auc: 0.8835\n",
      "Epoch 39/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.2843 - tp: 2443.1889 - fp: 471.5778 - tn: 2439.3556 - fn: 467.7444 - accuracy: 0.8312 - precision: 0.8310 - recall: 0.8315 - auc: 0.9250 - val_loss: 0.4422 - val_tp: 788.0000 - val_fp: 219.0000 - val_tn: 784.0000 - val_fn: 215.0000 - val_accuracy: 0.7836 - val_precision: 0.7825 - val_recall: 0.7856 - val_auc: 0.8894\n",
      "Epoch 40/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.2794 - tp: 2447.1889 - fp: 467.1556 - tn: 2443.7778 - fn: 463.7444 - accuracy: 0.8321 - precision: 0.8317 - recall: 0.8326 - auc: 0.9274 - val_loss: 0.4390 - val_tp: 790.0000 - val_fp: 218.0000 - val_tn: 785.0000 - val_fn: 213.0000 - val_accuracy: 0.7851 - val_precision: 0.7837 - val_recall: 0.7876 - val_auc: 0.8913\n",
      "Epoch 41/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2766 - tp: 2459.8333 - fp: 458.1111 - tn: 2452.8222 - fn: 451.1000 - accuracy: 0.8349 - precision: 0.8341 - recall: 0.8360 - auc: 0.9282 - val_loss: 0.4363 - val_tp: 794.0000 - val_fp: 217.0000 - val_tn: 786.0000 - val_fn: 209.0000 - val_accuracy: 0.7876 - val_precision: 0.7854 - val_recall: 0.7916 - val_auc: 0.8935\n",
      "Epoch 42/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2713 - tp: 2476.7556 - fp: 438.3333 - tn: 2472.6000 - fn: 434.1778 - accuracy: 0.8416 - precision: 0.8413 - recall: 0.8421 - auc: 0.9312 - val_loss: 0.4438 - val_tp: 791.0000 - val_fp: 216.0000 - val_tn: 787.0000 - val_fn: 212.0000 - val_accuracy: 0.7866 - val_precision: 0.7855 - val_recall: 0.7886 - val_auc: 0.8919\n",
      "Epoch 43/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.2679 - tp: 2481.7222 - fp: 429.5667 - tn: 2481.3667 - fn: 429.2111 - accuracy: 0.8448 - precision: 0.8448 - recall: 0.8447 - auc: 0.9333 - val_loss: 0.4274 - val_tp: 797.0000 - val_fp: 206.0000 - val_tn: 797.0000 - val_fn: 206.0000 - val_accuracy: 0.7946 - val_precision: 0.7946 - val_recall: 0.7946 - val_auc: 0.8992\n",
      "Epoch 44/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.2621 - tp: 2498.3444 - fp: 420.4111 - tn: 2490.5222 - fn: 412.5889 - accuracy: 0.8500 - precision: 0.8492 - recall: 0.8512 - auc: 0.9369 - val_loss: 0.4431 - val_tp: 795.0000 - val_fp: 208.0000 - val_tn: 795.0000 - val_fn: 208.0000 - val_accuracy: 0.7926 - val_precision: 0.7926 - val_recall: 0.7926 - val_auc: 0.8951\n",
      "Epoch 45/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.2610 - tp: 2503.3556 - fp: 411.3556 - tn: 2499.5778 - fn: 407.5778 - accuracy: 0.8520 - precision: 0.8513 - recall: 0.8530 - auc: 0.9366 - val_loss: 0.4303 - val_tp: 802.0000 - val_fp: 207.0000 - val_tn: 796.0000 - val_fn: 201.0000 - val_accuracy: 0.7966 - val_precision: 0.7948 - val_recall: 0.7996 - val_auc: 0.8995\n",
      "Epoch 46/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2559 - tp: 2512.1222 - fp: 403.5333 - tn: 2507.4000 - fn: 398.8111 - accuracy: 0.8543 - precision: 0.8534 - recall: 0.8555 - auc: 0.9390 - val_loss: 0.4299 - val_tp: 804.0000 - val_fp: 204.0000 - val_tn: 799.0000 - val_fn: 199.0000 - val_accuracy: 0.7991 - val_precision: 0.7976 - val_recall: 0.8016 - val_auc: 0.9012\n",
      "Epoch 47/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2531 - tp: 2523.4000 - fp: 394.6333 - tn: 2516.3000 - fn: 387.5333 - accuracy: 0.8574 - precision: 0.8563 - recall: 0.8589 - auc: 0.9409 - val_loss: 0.4383 - val_tp: 802.0000 - val_fp: 204.0000 - val_tn: 799.0000 - val_fn: 201.0000 - val_accuracy: 0.7981 - val_precision: 0.7972 - val_recall: 0.7996 - val_auc: 0.8987\n",
      "Epoch 48/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.2502 - tp: 2531.3222 - fp: 382.8667 - tn: 2528.0667 - fn: 379.6111 - accuracy: 0.8608 - precision: 0.8603 - recall: 0.8614 - auc: 0.9415 - val_loss: 0.4239 - val_tp: 806.0000 - val_fp: 200.0000 - val_tn: 803.0000 - val_fn: 197.0000 - val_accuracy: 0.8021 - val_precision: 0.8012 - val_recall: 0.8036 - val_auc: 0.9040\n",
      "Epoch 49/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.2465 - tp: 2531.7222 - fp: 377.6444 - tn: 2533.2889 - fn: 379.2111 - accuracy: 0.8619 - precision: 0.8619 - recall: 0.8619 - auc: 0.9435 - val_loss: 0.4272 - val_tp: 806.0000 - val_fp: 195.0000 - val_tn: 808.0000 - val_fn: 197.0000 - val_accuracy: 0.8046 - val_precision: 0.8052 - val_recall: 0.8036 - val_auc: 0.9046\n",
      "Epoch 50/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2434 - tp: 2540.0889 - fp: 372.8333 - tn: 2538.1000 - fn: 370.8444 - accuracy: 0.8645 - precision: 0.8640 - recall: 0.8651 - auc: 0.9448 - val_loss: 0.4188 - val_tp: 809.0000 - val_fp: 190.0000 - val_tn: 813.0000 - val_fn: 194.0000 - val_accuracy: 0.8086 - val_precision: 0.8098 - val_recall: 0.8066 - val_auc: 0.9074\n",
      "Epoch 51/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2388 - tp: 2546.7444 - fp: 363.7889 - tn: 2547.1444 - fn: 364.1889 - accuracy: 0.8671 - precision: 0.8670 - recall: 0.8673 - auc: 0.9467 - val_loss: 0.4286 - val_tp: 808.0000 - val_fp: 195.0000 - val_tn: 808.0000 - val_fn: 195.0000 - val_accuracy: 0.8056 - val_precision: 0.8056 - val_recall: 0.8056 - val_auc: 0.9057\n",
      "Epoch 52/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2366 - tp: 2553.5889 - fp: 362.7667 - tn: 2548.1667 - fn: 357.3444 - accuracy: 0.8687 - precision: 0.8680 - recall: 0.8698 - auc: 0.9476 - val_loss: 0.4273 - val_tp: 809.0000 - val_fp: 192.0000 - val_tn: 811.0000 - val_fn: 194.0000 - val_accuracy: 0.8076 - val_precision: 0.8082 - val_recall: 0.8066 - val_auc: 0.9061\n",
      "Epoch 53/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2322 - tp: 2561.3333 - fp: 348.9333 - tn: 2562.0000 - fn: 349.6000 - accuracy: 0.8725 - precision: 0.8724 - recall: 0.8726 - auc: 0.9495 - val_loss: 0.4351 - val_tp: 808.0000 - val_fp: 190.0000 - val_tn: 813.0000 - val_fn: 195.0000 - val_accuracy: 0.8081 - val_precision: 0.8096 - val_recall: 0.8056 - val_auc: 0.9056\n",
      "Epoch 54/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2302 - tp: 2568.6333 - fp: 342.3111 - tn: 2568.6222 - fn: 342.3000 - accuracy: 0.8749 - precision: 0.8748 - recall: 0.8750 - auc: 0.9503 - val_loss: 0.3945 - val_tp: 826.0000 - val_fp: 174.0000 - val_tn: 829.0000 - val_fn: 177.0000 - val_accuracy: 0.8250 - val_precision: 0.8260 - val_recall: 0.8235 - val_auc: 0.9187\n",
      "Epoch 55/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2240 - tp: 2569.6111 - fp: 342.9667 - tn: 2567.9667 - fn: 341.3222 - accuracy: 0.8753 - precision: 0.8746 - recall: 0.8762 - auc: 0.9527 - val_loss: 0.4069 - val_tp: 824.0000 - val_fp: 177.0000 - val_tn: 826.0000 - val_fn: 179.0000 - val_accuracy: 0.8225 - val_precision: 0.8232 - val_recall: 0.8215 - val_auc: 0.9156\n",
      "Epoch 56/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.2222 - tp: 2570.7333 - fp: 336.2333 - tn: 2574.7000 - fn: 340.2000 - accuracy: 0.8762 - precision: 0.8764 - recall: 0.8761 - auc: 0.9534 - val_loss: 0.4061 - val_tp: 827.0000 - val_fp: 175.0000 - val_tn: 828.0000 - val_fn: 176.0000 - val_accuracy: 0.8250 - val_precision: 0.8253 - val_recall: 0.8245 - val_auc: 0.9164\n",
      "Epoch 57/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2177 - tp: 2584.3556 - fp: 322.6556 - tn: 2588.2778 - fn: 326.5778 - accuracy: 0.8817 - precision: 0.8817 - recall: 0.8817 - auc: 0.9554 - val_loss: 0.3924 - val_tp: 828.0000 - val_fp: 169.0000 - val_tn: 834.0000 - val_fn: 175.0000 - val_accuracy: 0.8285 - val_precision: 0.8305 - val_recall: 0.8255 - val_auc: 0.9207\n",
      "Epoch 58/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2150 - tp: 2584.0667 - fp: 319.9222 - tn: 2591.0111 - fn: 326.8667 - accuracy: 0.8822 - precision: 0.8828 - recall: 0.8814 - auc: 0.9561 - val_loss: 0.3953 - val_tp: 828.0000 - val_fp: 168.0000 - val_tn: 835.0000 - val_fn: 175.0000 - val_accuracy: 0.8290 - val_precision: 0.8313 - val_recall: 0.8255 - val_auc: 0.9207\n",
      "Epoch 59/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2105 - tp: 2599.5889 - fp: 309.7778 - tn: 2601.1556 - fn: 311.3444 - accuracy: 0.8867 - precision: 0.8868 - recall: 0.8867 - auc: 0.9581 - val_loss: 0.3794 - val_tp: 836.0000 - val_fp: 167.0000 - val_tn: 836.0000 - val_fn: 167.0000 - val_accuracy: 0.8335 - val_precision: 0.8335 - val_recall: 0.8335 - val_auc: 0.9263\n",
      "Epoch 60/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.2082 - tp: 2596.0444 - fp: 309.2667 - tn: 2601.6667 - fn: 314.8889 - accuracy: 0.8860 - precision: 0.8864 - recall: 0.8857 - auc: 0.9585 - val_loss: 0.3785 - val_tp: 839.0000 - val_fp: 162.0000 - val_tn: 841.0000 - val_fn: 164.0000 - val_accuracy: 0.8375 - val_precision: 0.8382 - val_recall: 0.8365 - val_auc: 0.9269\n",
      "Epoch 61/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2025 - tp: 2610.4556 - fp: 295.0111 - tn: 2615.9222 - fn: 300.4778 - accuracy: 0.8909 - precision: 0.8915 - recall: 0.8902 - auc: 0.9611 - val_loss: 0.3770 - val_tp: 841.0000 - val_fp: 164.0000 - val_tn: 839.0000 - val_fn: 162.0000 - val_accuracy: 0.8375 - val_precision: 0.8368 - val_recall: 0.8385 - val_auc: 0.9282\n",
      "Epoch 62/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2000 - tp: 2614.0778 - fp: 292.0222 - tn: 2618.9111 - fn: 296.8556 - accuracy: 0.8919 - precision: 0.8924 - recall: 0.8914 - auc: 0.9615 - val_loss: 0.3742 - val_tp: 843.0000 - val_fp: 164.0000 - val_tn: 839.0000 - val_fn: 160.0000 - val_accuracy: 0.8385 - val_precision: 0.8371 - val_recall: 0.8405 - val_auc: 0.9294\n",
      "Epoch 63/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1967 - tp: 2621.4111 - fp: 285.8222 - tn: 2625.1111 - fn: 289.5222 - accuracy: 0.8943 - precision: 0.8945 - recall: 0.8940 - auc: 0.9627 - val_loss: 0.3697 - val_tp: 845.0000 - val_fp: 161.0000 - val_tn: 842.0000 - val_fn: 158.0000 - val_accuracy: 0.8410 - val_precision: 0.8400 - val_recall: 0.8425 - val_auc: 0.9316\n",
      "Epoch 64/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1920 - tp: 2628.0667 - fp: 284.8444 - tn: 2626.0889 - fn: 282.8667 - accuracy: 0.8959 - precision: 0.8952 - recall: 0.8968 - auc: 0.9646 - val_loss: 0.3608 - val_tp: 848.0000 - val_fp: 155.0000 - val_tn: 848.0000 - val_fn: 155.0000 - val_accuracy: 0.8455 - val_precision: 0.8455 - val_recall: 0.8455 - val_auc: 0.9347\n",
      "Epoch 65/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1897 - tp: 2630.0111 - fp: 277.9778 - tn: 2632.9556 - fn: 280.9222 - accuracy: 0.8977 - precision: 0.8979 - recall: 0.8974 - auc: 0.9650 - val_loss: 0.3486 - val_tp: 850.0000 - val_fp: 153.0000 - val_tn: 850.0000 - val_fn: 153.0000 - val_accuracy: 0.8475 - val_precision: 0.8475 - val_recall: 0.8475 - val_auc: 0.9386\n",
      "Epoch 66/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1850 - tp: 2637.2778 - fp: 274.5889 - tn: 2636.3444 - fn: 273.6556 - accuracy: 0.9000 - precision: 0.8996 - recall: 0.9005 - auc: 0.9670 - val_loss: 0.3510 - val_tp: 856.0000 - val_fp: 151.0000 - val_tn: 852.0000 - val_fn: 147.0000 - val_accuracy: 0.8514 - val_precision: 0.8500 - val_recall: 0.8534 - val_auc: 0.9389\n",
      "Epoch 67/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1810 - tp: 2647.9222 - fp: 262.4222 - tn: 2648.5111 - fn: 263.0111 - accuracy: 0.9047 - precision: 0.9049 - recall: 0.9045 - auc: 0.9685 - val_loss: 0.3536 - val_tp: 854.0000 - val_fp: 153.0000 - val_tn: 850.0000 - val_fn: 149.0000 - val_accuracy: 0.8495 - val_precision: 0.8481 - val_recall: 0.8514 - val_auc: 0.9380\n",
      "Epoch 68/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1768 - tp: 2652.6333 - fp: 256.8333 - tn: 2654.1000 - fn: 258.3000 - accuracy: 0.9069 - precision: 0.9076 - recall: 0.9061 - auc: 0.9701 - val_loss: 0.3689 - val_tp: 848.0000 - val_fp: 160.0000 - val_tn: 843.0000 - val_fn: 155.0000 - val_accuracy: 0.8430 - val_precision: 0.8413 - val_recall: 0.8455 - val_auc: 0.9337\n",
      "Epoch 69/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1748 - tp: 2656.9333 - fp: 254.9111 - tn: 2656.0222 - fn: 254.0000 - accuracy: 0.9070 - precision: 0.9070 - recall: 0.9071 - auc: 0.9700 - val_loss: 0.3618 - val_tp: 852.0000 - val_fp: 156.0000 - val_tn: 847.0000 - val_fn: 151.0000 - val_accuracy: 0.8470 - val_precision: 0.8452 - val_recall: 0.8495 - val_auc: 0.9365\n",
      "Epoch 70/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1711 - tp: 2663.7556 - fp: 245.4778 - tn: 2665.4556 - fn: 247.1778 - accuracy: 0.9103 - precision: 0.9110 - recall: 0.9094 - auc: 0.9708 - val_loss: 0.3508 - val_tp: 859.0000 - val_fp: 146.0000 - val_tn: 857.0000 - val_fn: 144.0000 - val_accuracy: 0.8554 - val_precision: 0.8547 - val_recall: 0.8564 - val_auc: 0.9404\n",
      "Epoch 71/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1673 - tp: 2668.0222 - fp: 241.7333 - tn: 2669.2000 - fn: 242.9111 - accuracy: 0.9119 - precision: 0.9125 - recall: 0.9111 - auc: 0.9724 - val_loss: 0.3433 - val_tp: 863.0000 - val_fp: 137.0000 - val_tn: 866.0000 - val_fn: 140.0000 - val_accuracy: 0.8619 - val_precision: 0.8630 - val_recall: 0.8604 - val_auc: 0.9429\n",
      "Epoch 72/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1639 - tp: 2673.7222 - fp: 233.7444 - tn: 2677.1889 - fn: 237.2111 - accuracy: 0.9145 - precision: 0.9152 - recall: 0.9137 - auc: 0.9734 - val_loss: 0.3262 - val_tp: 874.0000 - val_fp: 130.0000 - val_tn: 873.0000 - val_fn: 129.0000 - val_accuracy: 0.8709 - val_precision: 0.8705 - val_recall: 0.8714 - val_auc: 0.9487\n",
      "Epoch 73/80\n",
      "89/89 [==============================] - 1s 12ms/step - loss: 0.1598 - tp: 2675.6444 - fp: 230.5667 - tn: 2680.3667 - fn: 235.2889 - accuracy: 0.9157 - precision: 0.9168 - recall: 0.9142 - auc: 0.9752 - val_loss: 0.3070 - val_tp: 883.0000 - val_fp: 123.0000 - val_tn: 880.0000 - val_fn: 120.0000 - val_accuracy: 0.8789 - val_precision: 0.8777 - val_recall: 0.8804 - val_auc: 0.9541\n",
      "Epoch 74/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1559 - tp: 2685.7333 - fp: 222.0889 - tn: 2688.8444 - fn: 225.2000 - accuracy: 0.9199 - precision: 0.9205 - recall: 0.9192 - auc: 0.9763 - val_loss: 0.3086 - val_tp: 881.0000 - val_fp: 123.0000 - val_tn: 880.0000 - val_fn: 122.0000 - val_accuracy: 0.8779 - val_precision: 0.8775 - val_recall: 0.8784 - val_auc: 0.9544\n",
      "Epoch 75/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1530 - tp: 2690.5556 - fp: 220.1333 - tn: 2690.8000 - fn: 220.3778 - accuracy: 0.9210 - precision: 0.9210 - recall: 0.9211 - auc: 0.9773 - val_loss: 0.3014 - val_tp: 885.0000 - val_fp: 120.0000 - val_tn: 883.0000 - val_fn: 118.0000 - val_accuracy: 0.8814 - val_precision: 0.8806 - val_recall: 0.8824 - val_auc: 0.9566\n",
      "Epoch 76/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1509 - tp: 2692.2778 - fp: 217.0222 - tn: 2693.9111 - fn: 218.6556 - accuracy: 0.9217 - precision: 0.9218 - recall: 0.9216 - auc: 0.9778 - val_loss: 0.3456 - val_tp: 865.0000 - val_fp: 141.0000 - val_tn: 862.0000 - val_fn: 138.0000 - val_accuracy: 0.8609 - val_precision: 0.8598 - val_recall: 0.8624 - val_auc: 0.9442\n",
      "Epoch 77/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1466 - tp: 2697.1000 - fp: 205.7889 - tn: 2705.1444 - fn: 213.8333 - accuracy: 0.9229 - precision: 0.9244 - recall: 0.9211 - auc: 0.9782 - val_loss: 0.3387 - val_tp: 871.0000 - val_fp: 132.0000 - val_tn: 871.0000 - val_fn: 132.0000 - val_accuracy: 0.8684 - val_precision: 0.8684 - val_recall: 0.8684 - val_auc: 0.9466\n",
      "Epoch 78/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1438 - tp: 2699.6556 - fp: 205.7111 - tn: 2705.2222 - fn: 211.2778 - accuracy: 0.9235 - precision: 0.9246 - recall: 0.9222 - auc: 0.9789 - val_loss: 0.3229 - val_tp: 877.0000 - val_fp: 125.0000 - val_tn: 878.0000 - val_fn: 126.0000 - val_accuracy: 0.8749 - val_precision: 0.8752 - val_recall: 0.8744 - val_auc: 0.9513\n",
      "Epoch 79/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1409 - tp: 2704.2556 - fp: 199.7222 - tn: 2711.2111 - fn: 206.6778 - accuracy: 0.9260 - precision: 0.9271 - recall: 0.9246 - auc: 0.9797 - val_loss: 0.3285 - val_tp: 875.0000 - val_fp: 126.0000 - val_tn: 877.0000 - val_fn: 128.0000 - val_accuracy: 0.8734 - val_precision: 0.8741 - val_recall: 0.8724 - val_auc: 0.9496\n",
      "Epoch 80/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1378 - tp: 2711.7333 - fp: 193.8778 - tn: 2717.0556 - fn: 199.2000 - accuracy: 0.9285 - precision: 0.9293 - recall: 0.9274 - auc: 0.9803 - val_loss: 0.3260 - val_tp: 878.0000 - val_fp: 126.0000 - val_tn: 877.0000 - val_fn: 125.0000 - val_accuracy: 0.8749 - val_precision: 0.8745 - val_recall: 0.8754 - val_auc: 0.9506\n",
      "1\n",
      "Epoch 1/80\n",
      "89/89 [==============================] - 4s 22ms/step - loss: 0.6359 - tp: 2913.4222 - fp: 1023.4222 - tn: 2890.5111 - fn: 1000.5111 - accuracy: 0.7344 - precision: 0.7339 - recall: 0.7355 - auc: 0.8253 - val_loss: 0.7308 - val_tp: 571.0000 - val_fp: 432.0000 - val_tn: 571.0000 - val_fn: 432.0000 - val_accuracy: 0.5693 - val_precision: 0.5693 - val_recall: 0.5693 - val_auc: 0.6926\n",
      "Epoch 2/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4433 - tp: 2083.2444 - fp: 820.7778 - tn: 2090.1556 - fn: 827.6889 - accuracy: 0.7238 - precision: 0.7247 - recall: 0.7219 - auc: 0.8394 - val_loss: 0.6587 - val_tp: 586.0000 - val_fp: 417.0000 - val_tn: 586.0000 - val_fn: 417.0000 - val_accuracy: 0.5842 - val_precision: 0.5842 - val_recall: 0.5842 - val_auc: 0.7290\n",
      "Epoch 3/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4382 - tp: 2080.7778 - fp: 829.5556 - tn: 2081.3778 - fn: 830.1556 - accuracy: 0.7212 - precision: 0.7212 - recall: 0.7212 - auc: 0.8381 - val_loss: 0.6091 - val_tp: 611.0000 - val_fp: 397.0000 - val_tn: 606.0000 - val_fn: 392.0000 - val_accuracy: 0.6067 - val_precision: 0.6062 - val_recall: 0.6092 - val_auc: 0.7519\n",
      "Epoch 4/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4361 - tp: 2070.1556 - fp: 834.4778 - tn: 2076.4556 - fn: 840.7778 - accuracy: 0.7190 - precision: 0.7192 - recall: 0.7184 - auc: 0.8393 - val_loss: 0.5847 - val_tp: 617.0000 - val_fp: 388.0000 - val_tn: 615.0000 - val_fn: 386.0000 - val_accuracy: 0.6142 - val_precision: 0.6139 - val_recall: 0.6152 - val_auc: 0.7624\n",
      "Epoch 5/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4366 - tp: 2057.3778 - fp: 854.8556 - tn: 2056.0778 - fn: 853.5556 - accuracy: 0.7117 - precision: 0.7114 - recall: 0.7124 - auc: 0.8357 - val_loss: 0.5861 - val_tp: 622.0000 - val_fp: 388.0000 - val_tn: 615.0000 - val_fn: 381.0000 - val_accuracy: 0.6167 - val_precision: 0.6158 - val_recall: 0.6201 - val_auc: 0.7615\n",
      "Epoch 6/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4361 - tp: 2066.9333 - fp: 837.4444 - tn: 2073.4889 - fn: 844.0000 - accuracy: 0.7127 - precision: 0.7133 - recall: 0.7113 - auc: 0.8365 - val_loss: 0.5851 - val_tp: 636.0000 - val_fp: 362.0000 - val_tn: 641.0000 - val_fn: 367.0000 - val_accuracy: 0.6366 - val_precision: 0.6373 - val_recall: 0.6341 - val_auc: 0.7726\n",
      "Epoch 7/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4293 - tp: 2087.7889 - fp: 820.6444 - tn: 2090.2889 - fn: 823.1444 - accuracy: 0.7223 - precision: 0.7224 - recall: 0.7221 - auc: 0.8436 - val_loss: 0.5982 - val_tp: 613.0000 - val_fp: 387.0000 - val_tn: 616.0000 - val_fn: 390.0000 - val_accuracy: 0.6127 - val_precision: 0.6130 - val_recall: 0.6112 - val_auc: 0.7580\n",
      "Epoch 8/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4331 - tp: 2081.8889 - fp: 824.5111 - tn: 2086.4222 - fn: 829.0444 - accuracy: 0.7130 - precision: 0.7133 - recall: 0.7123 - auc: 0.8360 - val_loss: 0.6052 - val_tp: 636.0000 - val_fp: 363.0000 - val_tn: 640.0000 - val_fn: 367.0000 - val_accuracy: 0.6361 - val_precision: 0.6366 - val_recall: 0.6341 - val_auc: 0.7678\n",
      "Epoch 9/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4240 - tp: 2119.1667 - fp: 786.6000 - tn: 2124.3333 - fn: 791.7667 - accuracy: 0.7312 - precision: 0.7314 - recall: 0.7306 - auc: 0.8464 - val_loss: 0.5927 - val_tp: 635.0000 - val_fp: 365.0000 - val_tn: 638.0000 - val_fn: 368.0000 - val_accuracy: 0.6346 - val_precision: 0.6350 - val_recall: 0.6331 - val_auc: 0.7682\n",
      "Epoch 10/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4236 - tp: 2112.1222 - fp: 794.4111 - tn: 2116.5222 - fn: 798.8111 - accuracy: 0.7243 - precision: 0.7245 - recall: 0.7242 - auc: 0.8447 - val_loss: 0.5973 - val_tp: 642.0000 - val_fp: 355.0000 - val_tn: 648.0000 - val_fn: 361.0000 - val_accuracy: 0.6431 - val_precision: 0.6439 - val_recall: 0.6401 - val_auc: 0.7726\n",
      "Epoch 11/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4176 - tp: 2140.0111 - fp: 768.3667 - tn: 2142.5667 - fn: 770.9222 - accuracy: 0.7366 - precision: 0.7369 - recall: 0.7359 - auc: 0.8497 - val_loss: 0.5802 - val_tp: 661.0000 - val_fp: 343.0000 - val_tn: 660.0000 - val_fn: 342.0000 - val_accuracy: 0.6585 - val_precision: 0.6584 - val_recall: 0.6590 - val_auc: 0.7809\n",
      "Epoch 12/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4137 - tp: 2142.4333 - fp: 754.0667 - tn: 2156.8667 - fn: 768.5000 - accuracy: 0.7382 - precision: 0.7396 - recall: 0.7353 - auc: 0.8521 - val_loss: 0.5758 - val_tp: 670.0000 - val_fp: 334.0000 - val_tn: 669.0000 - val_fn: 333.0000 - val_accuracy: 0.6675 - val_precision: 0.6673 - val_recall: 0.6680 - val_auc: 0.7851\n",
      "Epoch 13/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4103 - tp: 2149.7667 - fp: 753.1556 - tn: 2157.7778 - fn: 761.1667 - accuracy: 0.7380 - precision: 0.7385 - recall: 0.7369 - auc: 0.8538 - val_loss: 0.5710 - val_tp: 685.0000 - val_fp: 316.0000 - val_tn: 687.0000 - val_fn: 318.0000 - val_accuracy: 0.6839 - val_precision: 0.6843 - val_recall: 0.6830 - val_auc: 0.7918\n",
      "Epoch 14/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4037 - tp: 2164.8333 - fp: 727.8444 - tn: 2183.0889 - fn: 746.1000 - accuracy: 0.7465 - precision: 0.7482 - recall: 0.7431 - auc: 0.8591 - val_loss: 0.5602 - val_tp: 689.0000 - val_fp: 310.0000 - val_tn: 693.0000 - val_fn: 314.0000 - val_accuracy: 0.6889 - val_precision: 0.6897 - val_recall: 0.6869 - val_auc: 0.7959\n",
      "Epoch 15/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4001 - tp: 2177.0111 - fp: 723.9889 - tn: 2186.9444 - fn: 733.9222 - accuracy: 0.7470 - precision: 0.7480 - recall: 0.7449 - auc: 0.8601 - val_loss: 0.5555 - val_tp: 693.0000 - val_fp: 302.0000 - val_tn: 701.0000 - val_fn: 310.0000 - val_accuracy: 0.6949 - val_precision: 0.6965 - val_recall: 0.6909 - val_auc: 0.8022\n",
      "Epoch 16/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3934 - tp: 2196.7778 - fp: 704.7444 - tn: 2206.1889 - fn: 714.1556 - accuracy: 0.7552 - precision: 0.7563 - recall: 0.7531 - auc: 0.8646 - val_loss: 0.5478 - val_tp: 696.0000 - val_fp: 302.0000 - val_tn: 701.0000 - val_fn: 307.0000 - val_accuracy: 0.6964 - val_precision: 0.6974 - val_recall: 0.6939 - val_auc: 0.8055\n",
      "Epoch 17/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3886 - tp: 2214.3444 - fp: 694.2000 - tn: 2216.7333 - fn: 696.5889 - accuracy: 0.7588 - precision: 0.7590 - recall: 0.7585 - auc: 0.8666 - val_loss: 0.5409 - val_tp: 707.0000 - val_fp: 290.0000 - val_tn: 713.0000 - val_fn: 296.0000 - val_accuracy: 0.7079 - val_precision: 0.7091 - val_recall: 0.7049 - val_auc: 0.8132\n",
      "Epoch 18/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3806 - tp: 2221.7111 - fp: 676.7889 - tn: 2234.1444 - fn: 689.2222 - accuracy: 0.7644 - precision: 0.7656 - recall: 0.7621 - auc: 0.8724 - val_loss: 0.5247 - val_tp: 719.0000 - val_fp: 283.0000 - val_tn: 720.0000 - val_fn: 284.0000 - val_accuracy: 0.7173 - val_precision: 0.7176 - val_recall: 0.7168 - val_auc: 0.8210\n",
      "Epoch 19/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3751 - tp: 2235.2556 - fp: 673.7778 - tn: 2237.1556 - fn: 675.6778 - accuracy: 0.7658 - precision: 0.7660 - recall: 0.7656 - auc: 0.8753 - val_loss: 0.5124 - val_tp: 725.0000 - val_fp: 274.0000 - val_tn: 729.0000 - val_fn: 278.0000 - val_accuracy: 0.7248 - val_precision: 0.7257 - val_recall: 0.7228 - val_auc: 0.8304\n",
      "Epoch 20/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3683 - tp: 2246.7333 - fp: 662.6111 - tn: 2248.3222 - fn: 664.2000 - accuracy: 0.7698 - precision: 0.7700 - recall: 0.7697 - auc: 0.8799 - val_loss: 0.5125 - val_tp: 727.0000 - val_fp: 277.0000 - val_tn: 726.0000 - val_fn: 276.0000 - val_accuracy: 0.7243 - val_precision: 0.7241 - val_recall: 0.7248 - val_auc: 0.8306\n",
      "Epoch 21/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3621 - tp: 2259.9444 - fp: 654.0000 - tn: 2256.9333 - fn: 650.9889 - accuracy: 0.7730 - precision: 0.7724 - recall: 0.7742 - auc: 0.8829 - val_loss: 0.4981 - val_tp: 733.0000 - val_fp: 266.0000 - val_tn: 737.0000 - val_fn: 270.0000 - val_accuracy: 0.7328 - val_precision: 0.7337 - val_recall: 0.7308 - val_auc: 0.8411\n",
      "Epoch 22/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3555 - tp: 2269.6000 - fp: 637.5778 - tn: 2273.3556 - fn: 641.3333 - accuracy: 0.7792 - precision: 0.7790 - recall: 0.7797 - auc: 0.8874 - val_loss: 0.5124 - val_tp: 724.0000 - val_fp: 277.0000 - val_tn: 726.0000 - val_fn: 279.0000 - val_accuracy: 0.7228 - val_precision: 0.7233 - val_recall: 0.7218 - val_auc: 0.8343\n",
      "Epoch 23/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3510 - tp: 2276.9111 - fp: 630.1444 - tn: 2280.7889 - fn: 634.0222 - accuracy: 0.7803 - precision: 0.7803 - recall: 0.7804 - auc: 0.8883 - val_loss: 0.4990 - val_tp: 730.0000 - val_fp: 268.0000 - val_tn: 735.0000 - val_fn: 273.0000 - val_accuracy: 0.7303 - val_precision: 0.7315 - val_recall: 0.7278 - val_auc: 0.8447\n",
      "Epoch 24/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3456 - tp: 2291.4667 - fp: 614.3333 - tn: 2296.6000 - fn: 619.4667 - accuracy: 0.7877 - precision: 0.7881 - recall: 0.7869 - auc: 0.8923 - val_loss: 0.5235 - val_tp: 722.0000 - val_fp: 283.0000 - val_tn: 720.0000 - val_fn: 281.0000 - val_accuracy: 0.7188 - val_precision: 0.7184 - val_recall: 0.7198 - val_auc: 0.8335\n",
      "Epoch 25/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3430 - tp: 2288.0444 - fp: 622.2333 - tn: 2288.7000 - fn: 622.8889 - accuracy: 0.7832 - precision: 0.7827 - recall: 0.7843 - auc: 0.8918 - val_loss: 0.4845 - val_tp: 743.0000 - val_fp: 258.0000 - val_tn: 745.0000 - val_fn: 260.0000 - val_accuracy: 0.7418 - val_precision: 0.7423 - val_recall: 0.7408 - val_auc: 0.8535\n",
      "Epoch 26/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3343 - tp: 2309.1556 - fp: 599.1444 - tn: 2311.7889 - fn: 601.7778 - accuracy: 0.7935 - precision: 0.7939 - recall: 0.7928 - auc: 0.8985 - val_loss: 0.5205 - val_tp: 727.0000 - val_fp: 280.0000 - val_tn: 723.0000 - val_fn: 276.0000 - val_accuracy: 0.7228 - val_precision: 0.7219 - val_recall: 0.7248 - val_auc: 0.8385\n",
      "Epoch 27/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3328 - tp: 2305.1222 - fp: 594.2778 - tn: 2316.6556 - fn: 605.8111 - accuracy: 0.7910 - precision: 0.7924 - recall: 0.7887 - auc: 0.8970 - val_loss: 0.4841 - val_tp: 750.0000 - val_fp: 251.0000 - val_tn: 752.0000 - val_fn: 253.0000 - val_accuracy: 0.7488 - val_precision: 0.7493 - val_recall: 0.7478 - val_auc: 0.8558\n",
      "Epoch 28/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3227 - tp: 2330.2222 - fp: 574.9889 - tn: 2335.9444 - fn: 580.7111 - accuracy: 0.8007 - precision: 0.8015 - recall: 0.7995 - auc: 0.9039 - val_loss: 0.4898 - val_tp: 753.0000 - val_fp: 249.0000 - val_tn: 754.0000 - val_fn: 250.0000 - val_accuracy: 0.7512 - val_precision: 0.7515 - val_recall: 0.7507 - val_auc: 0.8544\n",
      "Epoch 29/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3162 - tp: 2345.6333 - fp: 562.8667 - tn: 2348.0667 - fn: 565.3000 - accuracy: 0.8036 - precision: 0.8037 - recall: 0.8034 - auc: 0.9071 - val_loss: 0.5012 - val_tp: 750.0000 - val_fp: 252.0000 - val_tn: 751.0000 - val_fn: 253.0000 - val_accuracy: 0.7483 - val_precision: 0.7485 - val_recall: 0.7478 - val_auc: 0.8513\n",
      "Epoch 30/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3161 - tp: 2353.2333 - fp: 555.1111 - tn: 2355.8222 - fn: 557.7000 - accuracy: 0.8054 - precision: 0.8056 - recall: 0.8050 - auc: 0.9082 - val_loss: 0.4950 - val_tp: 754.0000 - val_fp: 254.0000 - val_tn: 749.0000 - val_fn: 249.0000 - val_accuracy: 0.7493 - val_precision: 0.7480 - val_recall: 0.7517 - val_auc: 0.8563\n",
      "Epoch 31/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3095 - tp: 2366.7333 - fp: 551.5556 - tn: 2359.3778 - fn: 544.2000 - accuracy: 0.8066 - precision: 0.8057 - recall: 0.8083 - auc: 0.9094 - val_loss: 0.5055 - val_tp: 753.0000 - val_fp: 248.0000 - val_tn: 755.0000 - val_fn: 250.0000 - val_accuracy: 0.7517 - val_precision: 0.7522 - val_recall: 0.7507 - val_auc: 0.8546\n",
      "Epoch 32/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3058 - tp: 2376.9111 - fp: 533.9222 - tn: 2377.0111 - fn: 534.0222 - accuracy: 0.8128 - precision: 0.8130 - recall: 0.8124 - auc: 0.9140 - val_loss: 0.4923 - val_tp: 762.0000 - val_fp: 247.0000 - val_tn: 756.0000 - val_fn: 241.0000 - val_accuracy: 0.7567 - val_precision: 0.7552 - val_recall: 0.7597 - val_auc: 0.8616\n",
      "Epoch 33/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2986 - tp: 2381.5000 - fp: 523.2000 - tn: 2387.7333 - fn: 529.4333 - accuracy: 0.8147 - precision: 0.8152 - recall: 0.8139 - auc: 0.9157 - val_loss: 0.5114 - val_tp: 755.0000 - val_fp: 243.0000 - val_tn: 760.0000 - val_fn: 248.0000 - val_accuracy: 0.7552 - val_precision: 0.7565 - val_recall: 0.7527 - val_auc: 0.8560\n",
      "Epoch 34/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2968 - tp: 2397.7556 - fp: 510.0333 - tn: 2400.9000 - fn: 513.1778 - accuracy: 0.8192 - precision: 0.8198 - recall: 0.8182 - auc: 0.9186 - val_loss: 0.4815 - val_tp: 764.0000 - val_fp: 234.0000 - val_tn: 769.0000 - val_fn: 239.0000 - val_accuracy: 0.7642 - val_precision: 0.7655 - val_recall: 0.7617 - val_auc: 0.8691\n",
      "Epoch 35/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2893 - tp: 2408.9889 - fp: 497.3889 - tn: 2413.5444 - fn: 501.9444 - accuracy: 0.8232 - precision: 0.8234 - recall: 0.8231 - auc: 0.9204 - val_loss: 0.4871 - val_tp: 765.0000 - val_fp: 234.0000 - val_tn: 769.0000 - val_fn: 238.0000 - val_accuracy: 0.7647 - val_precision: 0.7658 - val_recall: 0.7627 - val_auc: 0.8682\n",
      "Epoch 36/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2849 - tp: 2431.3333 - fp: 481.5222 - tn: 2429.4111 - fn: 479.6000 - accuracy: 0.8305 - precision: 0.8303 - recall: 0.8306 - auc: 0.9250 - val_loss: 0.4658 - val_tp: 774.0000 - val_fp: 227.0000 - val_tn: 776.0000 - val_fn: 229.0000 - val_accuracy: 0.7727 - val_precision: 0.7732 - val_recall: 0.7717 - val_auc: 0.8789\n",
      "Epoch 37/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2786 - tp: 2430.8222 - fp: 475.4778 - tn: 2435.4556 - fn: 480.1111 - accuracy: 0.8299 - precision: 0.8303 - recall: 0.8292 - auc: 0.9265 - val_loss: 0.5037 - val_tp: 763.0000 - val_fp: 235.0000 - val_tn: 768.0000 - val_fn: 240.0000 - val_accuracy: 0.7632 - val_precision: 0.7645 - val_recall: 0.7607 - val_auc: 0.8641\n",
      "Epoch 38/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2786 - tp: 2439.6889 - fp: 466.8556 - tn: 2444.0778 - fn: 471.2444 - accuracy: 0.8312 - precision: 0.8316 - recall: 0.8307 - auc: 0.9267 - val_loss: 0.4788 - val_tp: 772.0000 - val_fp: 225.0000 - val_tn: 778.0000 - val_fn: 231.0000 - val_accuracy: 0.7727 - val_precision: 0.7743 - val_recall: 0.7697 - val_auc: 0.8760\n",
      "Epoch 39/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2719 - tp: 2459.4333 - fp: 449.3556 - tn: 2461.5778 - fn: 451.5000 - accuracy: 0.8386 - precision: 0.8390 - recall: 0.8380 - auc: 0.9306 - val_loss: 0.4534 - val_tp: 786.0000 - val_fp: 219.0000 - val_tn: 784.0000 - val_fn: 217.0000 - val_accuracy: 0.7827 - val_precision: 0.7821 - val_recall: 0.7836 - val_auc: 0.8880\n",
      "Epoch 40/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2646 - tp: 2469.5889 - fp: 447.3778 - tn: 2463.5556 - fn: 441.3444 - accuracy: 0.8405 - precision: 0.8396 - recall: 0.8419 - auc: 0.9327 - val_loss: 0.4765 - val_tp: 774.0000 - val_fp: 223.0000 - val_tn: 780.0000 - val_fn: 229.0000 - val_accuracy: 0.7747 - val_precision: 0.7763 - val_recall: 0.7717 - val_auc: 0.8792\n",
      "Epoch 41/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2634 - tp: 2470.1333 - fp: 444.2667 - tn: 2466.6667 - fn: 440.8000 - accuracy: 0.8403 - precision: 0.8401 - recall: 0.8406 - auc: 0.9340 - val_loss: 0.4509 - val_tp: 783.0000 - val_fp: 219.0000 - val_tn: 784.0000 - val_fn: 220.0000 - val_accuracy: 0.7812 - val_precision: 0.7814 - val_recall: 0.7807 - val_auc: 0.8915\n",
      "Epoch 42/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2552 - tp: 2487.2111 - fp: 430.7000 - tn: 2480.2333 - fn: 423.7222 - accuracy: 0.8459 - precision: 0.8448 - recall: 0.8475 - auc: 0.9373 - val_loss: 0.4736 - val_tp: 776.0000 - val_fp: 224.0000 - val_tn: 779.0000 - val_fn: 227.0000 - val_accuracy: 0.7752 - val_precision: 0.7760 - val_recall: 0.7737 - val_auc: 0.8827\n",
      "Epoch 43/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2548 - tp: 2477.8444 - fp: 423.2444 - tn: 2487.6889 - fn: 433.0889 - accuracy: 0.8446 - precision: 0.8460 - recall: 0.8425 - auc: 0.9375 - val_loss: 0.4600 - val_tp: 780.0000 - val_fp: 219.0000 - val_tn: 784.0000 - val_fn: 223.0000 - val_accuracy: 0.7797 - val_precision: 0.7808 - val_recall: 0.7777 - val_auc: 0.8905\n",
      "Epoch 44/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2471 - tp: 2498.1000 - fp: 411.5667 - tn: 2499.3667 - fn: 412.8333 - accuracy: 0.8497 - precision: 0.8499 - recall: 0.8495 - auc: 0.9407 - val_loss: 0.4819 - val_tp: 777.0000 - val_fp: 225.0000 - val_tn: 778.0000 - val_fn: 226.0000 - val_accuracy: 0.7752 - val_precision: 0.7754 - val_recall: 0.7747 - val_auc: 0.8819\n",
      "Epoch 45/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2459 - tp: 2501.5111 - fp: 406.2222 - tn: 2504.7111 - fn: 409.4222 - accuracy: 0.8513 - precision: 0.8518 - recall: 0.8505 - auc: 0.9416 - val_loss: 0.4701 - val_tp: 780.0000 - val_fp: 221.0000 - val_tn: 782.0000 - val_fn: 223.0000 - val_accuracy: 0.7787 - val_precision: 0.7792 - val_recall: 0.7777 - val_auc: 0.8893\n",
      "Epoch 46/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2405 - tp: 2509.7444 - fp: 396.8778 - tn: 2514.0556 - fn: 401.1889 - accuracy: 0.8549 - precision: 0.8560 - recall: 0.8535 - auc: 0.9433 - val_loss: 0.4694 - val_tp: 785.0000 - val_fp: 216.0000 - val_tn: 787.0000 - val_fn: 218.0000 - val_accuracy: 0.7836 - val_precision: 0.7842 - val_recall: 0.7827 - val_auc: 0.8893\n",
      "Epoch 47/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2366 - tp: 2519.7778 - fp: 389.7000 - tn: 2521.2333 - fn: 391.1556 - accuracy: 0.8574 - precision: 0.8578 - recall: 0.8568 - auc: 0.9451 - val_loss: 0.4587 - val_tp: 791.0000 - val_fp: 212.0000 - val_tn: 791.0000 - val_fn: 212.0000 - val_accuracy: 0.7886 - val_precision: 0.7886 - val_recall: 0.7886 - val_auc: 0.8954\n",
      "Epoch 48/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2310 - tp: 2528.7778 - fp: 378.7333 - tn: 2532.2000 - fn: 382.1556 - accuracy: 0.8613 - precision: 0.8618 - recall: 0.8605 - auc: 0.9479 - val_loss: 0.4341 - val_tp: 803.0000 - val_fp: 191.0000 - val_tn: 812.0000 - val_fn: 200.0000 - val_accuracy: 0.8051 - val_precision: 0.8078 - val_recall: 0.8006 - val_auc: 0.9041\n",
      "Epoch 49/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2225 - tp: 2565.0333 - fp: 354.9889 - tn: 2555.9444 - fn: 345.9000 - accuracy: 0.8731 - precision: 0.8724 - recall: 0.8739 - auc: 0.9526 - val_loss: 0.4275 - val_tp: 811.0000 - val_fp: 189.0000 - val_tn: 814.0000 - val_fn: 192.0000 - val_accuracy: 0.8101 - val_precision: 0.8110 - val_recall: 0.8086 - val_auc: 0.9086\n",
      "Epoch 50/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2186 - tp: 2555.5222 - fp: 351.5556 - tn: 2559.3778 - fn: 355.4111 - accuracy: 0.8713 - precision: 0.8717 - recall: 0.8706 - auc: 0.9535 - val_loss: 0.4296 - val_tp: 812.0000 - val_fp: 189.0000 - val_tn: 814.0000 - val_fn: 191.0000 - val_accuracy: 0.8106 - val_precision: 0.8112 - val_recall: 0.8096 - val_auc: 0.9085\n",
      "Epoch 51/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2155 - tp: 2567.1000 - fp: 342.9444 - tn: 2567.9889 - fn: 343.8333 - accuracy: 0.8749 - precision: 0.8751 - recall: 0.8744 - auc: 0.9547 - val_loss: 0.4112 - val_tp: 817.0000 - val_fp: 178.0000 - val_tn: 825.0000 - val_fn: 186.0000 - val_accuracy: 0.8185 - val_precision: 0.8211 - val_recall: 0.8146 - val_auc: 0.9153\n",
      "Epoch 52/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2098 - tp: 2576.4556 - fp: 332.3111 - tn: 2578.6222 - fn: 334.4778 - accuracy: 0.8797 - precision: 0.8801 - recall: 0.8790 - auc: 0.9572 - val_loss: 0.4101 - val_tp: 821.0000 - val_fp: 177.0000 - val_tn: 826.0000 - val_fn: 182.0000 - val_accuracy: 0.8210 - val_precision: 0.8226 - val_recall: 0.8185 - val_auc: 0.9167\n",
      "Epoch 53/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2050 - tp: 2586.8778 - fp: 324.0222 - tn: 2586.9111 - fn: 324.0556 - accuracy: 0.8827 - precision: 0.8831 - recall: 0.8823 - auc: 0.9588 - val_loss: 0.4115 - val_tp: 823.0000 - val_fp: 175.0000 - val_tn: 828.0000 - val_fn: 180.0000 - val_accuracy: 0.8230 - val_precision: 0.8246 - val_recall: 0.8205 - val_auc: 0.9174\n",
      "Epoch 54/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2004 - tp: 2598.6222 - fp: 310.5444 - tn: 2600.3889 - fn: 312.3111 - accuracy: 0.8873 - precision: 0.8877 - recall: 0.8867 - auc: 0.9603 - val_loss: 0.4043 - val_tp: 827.0000 - val_fp: 168.0000 - val_tn: 835.0000 - val_fn: 176.0000 - val_accuracy: 0.8285 - val_precision: 0.8312 - val_recall: 0.8245 - val_auc: 0.9202\n",
      "Epoch 55/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1962 - tp: 2602.8667 - fp: 302.7333 - tn: 2608.2000 - fn: 308.0667 - accuracy: 0.8898 - precision: 0.8906 - recall: 0.8888 - auc: 0.9620 - val_loss: 0.3855 - val_tp: 839.0000 - val_fp: 161.0000 - val_tn: 842.0000 - val_fn: 164.0000 - val_accuracy: 0.8380 - val_precision: 0.8390 - val_recall: 0.8365 - val_auc: 0.9270\n",
      "Epoch 56/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1907 - tp: 2616.9333 - fp: 289.4778 - tn: 2621.4556 - fn: 294.0000 - accuracy: 0.8947 - precision: 0.8955 - recall: 0.8936 - auc: 0.9645 - val_loss: 0.3811 - val_tp: 845.0000 - val_fp: 153.0000 - val_tn: 850.0000 - val_fn: 158.0000 - val_accuracy: 0.8450 - val_precision: 0.8467 - val_recall: 0.8425 - val_auc: 0.9298\n",
      "Epoch 57/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1856 - tp: 2627.6000 - fp: 280.8778 - tn: 2630.0556 - fn: 283.3333 - accuracy: 0.8985 - precision: 0.8990 - recall: 0.8978 - auc: 0.9664 - val_loss: 0.3633 - val_tp: 854.0000 - val_fp: 143.0000 - val_tn: 860.0000 - val_fn: 149.0000 - val_accuracy: 0.8544 - val_precision: 0.8566 - val_recall: 0.8514 - val_auc: 0.9360\n",
      "Epoch 58/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1811 - tp: 2635.7889 - fp: 273.2667 - tn: 2637.6667 - fn: 275.1444 - accuracy: 0.9018 - precision: 0.9024 - recall: 0.9010 - auc: 0.9684 - val_loss: 0.3512 - val_tp: 861.0000 - val_fp: 140.0000 - val_tn: 863.0000 - val_fn: 142.0000 - val_accuracy: 0.8594 - val_precision: 0.8601 - val_recall: 0.8584 - val_auc: 0.9399\n",
      "Epoch 59/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1777 - tp: 2640.3000 - fp: 270.6444 - tn: 2640.2889 - fn: 270.6333 - accuracy: 0.9029 - precision: 0.9033 - recall: 0.9025 - auc: 0.9697 - val_loss: 0.3229 - val_tp: 879.0000 - val_fp: 126.0000 - val_tn: 877.0000 - val_fn: 124.0000 - val_accuracy: 0.8754 - val_precision: 0.8746 - val_recall: 0.8764 - val_auc: 0.9481\n",
      "Epoch 60/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1752 - tp: 2648.5000 - fp: 263.7000 - tn: 2647.2333 - fn: 262.4333 - accuracy: 0.9063 - precision: 0.9059 - recall: 0.9069 - auc: 0.9711 - val_loss: 0.3246 - val_tp: 880.0000 - val_fp: 128.0000 - val_tn: 875.0000 - val_fn: 123.0000 - val_accuracy: 0.8749 - val_precision: 0.8730 - val_recall: 0.8774 - val_auc: 0.9477\n",
      "Epoch 61/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1700 - tp: 2657.4000 - fp: 254.1667 - tn: 2656.7667 - fn: 253.5333 - accuracy: 0.9096 - precision: 0.9092 - recall: 0.9100 - auc: 0.9727 - val_loss: 0.3335 - val_tp: 872.0000 - val_fp: 130.0000 - val_tn: 873.0000 - val_fn: 131.0000 - val_accuracy: 0.8699 - val_precision: 0.8703 - val_recall: 0.8694 - val_auc: 0.9456\n",
      "Epoch 62/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1652 - tp: 2665.6333 - fp: 249.7111 - tn: 2661.2222 - fn: 245.3000 - accuracy: 0.9115 - precision: 0.9102 - recall: 0.9132 - auc: 0.9740 - val_loss: 0.3453 - val_tp: 867.0000 - val_fp: 135.0000 - val_tn: 868.0000 - val_fn: 136.0000 - val_accuracy: 0.8649 - val_precision: 0.8653 - val_recall: 0.8644 - val_auc: 0.9436\n",
      "Epoch 63/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1615 - tp: 2672.0222 - fp: 237.0444 - tn: 2673.8889 - fn: 238.9111 - accuracy: 0.9142 - precision: 0.9142 - recall: 0.9143 - auc: 0.9747 - val_loss: 0.3455 - val_tp: 871.0000 - val_fp: 132.0000 - val_tn: 871.0000 - val_fn: 132.0000 - val_accuracy: 0.8684 - val_precision: 0.8684 - val_recall: 0.8684 - val_auc: 0.9437\n",
      "Epoch 64/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1581 - tp: 2681.8111 - fp: 231.5222 - tn: 2679.4111 - fn: 229.1222 - accuracy: 0.9172 - precision: 0.9166 - recall: 0.9180 - auc: 0.9755 - val_loss: 0.3479 - val_tp: 873.0000 - val_fp: 130.0000 - val_tn: 873.0000 - val_fn: 130.0000 - val_accuracy: 0.8704 - val_precision: 0.8704 - val_recall: 0.8704 - val_auc: 0.9441\n",
      "Epoch 65/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1537 - tp: 2685.7556 - fp: 224.9111 - tn: 2686.0222 - fn: 225.1778 - accuracy: 0.9186 - precision: 0.9187 - recall: 0.9186 - auc: 0.9764 - val_loss: 0.3501 - val_tp: 872.0000 - val_fp: 130.0000 - val_tn: 873.0000 - val_fn: 131.0000 - val_accuracy: 0.8699 - val_precision: 0.8703 - val_recall: 0.8694 - val_auc: 0.9433\n",
      "Epoch 66/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1495 - tp: 2692.1444 - fp: 216.6778 - tn: 2694.2556 - fn: 218.7889 - accuracy: 0.9208 - precision: 0.9209 - recall: 0.9207 - auc: 0.9772 - val_loss: 0.3530 - val_tp: 874.0000 - val_fp: 131.0000 - val_tn: 872.0000 - val_fn: 129.0000 - val_accuracy: 0.8704 - val_precision: 0.8697 - val_recall: 0.8714 - val_auc: 0.9428\n",
      "Epoch 67/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1458 - tp: 2696.5111 - fp: 210.5667 - tn: 2700.3667 - fn: 214.4222 - accuracy: 0.9223 - precision: 0.9229 - recall: 0.9215 - auc: 0.9780 - val_loss: 0.3539 - val_tp: 877.0000 - val_fp: 130.0000 - val_tn: 873.0000 - val_fn: 126.0000 - val_accuracy: 0.8724 - val_precision: 0.8709 - val_recall: 0.8744 - val_auc: 0.9429\n",
      "Epoch 68/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1423 - tp: 2708.1889 - fp: 208.6000 - tn: 2702.3333 - fn: 202.7444 - accuracy: 0.9247 - precision: 0.9235 - recall: 0.9261 - auc: 0.9788 - val_loss: 0.3553 - val_tp: 875.0000 - val_fp: 131.0000 - val_tn: 872.0000 - val_fn: 128.0000 - val_accuracy: 0.8709 - val_precision: 0.8698 - val_recall: 0.8724 - val_auc: 0.9423\n",
      "Epoch 69/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1408 - tp: 2703.2444 - fp: 203.8667 - tn: 2707.0667 - fn: 207.6889 - accuracy: 0.9242 - precision: 0.9246 - recall: 0.9237 - auc: 0.9790 - val_loss: 0.3610 - val_tp: 874.0000 - val_fp: 133.0000 - val_tn: 870.0000 - val_fn: 129.0000 - val_accuracy: 0.8694 - val_precision: 0.8679 - val_recall: 0.8714 - val_auc: 0.9413\n",
      "Epoch 70/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1381 - tp: 2705.7222 - fp: 200.9111 - tn: 2710.0222 - fn: 205.2111 - accuracy: 0.9250 - precision: 0.9255 - recall: 0.9243 - auc: 0.9794 - val_loss: 0.3574 - val_tp: 879.0000 - val_fp: 133.0000 - val_tn: 870.0000 - val_fn: 124.0000 - val_accuracy: 0.8719 - val_precision: 0.8686 - val_recall: 0.8764 - val_auc: 0.9428\n",
      "Epoch 71/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1352 - tp: 2711.7000 - fp: 196.8667 - tn: 2714.0667 - fn: 199.2333 - accuracy: 0.9267 - precision: 0.9268 - recall: 0.9266 - auc: 0.9801 - val_loss: 0.3547 - val_tp: 883.0000 - val_fp: 130.0000 - val_tn: 873.0000 - val_fn: 120.0000 - val_accuracy: 0.8754 - val_precision: 0.8717 - val_recall: 0.8804 - val_auc: 0.9441\n",
      "Epoch 72/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1322 - tp: 2715.2111 - fp: 191.1556 - tn: 2719.7778 - fn: 195.7222 - accuracy: 0.9287 - precision: 0.9288 - recall: 0.9286 - auc: 0.9810 - val_loss: 0.3584 - val_tp: 881.0000 - val_fp: 132.0000 - val_tn: 871.0000 - val_fn: 122.0000 - val_accuracy: 0.8734 - val_precision: 0.8697 - val_recall: 0.8784 - val_auc: 0.9432\n",
      "Epoch 73/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1289 - tp: 2729.9667 - fp: 182.9444 - tn: 2727.9889 - fn: 180.9667 - accuracy: 0.9327 - precision: 0.9321 - recall: 0.9334 - auc: 0.9820 - val_loss: 0.3670 - val_tp: 878.0000 - val_fp: 136.0000 - val_tn: 867.0000 - val_fn: 125.0000 - val_accuracy: 0.8699 - val_precision: 0.8659 - val_recall: 0.8754 - val_auc: 0.9417\n",
      "Epoch 74/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1273 - tp: 2730.0889 - fp: 181.1556 - tn: 2729.7778 - fn: 180.8444 - accuracy: 0.9330 - precision: 0.9327 - recall: 0.9334 - auc: 0.9821 - val_loss: 0.3753 - val_tp: 882.0000 - val_fp: 136.0000 - val_tn: 867.0000 - val_fn: 121.0000 - val_accuracy: 0.8719 - val_precision: 0.8664 - val_recall: 0.8794 - val_auc: 0.9410\n",
      "Epoch 75/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1276 - tp: 2725.0222 - fp: 182.3333 - tn: 2728.6000 - fn: 185.9111 - accuracy: 0.9320 - precision: 0.9325 - recall: 0.9314 - auc: 0.9815 - val_loss: 0.3668 - val_tp: 878.0000 - val_fp: 136.0000 - val_tn: 867.0000 - val_fn: 125.0000 - val_accuracy: 0.8699 - val_precision: 0.8659 - val_recall: 0.8754 - val_auc: 0.9420\n",
      "Epoch 76/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1298 - tp: 2717.4778 - fp: 194.5000 - tn: 2716.4333 - fn: 193.4556 - accuracy: 0.9274 - precision: 0.9271 - recall: 0.9278 - auc: 0.9806 - val_loss: 0.3294 - val_tp: 889.0000 - val_fp: 125.0000 - val_tn: 878.0000 - val_fn: 114.0000 - val_accuracy: 0.8809 - val_precision: 0.8767 - val_recall: 0.8863 - val_auc: 0.9514\n",
      "Epoch 77/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1385 - tp: 2697.1889 - fp: 215.1222 - tn: 2695.8111 - fn: 213.7444 - accuracy: 0.9198 - precision: 0.9193 - recall: 0.9204 - auc: 0.9782 - val_loss: 0.2497 - val_tp: 908.0000 - val_fp: 88.0000 - val_tn: 915.0000 - val_fn: 95.0000 - val_accuracy: 0.9088 - val_precision: 0.9116 - val_recall: 0.9053 - val_auc: 0.9684\n",
      "Epoch 78/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1333 - tp: 2710.1556 - fp: 203.1444 - tn: 2707.7889 - fn: 200.7778 - accuracy: 0.9261 - precision: 0.9260 - recall: 0.9262 - auc: 0.9808 - val_loss: 0.2089 - val_tp: 922.0000 - val_fp: 78.0000 - val_tn: 925.0000 - val_fn: 81.0000 - val_accuracy: 0.9207 - val_precision: 0.9220 - val_recall: 0.9192 - val_auc: 0.9763\n",
      "Epoch 79/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1346 - tp: 2718.7889 - fp: 193.3778 - tn: 2717.5556 - fn: 192.1444 - accuracy: 0.9293 - precision: 0.9292 - recall: 0.9295 - auc: 0.9816 - val_loss: 0.2225 - val_tp: 917.0000 - val_fp: 79.0000 - val_tn: 924.0000 - val_fn: 86.0000 - val_accuracy: 0.9177 - val_precision: 0.9207 - val_recall: 0.9143 - val_auc: 0.9740\n",
      "Epoch 80/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1236 - tp: 2734.4000 - fp: 181.1889 - tn: 2729.7444 - fn: 176.5333 - accuracy: 0.9343 - precision: 0.9335 - recall: 0.9353 - auc: 0.9837 - val_loss: 0.2329 - val_tp: 913.0000 - val_fp: 81.0000 - val_tn: 922.0000 - val_fn: 90.0000 - val_accuracy: 0.9148 - val_precision: 0.9185 - val_recall: 0.9103 - val_auc: 0.9723\n",
      "2\n",
      "Epoch 1/80\n",
      "89/89 [==============================] - 3s 21ms/step - loss: 0.6413 - tp: 2917.1889 - fp: 1057.9889 - tn: 2855.9444 - fn: 996.7444 - accuracy: 0.7372 - precision: 0.7327 - recall: 0.7468 - auc: 0.8386 - val_loss: 0.7693 - val_tp: 543.0000 - val_fp: 466.0000 - val_tn: 537.0000 - val_fn: 460.0000 - val_accuracy: 0.5384 - val_precision: 0.5382 - val_recall: 0.5414 - val_auc: 0.6519\n",
      "Epoch 2/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4519 - tp: 2067.2222 - fp: 837.3556 - tn: 2073.5778 - fn: 843.7111 - accuracy: 0.7155 - precision: 0.7160 - recall: 0.7143 - auc: 0.8318 - val_loss: 0.6157 - val_tp: 613.0000 - val_fp: 393.0000 - val_tn: 610.0000 - val_fn: 390.0000 - val_accuracy: 0.6097 - val_precision: 0.6093 - val_recall: 0.6112 - val_auc: 0.7460\n",
      "Epoch 3/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4475 - tp: 2064.1222 - fp: 845.2444 - tn: 2065.6889 - fn: 846.8111 - accuracy: 0.7165 - precision: 0.7163 - recall: 0.7172 - auc: 0.8317 - val_loss: 0.5912 - val_tp: 616.0000 - val_fp: 387.0000 - val_tn: 616.0000 - val_fn: 387.0000 - val_accuracy: 0.6142 - val_precision: 0.6142 - val_recall: 0.6142 - val_auc: 0.7568\n",
      "Epoch 4/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4477 - tp: 2066.8778 - fp: 841.6889 - tn: 2069.2444 - fn: 844.0556 - accuracy: 0.7129 - precision: 0.7128 - recall: 0.7134 - auc: 0.8318 - val_loss: 0.6089 - val_tp: 624.0000 - val_fp: 380.0000 - val_tn: 623.0000 - val_fn: 379.0000 - val_accuracy: 0.6216 - val_precision: 0.6215 - val_recall: 0.6221 - val_auc: 0.7574\n",
      "Epoch 5/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4444 - tp: 2076.0111 - fp: 835.6444 - tn: 2075.2889 - fn: 834.9222 - accuracy: 0.7148 - precision: 0.7144 - recall: 0.7156 - auc: 0.8336 - val_loss: 0.6047 - val_tp: 630.0000 - val_fp: 373.0000 - val_tn: 630.0000 - val_fn: 373.0000 - val_accuracy: 0.6281 - val_precision: 0.6281 - val_recall: 0.6281 - val_auc: 0.7626\n",
      "Epoch 6/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4385 - tp: 2101.1333 - fp: 805.7111 - tn: 2105.2222 - fn: 809.8000 - accuracy: 0.7238 - precision: 0.7241 - recall: 0.7232 - auc: 0.8385 - val_loss: 0.5906 - val_tp: 646.0000 - val_fp: 362.0000 - val_tn: 641.0000 - val_fn: 357.0000 - val_accuracy: 0.6416 - val_precision: 0.6409 - val_recall: 0.6441 - val_auc: 0.7734\n",
      "Epoch 7/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4318 - tp: 2115.0111 - fp: 795.2111 - tn: 2115.7222 - fn: 795.9222 - accuracy: 0.7290 - precision: 0.7289 - recall: 0.7293 - auc: 0.8443 - val_loss: 0.5835 - val_tp: 653.0000 - val_fp: 347.0000 - val_tn: 656.0000 - val_fn: 350.0000 - val_accuracy: 0.6525 - val_precision: 0.6530 - val_recall: 0.6510 - val_auc: 0.7791\n",
      "Epoch 8/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4276 - tp: 2123.7444 - fp: 785.8667 - tn: 2125.0667 - fn: 787.1889 - accuracy: 0.7310 - precision: 0.7310 - recall: 0.7308 - auc: 0.8462 - val_loss: 0.5700 - val_tp: 675.0000 - val_fp: 329.0000 - val_tn: 674.0000 - val_fn: 328.0000 - val_accuracy: 0.6725 - val_precision: 0.6723 - val_recall: 0.6730 - val_auc: 0.7904\n",
      "Epoch 9/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4175 - tp: 2160.9667 - fp: 755.5556 - tn: 2155.3778 - fn: 749.9667 - accuracy: 0.7430 - precision: 0.7423 - recall: 0.7445 - auc: 0.8547 - val_loss: 0.5591 - val_tp: 685.0000 - val_fp: 315.0000 - val_tn: 688.0000 - val_fn: 318.0000 - val_accuracy: 0.6844 - val_precision: 0.6850 - val_recall: 0.6830 - val_auc: 0.7972\n",
      "Epoch 10/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4128 - tp: 2170.3222 - fp: 745.2667 - tn: 2165.6667 - fn: 740.6111 - accuracy: 0.7444 - precision: 0.7439 - recall: 0.7455 - auc: 0.8571 - val_loss: 0.5460 - val_tp: 706.0000 - val_fp: 300.0000 - val_tn: 703.0000 - val_fn: 297.0000 - val_accuracy: 0.7024 - val_precision: 0.7018 - val_recall: 0.7039 - val_auc: 0.8079\n",
      "Epoch 11/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4035 - tp: 2191.2444 - fp: 723.0889 - tn: 2187.8444 - fn: 719.6889 - accuracy: 0.7525 - precision: 0.7519 - recall: 0.7538 - auc: 0.8643 - val_loss: 0.5529 - val_tp: 709.0000 - val_fp: 301.0000 - val_tn: 702.0000 - val_fn: 294.0000 - val_accuracy: 0.7034 - val_precision: 0.7020 - val_recall: 0.7069 - val_auc: 0.8078\n",
      "Epoch 12/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3970 - tp: 2202.4667 - fp: 708.1778 - tn: 2202.7556 - fn: 708.4667 - accuracy: 0.7561 - precision: 0.7558 - recall: 0.7568 - auc: 0.8677 - val_loss: 0.5312 - val_tp: 717.0000 - val_fp: 287.0000 - val_tn: 716.0000 - val_fn: 286.0000 - val_accuracy: 0.7144 - val_precision: 0.7141 - val_recall: 0.7149 - val_auc: 0.8208\n",
      "Epoch 13/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3888 - tp: 2228.0889 - fp: 682.6111 - tn: 2228.3222 - fn: 682.8444 - accuracy: 0.7658 - precision: 0.7657 - recall: 0.7660 - auc: 0.8738 - val_loss: 0.5321 - val_tp: 721.0000 - val_fp: 287.0000 - val_tn: 716.0000 - val_fn: 282.0000 - val_accuracy: 0.7164 - val_precision: 0.7153 - val_recall: 0.7188 - val_auc: 0.8231\n",
      "Epoch 14/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3833 - tp: 2237.6333 - fp: 680.0111 - tn: 2230.9222 - fn: 673.3000 - accuracy: 0.7675 - precision: 0.7665 - recall: 0.7695 - auc: 0.8763 - val_loss: 0.5256 - val_tp: 727.0000 - val_fp: 280.0000 - val_tn: 723.0000 - val_fn: 276.0000 - val_accuracy: 0.7228 - val_precision: 0.7219 - val_recall: 0.7248 - val_auc: 0.8292\n",
      "Epoch 15/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3762 - tp: 2253.0556 - fp: 664.4000 - tn: 2246.5333 - fn: 657.8778 - accuracy: 0.7736 - precision: 0.7726 - recall: 0.7756 - auc: 0.8804 - val_loss: 0.5200 - val_tp: 731.0000 - val_fp: 274.0000 - val_tn: 729.0000 - val_fn: 272.0000 - val_accuracy: 0.7278 - val_precision: 0.7274 - val_recall: 0.7288 - val_auc: 0.8337\n",
      "Epoch 16/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3717 - tp: 2260.9667 - fp: 650.7889 - tn: 2260.1444 - fn: 649.9667 - accuracy: 0.7775 - precision: 0.7770 - recall: 0.7785 - auc: 0.8823 - val_loss: 0.5151 - val_tp: 739.0000 - val_fp: 272.0000 - val_tn: 731.0000 - val_fn: 264.0000 - val_accuracy: 0.7328 - val_precision: 0.7310 - val_recall: 0.7368 - val_auc: 0.8382\n",
      "Epoch 17/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3657 - tp: 2278.3000 - fp: 639.9556 - tn: 2270.9778 - fn: 632.6333 - accuracy: 0.7822 - precision: 0.7811 - recall: 0.7841 - auc: 0.8854 - val_loss: 0.5202 - val_tp: 738.0000 - val_fp: 269.0000 - val_tn: 734.0000 - val_fn: 265.0000 - val_accuracy: 0.7338 - val_precision: 0.7329 - val_recall: 0.7358 - val_auc: 0.8369\n",
      "Epoch 18/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3608 - tp: 2292.7111 - fp: 625.4000 - tn: 2285.5333 - fn: 618.2222 - accuracy: 0.7866 - precision: 0.7855 - recall: 0.7886 - auc: 0.8866 - val_loss: 0.5144 - val_tp: 740.0000 - val_fp: 264.0000 - val_tn: 739.0000 - val_fn: 263.0000 - val_accuracy: 0.7373 - val_precision: 0.7371 - val_recall: 0.7378 - val_auc: 0.8418\n",
      "Epoch 19/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3561 - tp: 2299.4556 - fp: 617.2778 - tn: 2293.6556 - fn: 611.4778 - accuracy: 0.7879 - precision: 0.7871 - recall: 0.7893 - auc: 0.8889 - val_loss: 0.5058 - val_tp: 745.0000 - val_fp: 262.0000 - val_tn: 741.0000 - val_fn: 258.0000 - val_accuracy: 0.7408 - val_precision: 0.7398 - val_recall: 0.7428 - val_auc: 0.8474\n",
      "Epoch 20/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3497 - tp: 2310.3000 - fp: 608.2333 - tn: 2302.7000 - fn: 600.6333 - accuracy: 0.7907 - precision: 0.7896 - recall: 0.7927 - auc: 0.8925 - val_loss: 0.5054 - val_tp: 747.0000 - val_fp: 259.0000 - val_tn: 744.0000 - val_fn: 256.0000 - val_accuracy: 0.7433 - val_precision: 0.7425 - val_recall: 0.7448 - val_auc: 0.8488\n",
      "Epoch 21/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3454 - tp: 2316.9444 - fp: 602.5778 - tn: 2308.3556 - fn: 593.9889 - accuracy: 0.7918 - precision: 0.7907 - recall: 0.7936 - auc: 0.8940 - val_loss: 0.5066 - val_tp: 745.0000 - val_fp: 258.0000 - val_tn: 745.0000 - val_fn: 258.0000 - val_accuracy: 0.7428 - val_precision: 0.7428 - val_recall: 0.7428 - val_auc: 0.8497\n",
      "Epoch 22/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3405 - tp: 2322.2333 - fp: 594.4333 - tn: 2316.5000 - fn: 588.7000 - accuracy: 0.7932 - precision: 0.7926 - recall: 0.7943 - auc: 0.8959 - val_loss: 0.5009 - val_tp: 749.0000 - val_fp: 254.0000 - val_tn: 749.0000 - val_fn: 254.0000 - val_accuracy: 0.7468 - val_precision: 0.7468 - val_recall: 0.7468 - val_auc: 0.8541\n",
      "Epoch 23/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3357 - tp: 2336.2333 - fp: 583.3111 - tn: 2327.6222 - fn: 574.7000 - accuracy: 0.7968 - precision: 0.7957 - recall: 0.7988 - auc: 0.8982 - val_loss: 0.4943 - val_tp: 755.0000 - val_fp: 249.0000 - val_tn: 754.0000 - val_fn: 248.0000 - val_accuracy: 0.7522 - val_precision: 0.7520 - val_recall: 0.7527 - val_auc: 0.8584\n",
      "Epoch 24/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3299 - tp: 2347.5111 - fp: 569.1556 - tn: 2341.7778 - fn: 563.4222 - accuracy: 0.8009 - precision: 0.7998 - recall: 0.8026 - auc: 0.9015 - val_loss: 0.4944 - val_tp: 759.0000 - val_fp: 243.0000 - val_tn: 760.0000 - val_fn: 244.0000 - val_accuracy: 0.7572 - val_precision: 0.7575 - val_recall: 0.7567 - val_auc: 0.8601\n",
      "Epoch 25/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3251 - tp: 2354.0778 - fp: 559.9667 - tn: 2350.9667 - fn: 556.8556 - accuracy: 0.8027 - precision: 0.8021 - recall: 0.8036 - auc: 0.9033 - val_loss: 0.4930 - val_tp: 760.0000 - val_fp: 237.0000 - val_tn: 766.0000 - val_fn: 243.0000 - val_accuracy: 0.7607 - val_precision: 0.7623 - val_recall: 0.7577 - val_auc: 0.8618\n",
      "Epoch 26/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3196 - tp: 2368.4556 - fp: 548.8222 - tn: 2362.1111 - fn: 542.4778 - accuracy: 0.8063 - precision: 0.8055 - recall: 0.8078 - auc: 0.9060 - val_loss: 0.4897 - val_tp: 769.0000 - val_fp: 231.0000 - val_tn: 772.0000 - val_fn: 234.0000 - val_accuracy: 0.7682 - val_precision: 0.7690 - val_recall: 0.7667 - val_auc: 0.8649\n",
      "Epoch 27/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3146 - tp: 2380.9667 - fp: 533.1000 - tn: 2377.8333 - fn: 529.9667 - accuracy: 0.8102 - precision: 0.8095 - recall: 0.8116 - auc: 0.9086 - val_loss: 0.4867 - val_tp: 774.0000 - val_fp: 227.0000 - val_tn: 776.0000 - val_fn: 229.0000 - val_accuracy: 0.7727 - val_precision: 0.7732 - val_recall: 0.7717 - val_auc: 0.8680\n",
      "Epoch 28/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3087 - tp: 2396.0333 - fp: 518.7333 - tn: 2392.2000 - fn: 514.9000 - accuracy: 0.8154 - precision: 0.8149 - recall: 0.8162 - auc: 0.9117 - val_loss: 0.4832 - val_tp: 774.0000 - val_fp: 229.0000 - val_tn: 774.0000 - val_fn: 229.0000 - val_accuracy: 0.7717 - val_precision: 0.7717 - val_recall: 0.7717 - val_auc: 0.8705\n",
      "Epoch 29/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3038 - tp: 2403.0222 - fp: 507.8444 - tn: 2403.0889 - fn: 507.9111 - accuracy: 0.8178 - precision: 0.8177 - recall: 0.8180 - auc: 0.9139 - val_loss: 0.4706 - val_tp: 775.0000 - val_fp: 228.0000 - val_tn: 775.0000 - val_fn: 228.0000 - val_accuracy: 0.7727 - val_precision: 0.7727 - val_recall: 0.7727 - val_auc: 0.8777\n",
      "Epoch 30/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2968 - tp: 2419.8000 - fp: 489.7778 - tn: 2421.1556 - fn: 491.1333 - accuracy: 0.8240 - precision: 0.8239 - recall: 0.8242 - auc: 0.9183 - val_loss: 0.4779 - val_tp: 774.0000 - val_fp: 231.0000 - val_tn: 772.0000 - val_fn: 229.0000 - val_accuracy: 0.7707 - val_precision: 0.7701 - val_recall: 0.7717 - val_auc: 0.8753\n",
      "Epoch 31/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2933 - tp: 2425.7778 - fp: 481.3111 - tn: 2429.6222 - fn: 485.1556 - accuracy: 0.8252 - precision: 0.8254 - recall: 0.8248 - auc: 0.9192 - val_loss: 0.4694 - val_tp: 776.0000 - val_fp: 227.0000 - val_tn: 776.0000 - val_fn: 227.0000 - val_accuracy: 0.7737 - val_precision: 0.7737 - val_recall: 0.7737 - val_auc: 0.8803\n",
      "Epoch 32/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2874 - tp: 2439.4111 - fp: 467.8333 - tn: 2443.1000 - fn: 471.5222 - accuracy: 0.8301 - precision: 0.8304 - recall: 0.8295 - auc: 0.9224 - val_loss: 0.4769 - val_tp: 774.0000 - val_fp: 231.0000 - val_tn: 772.0000 - val_fn: 229.0000 - val_accuracy: 0.7707 - val_precision: 0.7701 - val_recall: 0.7717 - val_auc: 0.8791\n",
      "Epoch 33/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2833 - tp: 2451.4444 - fp: 456.5667 - tn: 2454.3667 - fn: 459.4889 - accuracy: 0.8334 - precision: 0.8337 - recall: 0.8331 - auc: 0.9242 - val_loss: 0.4658 - val_tp: 776.0000 - val_fp: 226.0000 - val_tn: 777.0000 - val_fn: 227.0000 - val_accuracy: 0.7742 - val_precision: 0.7745 - val_recall: 0.7737 - val_auc: 0.8845\n",
      "Epoch 34/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2777 - tp: 2457.7222 - fp: 446.1778 - tn: 2464.7556 - fn: 453.2111 - accuracy: 0.8360 - precision: 0.8365 - recall: 0.8353 - auc: 0.9271 - val_loss: 0.4648 - val_tp: 778.0000 - val_fp: 221.0000 - val_tn: 782.0000 - val_fn: 225.0000 - val_accuracy: 0.7777 - val_precision: 0.7788 - val_recall: 0.7757 - val_auc: 0.8860\n",
      "Epoch 35/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2726 - tp: 2473.9556 - fp: 438.0222 - tn: 2472.9111 - fn: 436.9778 - accuracy: 0.8397 - precision: 0.8392 - recall: 0.8404 - auc: 0.9299 - val_loss: 0.4727 - val_tp: 781.0000 - val_fp: 218.0000 - val_tn: 785.0000 - val_fn: 222.0000 - val_accuracy: 0.7807 - val_precision: 0.7818 - val_recall: 0.7787 - val_auc: 0.8843\n",
      "Epoch 36/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2687 - tp: 2480.4222 - fp: 420.5222 - tn: 2490.4111 - fn: 430.5111 - accuracy: 0.8432 - precision: 0.8441 - recall: 0.8420 - auc: 0.9315 - val_loss: 0.4627 - val_tp: 782.0000 - val_fp: 214.0000 - val_tn: 789.0000 - val_fn: 221.0000 - val_accuracy: 0.7832 - val_precision: 0.7851 - val_recall: 0.7797 - val_auc: 0.8897\n",
      "Epoch 37/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2631 - tp: 2495.4444 - fp: 413.4444 - tn: 2497.4889 - fn: 415.4889 - accuracy: 0.8474 - precision: 0.8474 - recall: 0.8475 - auc: 0.9346 - val_loss: 0.4665 - val_tp: 785.0000 - val_fp: 215.0000 - val_tn: 788.0000 - val_fn: 218.0000 - val_accuracy: 0.7841 - val_precision: 0.7850 - val_recall: 0.7827 - val_auc: 0.8893\n",
      "Epoch 38/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2593 - tp: 2505.7889 - fp: 406.1111 - tn: 2504.8222 - fn: 405.1444 - accuracy: 0.8502 - precision: 0.8498 - recall: 0.8507 - auc: 0.9362 - val_loss: 0.4491 - val_tp: 789.0000 - val_fp: 212.0000 - val_tn: 791.0000 - val_fn: 214.0000 - val_accuracy: 0.7876 - val_precision: 0.7882 - val_recall: 0.7866 - val_auc: 0.8968\n",
      "Epoch 39/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2533 - tp: 2517.6556 - fp: 394.6333 - tn: 2516.3000 - fn: 393.2778 - accuracy: 0.8541 - precision: 0.8540 - recall: 0.8543 - auc: 0.9393 - val_loss: 0.4508 - val_tp: 792.0000 - val_fp: 214.0000 - val_tn: 789.0000 - val_fn: 211.0000 - val_accuracy: 0.7881 - val_precision: 0.7873 - val_recall: 0.7896 - val_auc: 0.8973\n",
      "Epoch 40/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2496 - tp: 2524.4333 - fp: 384.6444 - tn: 2526.2889 - fn: 386.5000 - accuracy: 0.8570 - precision: 0.8572 - recall: 0.8569 - auc: 0.9407 - val_loss: 0.4449 - val_tp: 795.0000 - val_fp: 211.0000 - val_tn: 792.0000 - val_fn: 208.0000 - val_accuracy: 0.7911 - val_precision: 0.7903 - val_recall: 0.7926 - val_auc: 0.9003\n",
      "Epoch 41/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2448 - tp: 2540.2667 - fp: 376.3222 - tn: 2534.6111 - fn: 370.6667 - accuracy: 0.8611 - precision: 0.8604 - recall: 0.8621 - auc: 0.9429 - val_loss: 0.4404 - val_tp: 797.0000 - val_fp: 206.0000 - val_tn: 797.0000 - val_fn: 206.0000 - val_accuracy: 0.7946 - val_precision: 0.7946 - val_recall: 0.7946 - val_auc: 0.9029\n",
      "Epoch 42/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2404 - tp: 2542.9667 - fp: 371.1556 - tn: 2539.7778 - fn: 367.9667 - accuracy: 0.8625 - precision: 0.8618 - recall: 0.8634 - auc: 0.9448 - val_loss: 0.4289 - val_tp: 804.0000 - val_fp: 202.0000 - val_tn: 801.0000 - val_fn: 199.0000 - val_accuracy: 0.8001 - val_precision: 0.7992 - val_recall: 0.8016 - val_auc: 0.9079\n",
      "Epoch 43/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2355 - tp: 2551.0556 - fp: 357.3444 - tn: 2553.5889 - fn: 359.8778 - accuracy: 0.8668 - precision: 0.8672 - recall: 0.8661 - auc: 0.9472 - val_loss: 0.4212 - val_tp: 813.0000 - val_fp: 197.0000 - val_tn: 806.0000 - val_fn: 190.0000 - val_accuracy: 0.8071 - val_precision: 0.8050 - val_recall: 0.8106 - val_auc: 0.9113\n",
      "Epoch 44/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2309 - tp: 2561.3667 - fp: 347.9222 - tn: 2563.0111 - fn: 349.5667 - accuracy: 0.8708 - precision: 0.8707 - recall: 0.8710 - auc: 0.9492 - val_loss: 0.4177 - val_tp: 815.0000 - val_fp: 193.0000 - val_tn: 810.0000 - val_fn: 188.0000 - val_accuracy: 0.8101 - val_precision: 0.8085 - val_recall: 0.8126 - val_auc: 0.9134\n",
      "Epoch 45/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2264 - tp: 2567.6444 - fp: 339.7556 - tn: 2571.1778 - fn: 343.2889 - accuracy: 0.8736 - precision: 0.8741 - recall: 0.8730 - auc: 0.9513 - val_loss: 0.4118 - val_tp: 820.0000 - val_fp: 192.0000 - val_tn: 811.0000 - val_fn: 183.0000 - val_accuracy: 0.8131 - val_precision: 0.8103 - val_recall: 0.8175 - val_auc: 0.9156\n",
      "Epoch 46/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.2225 - tp: 2575.8222 - fp: 334.2667 - tn: 2576.6667 - fn: 335.1111 - accuracy: 0.8760 - precision: 0.8760 - recall: 0.8761 - auc: 0.9527 - val_loss: 0.4066 - val_tp: 822.0000 - val_fp: 191.0000 - val_tn: 812.0000 - val_fn: 181.0000 - val_accuracy: 0.8146 - val_precision: 0.8115 - val_recall: 0.8195 - val_auc: 0.9180\n",
      "Epoch 47/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2184 - tp: 2581.4889 - fp: 325.6333 - tn: 2585.3000 - fn: 329.4444 - accuracy: 0.8786 - precision: 0.8791 - recall: 0.8781 - auc: 0.9544 - val_loss: 0.4013 - val_tp: 825.0000 - val_fp: 184.0000 - val_tn: 819.0000 - val_fn: 178.0000 - val_accuracy: 0.8195 - val_precision: 0.8176 - val_recall: 0.8225 - val_auc: 0.9205\n",
      "Epoch 48/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2145 - tp: 2590.7889 - fp: 318.6778 - tn: 2592.2556 - fn: 320.1444 - accuracy: 0.8821 - precision: 0.8820 - recall: 0.8822 - auc: 0.9560 - val_loss: 0.4076 - val_tp: 824.0000 - val_fp: 189.0000 - val_tn: 814.0000 - val_fn: 179.0000 - val_accuracy: 0.8166 - val_precision: 0.8134 - val_recall: 0.8215 - val_auc: 0.9189\n",
      "Epoch 49/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2113 - tp: 2598.2667 - fp: 313.9333 - tn: 2597.0000 - fn: 312.6667 - accuracy: 0.8839 - precision: 0.8836 - recall: 0.8842 - auc: 0.9571 - val_loss: 0.3996 - val_tp: 831.0000 - val_fp: 182.0000 - val_tn: 821.0000 - val_fn: 172.0000 - val_accuracy: 0.8235 - val_precision: 0.8203 - val_recall: 0.8285 - val_auc: 0.9221\n",
      "Epoch 50/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2074 - tp: 2604.2111 - fp: 309.0333 - tn: 2601.9000 - fn: 306.7222 - accuracy: 0.8861 - precision: 0.8856 - recall: 0.8868 - auc: 0.9588 - val_loss: 0.4027 - val_tp: 829.0000 - val_fp: 182.0000 - val_tn: 821.0000 - val_fn: 174.0000 - val_accuracy: 0.8225 - val_precision: 0.8200 - val_recall: 0.8265 - val_auc: 0.9217\n",
      "Epoch 51/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2036 - tp: 2610.4000 - fp: 304.3222 - tn: 2606.6111 - fn: 300.5333 - accuracy: 0.8878 - precision: 0.8868 - recall: 0.8891 - auc: 0.9602 - val_loss: 0.3986 - val_tp: 829.0000 - val_fp: 180.0000 - val_tn: 823.0000 - val_fn: 174.0000 - val_accuracy: 0.8235 - val_precision: 0.8216 - val_recall: 0.8265 - val_auc: 0.9241\n",
      "Epoch 52/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2002 - tp: 2614.7889 - fp: 294.2000 - tn: 2616.7333 - fn: 296.1444 - accuracy: 0.8906 - precision: 0.8905 - recall: 0.8908 - auc: 0.9614 - val_loss: 0.3913 - val_tp: 832.0000 - val_fp: 176.0000 - val_tn: 827.0000 - val_fn: 171.0000 - val_accuracy: 0.8270 - val_precision: 0.8254 - val_recall: 0.8295 - val_auc: 0.9269\n",
      "Epoch 53/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1963 - tp: 2621.3667 - fp: 291.2333 - tn: 2619.7000 - fn: 289.5667 - accuracy: 0.8928 - precision: 0.8922 - recall: 0.8936 - auc: 0.9629 - val_loss: 0.3898 - val_tp: 835.0000 - val_fp: 172.0000 - val_tn: 831.0000 - val_fn: 168.0000 - val_accuracy: 0.8305 - val_precision: 0.8292 - val_recall: 0.8325 - val_auc: 0.9281\n",
      "Epoch 54/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1922 - tp: 2633.7444 - fp: 279.6667 - tn: 2631.2667 - fn: 277.1889 - accuracy: 0.8966 - precision: 0.8959 - recall: 0.8974 - auc: 0.9642 - val_loss: 0.3717 - val_tp: 843.0000 - val_fp: 160.0000 - val_tn: 843.0000 - val_fn: 160.0000 - val_accuracy: 0.8405 - val_precision: 0.8405 - val_recall: 0.8405 - val_auc: 0.9342\n",
      "Epoch 55/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1885 - tp: 2636.4000 - fp: 279.6000 - tn: 2631.3333 - fn: 274.5333 - accuracy: 0.8970 - precision: 0.8961 - recall: 0.8982 - auc: 0.9657 - val_loss: 0.3770 - val_tp: 843.0000 - val_fp: 165.0000 - val_tn: 838.0000 - val_fn: 160.0000 - val_accuracy: 0.8380 - val_precision: 0.8363 - val_recall: 0.8405 - val_auc: 0.9333\n",
      "Epoch 56/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1852 - tp: 2640.3111 - fp: 270.2111 - tn: 2640.7222 - fn: 270.6222 - accuracy: 0.8992 - precision: 0.8993 - recall: 0.8991 - auc: 0.9667 - val_loss: 0.3672 - val_tp: 844.0000 - val_fp: 156.0000 - val_tn: 847.0000 - val_fn: 159.0000 - val_accuracy: 0.8430 - val_precision: 0.8440 - val_recall: 0.8415 - val_auc: 0.9367\n",
      "Epoch 57/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1810 - tp: 2645.8222 - fp: 261.5778 - tn: 2649.3556 - fn: 265.1111 - accuracy: 0.9020 - precision: 0.9024 - recall: 0.9015 - auc: 0.9682 - val_loss: 0.3608 - val_tp: 849.0000 - val_fp: 153.0000 - val_tn: 850.0000 - val_fn: 154.0000 - val_accuracy: 0.8470 - val_precision: 0.8473 - val_recall: 0.8465 - val_auc: 0.9393\n",
      "Epoch 58/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1776 - tp: 2649.3556 - fp: 259.6333 - tn: 2651.3000 - fn: 261.5778 - accuracy: 0.9032 - precision: 0.9034 - recall: 0.9029 - auc: 0.9692 - val_loss: 0.3595 - val_tp: 850.0000 - val_fp: 152.0000 - val_tn: 851.0000 - val_fn: 153.0000 - val_accuracy: 0.8480 - val_precision: 0.8483 - val_recall: 0.8475 - val_auc: 0.9400\n",
      "Epoch 59/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1736 - tp: 2650.4667 - fp: 254.4222 - tn: 2656.5111 - fn: 260.4667 - accuracy: 0.9044 - precision: 0.9050 - recall: 0.9037 - auc: 0.9705 - val_loss: 0.3540 - val_tp: 851.0000 - val_fp: 148.0000 - val_tn: 855.0000 - val_fn: 152.0000 - val_accuracy: 0.8504 - val_precision: 0.8519 - val_recall: 0.8485 - val_auc: 0.9422\n",
      "Epoch 60/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1697 - tp: 2655.7556 - fp: 251.5000 - tn: 2659.4333 - fn: 255.1778 - accuracy: 0.9057 - precision: 0.9059 - recall: 0.9056 - auc: 0.9719 - val_loss: 0.3607 - val_tp: 851.0000 - val_fp: 149.0000 - val_tn: 854.0000 - val_fn: 152.0000 - val_accuracy: 0.8500 - val_precision: 0.8510 - val_recall: 0.8485 - val_auc: 0.9413\n",
      "Epoch 61/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.1663 - tp: 2661.1778 - fp: 246.5667 - tn: 2664.3667 - fn: 249.7556 - accuracy: 0.9075 - precision: 0.9075 - recall: 0.9075 - auc: 0.9727 - val_loss: 0.3628 - val_tp: 852.0000 - val_fp: 147.0000 - val_tn: 856.0000 - val_fn: 151.0000 - val_accuracy: 0.8514 - val_precision: 0.8529 - val_recall: 0.8495 - val_auc: 0.9412\n",
      "Epoch 62/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1632 - tp: 2666.2556 - fp: 241.7000 - tn: 2669.2333 - fn: 244.6778 - accuracy: 0.9090 - precision: 0.9090 - recall: 0.9091 - auc: 0.9736 - val_loss: 0.3762 - val_tp: 846.0000 - val_fp: 154.0000 - val_tn: 849.0000 - val_fn: 157.0000 - val_accuracy: 0.8450 - val_precision: 0.8460 - val_recall: 0.8435 - val_auc: 0.9376\n",
      "Epoch 63/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1596 - tp: 2672.8889 - fp: 236.1667 - tn: 2674.7667 - fn: 238.0444 - accuracy: 0.9112 - precision: 0.9110 - recall: 0.9115 - auc: 0.9743 - val_loss: 0.3764 - val_tp: 846.0000 - val_fp: 155.0000 - val_tn: 848.0000 - val_fn: 157.0000 - val_accuracy: 0.8445 - val_precision: 0.8452 - val_recall: 0.8435 - val_auc: 0.9380\n",
      "Epoch 64/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1554 - tp: 2679.2444 - fp: 228.1000 - tn: 2682.8333 - fn: 231.6889 - accuracy: 0.9134 - precision: 0.9135 - recall: 0.9133 - auc: 0.9754 - val_loss: 0.3670 - val_tp: 853.0000 - val_fp: 146.0000 - val_tn: 857.0000 - val_fn: 150.0000 - val_accuracy: 0.8524 - val_precision: 0.8539 - val_recall: 0.8504 - val_auc: 0.9412\n",
      "Epoch 65/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1510 - tp: 2686.9222 - fp: 223.2778 - tn: 2687.6556 - fn: 224.0111 - accuracy: 0.9159 - precision: 0.9159 - recall: 0.9160 - auc: 0.9766 - val_loss: 0.3626 - val_tp: 853.0000 - val_fp: 140.0000 - val_tn: 863.0000 - val_fn: 150.0000 - val_accuracy: 0.8554 - val_precision: 0.8590 - val_recall: 0.8504 - val_auc: 0.9429\n",
      "Epoch 66/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1473 - tp: 2691.7111 - fp: 219.6000 - tn: 2691.3333 - fn: 219.2222 - accuracy: 0.9174 - precision: 0.9172 - recall: 0.9176 - auc: 0.9777 - val_loss: 0.3542 - val_tp: 856.0000 - val_fp: 137.0000 - val_tn: 866.0000 - val_fn: 147.0000 - val_accuracy: 0.8584 - val_precision: 0.8620 - val_recall: 0.8534 - val_auc: 0.9455\n",
      "Epoch 67/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1440 - tp: 2697.1333 - fp: 211.9111 - tn: 2699.0222 - fn: 213.8000 - accuracy: 0.9206 - precision: 0.9209 - recall: 0.9203 - auc: 0.9785 - val_loss: 0.3533 - val_tp: 857.0000 - val_fp: 139.0000 - val_tn: 864.0000 - val_fn: 146.0000 - val_accuracy: 0.8579 - val_precision: 0.8604 - val_recall: 0.8544 - val_auc: 0.9464\n",
      "Epoch 68/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1403 - tp: 2703.1778 - fp: 205.9444 - tn: 2704.9889 - fn: 207.7556 - accuracy: 0.9231 - precision: 0.9236 - recall: 0.9225 - auc: 0.9795 - val_loss: 0.3479 - val_tp: 861.0000 - val_fp: 135.0000 - val_tn: 868.0000 - val_fn: 142.0000 - val_accuracy: 0.8619 - val_precision: 0.8645 - val_recall: 0.8584 - val_auc: 0.9479\n",
      "Epoch 69/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1368 - tp: 2706.0000 - fp: 199.0889 - tn: 2711.8444 - fn: 204.9333 - accuracy: 0.9250 - precision: 0.9260 - recall: 0.9238 - auc: 0.9804 - val_loss: 0.3490 - val_tp: 862.0000 - val_fp: 134.0000 - val_tn: 869.0000 - val_fn: 141.0000 - val_accuracy: 0.8629 - val_precision: 0.8655 - val_recall: 0.8594 - val_auc: 0.9480\n",
      "Epoch 70/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.1335 - tp: 2715.0111 - fp: 193.3556 - tn: 2717.5778 - fn: 195.9222 - accuracy: 0.9281 - precision: 0.9282 - recall: 0.9280 - auc: 0.9811 - val_loss: 0.3427 - val_tp: 865.0000 - val_fp: 130.0000 - val_tn: 873.0000 - val_fn: 138.0000 - val_accuracy: 0.8664 - val_precision: 0.8693 - val_recall: 0.8624 - val_auc: 0.9500\n",
      "Epoch 71/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1298 - tp: 2721.0444 - fp: 190.5333 - tn: 2720.4000 - fn: 189.8889 - accuracy: 0.9298 - precision: 0.9295 - recall: 0.9302 - auc: 0.9819 - val_loss: 0.3484 - val_tp: 863.0000 - val_fp: 131.0000 - val_tn: 872.0000 - val_fn: 140.0000 - val_accuracy: 0.8649 - val_precision: 0.8682 - val_recall: 0.8604 - val_auc: 0.9493\n",
      "Epoch 72/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1268 - tp: 2725.8556 - fp: 184.7444 - tn: 2726.1889 - fn: 185.0778 - accuracy: 0.9317 - precision: 0.9316 - recall: 0.9318 - auc: 0.9826 - val_loss: 0.3536 - val_tp: 862.0000 - val_fp: 130.0000 - val_tn: 873.0000 - val_fn: 141.0000 - val_accuracy: 0.8649 - val_precision: 0.8690 - val_recall: 0.8594 - val_auc: 0.9491\n",
      "Epoch 73/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1239 - tp: 2734.2333 - fp: 178.2444 - tn: 2732.6889 - fn: 176.7000 - accuracy: 0.9343 - precision: 0.9340 - recall: 0.9348 - auc: 0.9831 - val_loss: 0.3624 - val_tp: 861.0000 - val_fp: 135.0000 - val_tn: 868.0000 - val_fn: 142.0000 - val_accuracy: 0.8619 - val_precision: 0.8645 - val_recall: 0.8584 - val_auc: 0.9472\n",
      "Epoch 74/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1219 - tp: 2738.0444 - fp: 175.2222 - tn: 2735.7111 - fn: 172.8889 - accuracy: 0.9353 - precision: 0.9348 - recall: 0.9360 - auc: 0.9834 - val_loss: 0.3663 - val_tp: 858.0000 - val_fp: 135.0000 - val_tn: 868.0000 - val_fn: 145.0000 - val_accuracy: 0.8604 - val_precision: 0.8640 - val_recall: 0.8554 - val_auc: 0.9467\n",
      "Epoch 75/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1199 - tp: 2744.5667 - fp: 169.4556 - tn: 2741.4778 - fn: 166.3667 - accuracy: 0.9376 - precision: 0.9370 - recall: 0.9384 - auc: 0.9834 - val_loss: 0.4070 - val_tp: 851.0000 - val_fp: 144.0000 - val_tn: 859.0000 - val_fn: 152.0000 - val_accuracy: 0.8524 - val_precision: 0.8553 - val_recall: 0.8485 - val_auc: 0.9380\n",
      "Epoch 76/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1224 - tp: 2741.2444 - fp: 171.7889 - tn: 2739.1444 - fn: 169.6889 - accuracy: 0.9357 - precision: 0.9354 - recall: 0.9360 - auc: 0.9823 - val_loss: 0.3934 - val_tp: 859.0000 - val_fp: 138.0000 - val_tn: 865.0000 - val_fn: 144.0000 - val_accuracy: 0.8594 - val_precision: 0.8616 - val_recall: 0.8564 - val_auc: 0.9412\n",
      "Epoch 77/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1213 - tp: 2741.4667 - fp: 167.3222 - tn: 2743.6111 - fn: 169.4667 - accuracy: 0.9366 - precision: 0.9372 - recall: 0.9360 - auc: 0.9826 - val_loss: 0.4058 - val_tp: 856.0000 - val_fp: 146.0000 - val_tn: 857.0000 - val_fn: 147.0000 - val_accuracy: 0.8539 - val_precision: 0.8543 - val_recall: 0.8534 - val_auc: 0.9386\n",
      "Epoch 78/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1196 - tp: 2744.6889 - fp: 169.7778 - tn: 2741.1556 - fn: 166.2444 - accuracy: 0.9362 - precision: 0.9356 - recall: 0.9367 - auc: 0.9826 - val_loss: 0.4142 - val_tp: 851.0000 - val_fp: 147.0000 - val_tn: 856.0000 - val_fn: 152.0000 - val_accuracy: 0.8509 - val_precision: 0.8527 - val_recall: 0.8485 - val_auc: 0.9362\n",
      "Epoch 79/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1193 - tp: 2745.5444 - fp: 169.8333 - tn: 2741.1000 - fn: 165.3889 - accuracy: 0.9357 - precision: 0.9352 - recall: 0.9363 - auc: 0.9824 - val_loss: 0.4168 - val_tp: 849.0000 - val_fp: 150.0000 - val_tn: 853.0000 - val_fn: 154.0000 - val_accuracy: 0.8485 - val_precision: 0.8498 - val_recall: 0.8465 - val_auc: 0.9360\n",
      "Epoch 80/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.1246 - tp: 2735.1778 - fp: 179.5333 - tn: 2731.4000 - fn: 175.7556 - accuracy: 0.9301 - precision: 0.9292 - recall: 0.9312 - auc: 0.9810 - val_loss: 0.3491 - val_tp: 865.0000 - val_fp: 133.0000 - val_tn: 870.0000 - val_fn: 138.0000 - val_accuracy: 0.8649 - val_precision: 0.8667 - val_recall: 0.8624 - val_auc: 0.9508\n",
      "3\n",
      "Epoch 1/80\n",
      "89/89 [==============================] - 3s 23ms/step - loss: 0.6274 - tp: 2810.5667 - fp: 1007.4333 - tn: 2906.5000 - fn: 1103.3667 - accuracy: 0.7243 - precision: 0.7309 - recall: 0.7092 - auc: 0.8344 - val_loss: 0.7235 - val_tp: 568.0000 - val_fp: 434.0000 - val_tn: 569.0000 - val_fn: 435.0000 - val_accuracy: 0.5668 - val_precision: 0.5669 - val_recall: 0.5663 - val_auc: 0.6948\n",
      "Epoch 2/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4511 - tp: 2048.4222 - fp: 859.5111 - tn: 2051.4222 - fn: 862.5111 - accuracy: 0.7129 - precision: 0.7129 - recall: 0.7127 - auc: 0.8317 - val_loss: 0.6285 - val_tp: 584.0000 - val_fp: 417.0000 - val_tn: 586.0000 - val_fn: 419.0000 - val_accuracy: 0.5833 - val_precision: 0.5834 - val_recall: 0.5823 - val_auc: 0.7322\n",
      "Epoch 3/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4472 - tp: 2038.1222 - fp: 872.7111 - tn: 2038.2222 - fn: 872.8111 - accuracy: 0.7062 - precision: 0.7061 - recall: 0.7065 - auc: 0.8280 - val_loss: 0.5812 - val_tp: 610.0000 - val_fp: 391.0000 - val_tn: 612.0000 - val_fn: 393.0000 - val_accuracy: 0.6092 - val_precision: 0.6094 - val_recall: 0.6082 - val_auc: 0.7602\n",
      "Epoch 4/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4455 - tp: 2036.5111 - fp: 871.8111 - tn: 2039.1222 - fn: 874.4222 - accuracy: 0.7086 - precision: 0.7085 - recall: 0.7087 - auc: 0.8298 - val_loss: 0.5840 - val_tp: 601.0000 - val_fp: 398.0000 - val_tn: 605.0000 - val_fn: 402.0000 - val_accuracy: 0.6012 - val_precision: 0.6016 - val_recall: 0.5992 - val_auc: 0.7560\n",
      "Epoch 5/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4455 - tp: 2044.7333 - fp: 854.4111 - tn: 2056.5222 - fn: 866.2000 - accuracy: 0.7050 - precision: 0.7060 - recall: 0.7026 - auc: 0.8288 - val_loss: 0.5987 - val_tp: 610.0000 - val_fp: 388.0000 - val_tn: 615.0000 - val_fn: 393.0000 - val_accuracy: 0.6107 - val_precision: 0.6112 - val_recall: 0.6082 - val_auc: 0.7585\n",
      "Epoch 6/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4398 - tp: 2066.7000 - fp: 834.9222 - tn: 2076.0111 - fn: 844.2333 - accuracy: 0.7130 - precision: 0.7136 - recall: 0.7113 - auc: 0.8340 - val_loss: 0.6005 - val_tp: 623.0000 - val_fp: 377.0000 - val_tn: 626.0000 - val_fn: 380.0000 - val_accuracy: 0.6226 - val_precision: 0.6230 - val_recall: 0.6211 - val_auc: 0.7614\n",
      "Epoch 7/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.4350 - tp: 2086.3667 - fp: 820.0556 - tn: 2090.8778 - fn: 824.5667 - accuracy: 0.7187 - precision: 0.7191 - recall: 0.7180 - auc: 0.8384 - val_loss: 0.5749 - val_tp: 645.0000 - val_fp: 357.0000 - val_tn: 646.0000 - val_fn: 358.0000 - val_accuracy: 0.6436 - val_precision: 0.6437 - val_recall: 0.6431 - val_auc: 0.7751\n",
      "Epoch 8/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4297 - tp: 2099.9000 - fp: 804.8667 - tn: 2106.0667 - fn: 811.0333 - accuracy: 0.7253 - precision: 0.7258 - recall: 0.7243 - auc: 0.8430 - val_loss: 0.5770 - val_tp: 651.0000 - val_fp: 355.0000 - val_tn: 648.0000 - val_fn: 352.0000 - val_accuracy: 0.6476 - val_precision: 0.6471 - val_recall: 0.6491 - val_auc: 0.7779\n",
      "Epoch 9/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4256 - tp: 2121.9333 - fp: 789.1111 - tn: 2121.8222 - fn: 789.0000 - accuracy: 0.7311 - precision: 0.7310 - recall: 0.7313 - auc: 0.8462 - val_loss: 0.5588 - val_tp: 675.0000 - val_fp: 326.0000 - val_tn: 677.0000 - val_fn: 328.0000 - val_accuracy: 0.6740 - val_precision: 0.6743 - val_recall: 0.6730 - val_auc: 0.7919\n",
      "Epoch 10/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4192 - tp: 2134.2444 - fp: 770.6222 - tn: 2140.3111 - fn: 776.6889 - accuracy: 0.7371 - precision: 0.7376 - recall: 0.7361 - auc: 0.8513 - val_loss: 0.5610 - val_tp: 667.0000 - val_fp: 334.0000 - val_tn: 669.0000 - val_fn: 336.0000 - val_accuracy: 0.6660 - val_precision: 0.6663 - val_recall: 0.6650 - val_auc: 0.7884\n",
      "Epoch 11/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4165 - tp: 2138.1667 - fp: 767.9889 - tn: 2142.9444 - fn: 772.7667 - accuracy: 0.7356 - precision: 0.7360 - recall: 0.7349 - auc: 0.8514 - val_loss: 0.5529 - val_tp: 690.0000 - val_fp: 309.0000 - val_tn: 694.0000 - val_fn: 313.0000 - val_accuracy: 0.6899 - val_precision: 0.6907 - val_recall: 0.6879 - val_auc: 0.7993\n",
      "Epoch 12/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4085 - tp: 2162.7667 - fp: 743.3000 - tn: 2167.6333 - fn: 748.1667 - accuracy: 0.7457 - precision: 0.7460 - recall: 0.7452 - auc: 0.8582 - val_loss: 0.5452 - val_tp: 699.0000 - val_fp: 308.0000 - val_tn: 695.0000 - val_fn: 304.0000 - val_accuracy: 0.6949 - val_precision: 0.6941 - val_recall: 0.6969 - val_auc: 0.8020\n",
      "Epoch 13/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.4050 - tp: 2172.7111 - fp: 729.8556 - tn: 2181.0778 - fn: 738.2222 - accuracy: 0.7469 - precision: 0.7475 - recall: 0.7459 - auc: 0.8587 - val_loss: 0.5355 - val_tp: 706.0000 - val_fp: 295.0000 - val_tn: 708.0000 - val_fn: 297.0000 - val_accuracy: 0.7049 - val_precision: 0.7053 - val_recall: 0.7039 - val_auc: 0.8114\n",
      "Epoch 14/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3973 - tp: 2184.3333 - fp: 722.7333 - tn: 2188.2000 - fn: 726.6000 - accuracy: 0.7526 - precision: 0.7527 - recall: 0.7526 - auc: 0.8648 - val_loss: 0.5344 - val_tp: 712.0000 - val_fp: 293.0000 - val_tn: 710.0000 - val_fn: 291.0000 - val_accuracy: 0.7089 - val_precision: 0.7085 - val_recall: 0.7099 - val_auc: 0.8118\n",
      "Epoch 15/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3908 - tp: 2205.9778 - fp: 699.3556 - tn: 2211.5778 - fn: 704.9556 - accuracy: 0.7599 - precision: 0.7600 - recall: 0.7597 - auc: 0.8673 - val_loss: 0.5250 - val_tp: 720.0000 - val_fp: 284.0000 - val_tn: 719.0000 - val_fn: 283.0000 - val_accuracy: 0.7173 - val_precision: 0.7171 - val_recall: 0.7178 - val_auc: 0.8200\n",
      "Epoch 16/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3851 - tp: 2216.5889 - fp: 691.1000 - tn: 2219.8333 - fn: 694.3444 - accuracy: 0.7628 - precision: 0.7628 - recall: 0.7628 - auc: 0.8721 - val_loss: 0.5232 - val_tp: 714.0000 - val_fp: 290.0000 - val_tn: 713.0000 - val_fn: 289.0000 - val_accuracy: 0.7114 - val_precision: 0.7112 - val_recall: 0.7119 - val_auc: 0.8206\n",
      "Epoch 17/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3780 - tp: 2231.7111 - fp: 675.5667 - tn: 2235.3667 - fn: 679.2222 - accuracy: 0.7670 - precision: 0.7673 - recall: 0.7665 - auc: 0.8745 - val_loss: 0.5248 - val_tp: 720.0000 - val_fp: 286.0000 - val_tn: 717.0000 - val_fn: 283.0000 - val_accuracy: 0.7164 - val_precision: 0.7157 - val_recall: 0.7178 - val_auc: 0.8223\n",
      "Epoch 18/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3730 - tp: 2240.1222 - fp: 665.6444 - tn: 2245.2889 - fn: 670.8111 - accuracy: 0.7696 - precision: 0.7701 - recall: 0.7686 - auc: 0.8765 - val_loss: 0.5059 - val_tp: 730.0000 - val_fp: 275.0000 - val_tn: 728.0000 - val_fn: 273.0000 - val_accuracy: 0.7268 - val_precision: 0.7264 - val_recall: 0.7278 - val_auc: 0.8350\n",
      "Epoch 19/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3641 - tp: 2260.8333 - fp: 646.3222 - tn: 2264.6111 - fn: 650.1000 - accuracy: 0.7769 - precision: 0.7774 - recall: 0.7760 - auc: 0.8830 - val_loss: 0.5057 - val_tp: 730.0000 - val_fp: 274.0000 - val_tn: 729.0000 - val_fn: 273.0000 - val_accuracy: 0.7273 - val_precision: 0.7271 - val_recall: 0.7278 - val_auc: 0.8360\n",
      "Epoch 20/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3588 - tp: 2267.9556 - fp: 632.9111 - tn: 2278.0222 - fn: 642.9778 - accuracy: 0.7795 - precision: 0.7803 - recall: 0.7781 - auc: 0.8847 - val_loss: 0.4975 - val_tp: 734.0000 - val_fp: 268.0000 - val_tn: 735.0000 - val_fn: 269.0000 - val_accuracy: 0.7323 - val_precision: 0.7325 - val_recall: 0.7318 - val_auc: 0.8422\n",
      "Epoch 21/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3511 - tp: 2284.5000 - fp: 623.2778 - tn: 2287.6556 - fn: 626.4333 - accuracy: 0.7840 - precision: 0.7842 - recall: 0.7835 - auc: 0.8898 - val_loss: 0.5042 - val_tp: 737.0000 - val_fp: 270.0000 - val_tn: 733.0000 - val_fn: 266.0000 - val_accuracy: 0.7328 - val_precision: 0.7319 - val_recall: 0.7348 - val_auc: 0.8421\n",
      "Epoch 22/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3465 - tp: 2300.4444 - fp: 609.9000 - tn: 2301.0333 - fn: 610.4889 - accuracy: 0.7876 - precision: 0.7875 - recall: 0.7878 - auc: 0.8919 - val_loss: 0.4989 - val_tp: 739.0000 - val_fp: 266.0000 - val_tn: 737.0000 - val_fn: 264.0000 - val_accuracy: 0.7358 - val_precision: 0.7353 - val_recall: 0.7368 - val_auc: 0.8474\n",
      "Epoch 23/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3390 - tp: 2311.2778 - fp: 598.6444 - tn: 2312.2889 - fn: 599.6556 - accuracy: 0.7919 - precision: 0.7920 - recall: 0.7917 - auc: 0.8962 - val_loss: 0.4896 - val_tp: 745.0000 - val_fp: 256.0000 - val_tn: 747.0000 - val_fn: 258.0000 - val_accuracy: 0.7438 - val_precision: 0.7443 - val_recall: 0.7428 - val_auc: 0.8527\n",
      "Epoch 24/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3345 - tp: 2326.3889 - fp: 583.2222 - tn: 2327.7111 - fn: 584.5444 - accuracy: 0.7947 - precision: 0.7950 - recall: 0.7942 - auc: 0.8982 - val_loss: 0.4868 - val_tp: 749.0000 - val_fp: 253.0000 - val_tn: 750.0000 - val_fn: 254.0000 - val_accuracy: 0.7473 - val_precision: 0.7475 - val_recall: 0.7468 - val_auc: 0.8569\n",
      "Epoch 25/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.3268 - tp: 2338.7000 - fp: 567.9333 - tn: 2343.0000 - fn: 572.2333 - accuracy: 0.8005 - precision: 0.8009 - recall: 0.8000 - auc: 0.9031 - val_loss: 0.4675 - val_tp: 759.0000 - val_fp: 246.0000 - val_tn: 757.0000 - val_fn: 244.0000 - val_accuracy: 0.7557 - val_precision: 0.7552 - val_recall: 0.7567 - val_auc: 0.8659\n",
      "Epoch 26/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.3218 - tp: 2352.7778 - fp: 557.0889 - tn: 2353.8444 - fn: 558.1556 - accuracy: 0.8030 - precision: 0.8032 - recall: 0.8028 - auc: 0.9059 - val_loss: 0.4609 - val_tp: 767.0000 - val_fp: 243.0000 - val_tn: 760.0000 - val_fn: 236.0000 - val_accuracy: 0.7612 - val_precision: 0.7594 - val_recall: 0.7647 - val_auc: 0.8690\n",
      "Epoch 27/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3155 - tp: 2365.1111 - fp: 542.0889 - tn: 2368.8444 - fn: 545.8222 - accuracy: 0.8072 - precision: 0.8075 - recall: 0.8068 - auc: 0.9087 - val_loss: 0.4760 - val_tp: 764.0000 - val_fp: 243.0000 - val_tn: 760.0000 - val_fn: 239.0000 - val_accuracy: 0.7597 - val_precision: 0.7587 - val_recall: 0.7617 - val_auc: 0.8647\n",
      "Epoch 28/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3117 - tp: 2364.3778 - fp: 547.6556 - tn: 2363.2778 - fn: 546.5556 - accuracy: 0.8063 - precision: 0.8065 - recall: 0.8060 - auc: 0.9102 - val_loss: 0.4724 - val_tp: 766.0000 - val_fp: 232.0000 - val_tn: 771.0000 - val_fn: 237.0000 - val_accuracy: 0.7662 - val_precision: 0.7675 - val_recall: 0.7637 - val_auc: 0.8681\n",
      "Epoch 29/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3062 - tp: 2387.3667 - fp: 522.5000 - tn: 2388.4333 - fn: 523.5667 - accuracy: 0.8140 - precision: 0.8142 - recall: 0.8137 - auc: 0.9129 - val_loss: 0.4630 - val_tp: 774.0000 - val_fp: 227.0000 - val_tn: 776.0000 - val_fn: 229.0000 - val_accuracy: 0.7727 - val_precision: 0.7732 - val_recall: 0.7717 - val_auc: 0.8735\n",
      "Epoch 30/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2993 - tp: 2396.0000 - fp: 513.8000 - tn: 2397.1333 - fn: 514.9333 - accuracy: 0.8165 - precision: 0.8169 - recall: 0.8158 - auc: 0.9167 - val_loss: 0.4590 - val_tp: 780.0000 - val_fp: 220.0000 - val_tn: 783.0000 - val_fn: 223.0000 - val_accuracy: 0.7792 - val_precision: 0.7800 - val_recall: 0.7777 - val_auc: 0.8770\n",
      "Epoch 31/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2949 - tp: 2406.5111 - fp: 503.7667 - tn: 2407.1667 - fn: 504.4222 - accuracy: 0.8192 - precision: 0.8196 - recall: 0.8185 - auc: 0.9190 - val_loss: 0.4534 - val_tp: 779.0000 - val_fp: 222.0000 - val_tn: 781.0000 - val_fn: 224.0000 - val_accuracy: 0.7777 - val_precision: 0.7782 - val_recall: 0.7767 - val_auc: 0.8796\n",
      "Epoch 32/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2875 - tp: 2422.8222 - fp: 488.5000 - tn: 2422.4333 - fn: 488.1111 - accuracy: 0.8247 - precision: 0.8248 - recall: 0.8246 - auc: 0.9223 - val_loss: 0.4595 - val_tp: 776.0000 - val_fp: 224.0000 - val_tn: 779.0000 - val_fn: 227.0000 - val_accuracy: 0.7752 - val_precision: 0.7760 - val_recall: 0.7737 - val_auc: 0.8789\n",
      "Epoch 33/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2848 - tp: 2428.7222 - fp: 483.8556 - tn: 2427.0778 - fn: 482.2111 - accuracy: 0.8258 - precision: 0.8261 - recall: 0.8254 - auc: 0.9231 - val_loss: 0.4636 - val_tp: 776.0000 - val_fp: 221.0000 - val_tn: 782.0000 - val_fn: 227.0000 - val_accuracy: 0.7767 - val_precision: 0.7783 - val_recall: 0.7737 - val_auc: 0.8798\n",
      "Epoch 34/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2784 - tp: 2447.4333 - fp: 467.0778 - tn: 2443.8556 - fn: 463.5000 - accuracy: 0.8329 - precision: 0.8326 - recall: 0.8333 - auc: 0.9269 - val_loss: 0.4446 - val_tp: 781.0000 - val_fp: 218.0000 - val_tn: 785.0000 - val_fn: 222.0000 - val_accuracy: 0.7807 - val_precision: 0.7818 - val_recall: 0.7787 - val_auc: 0.8875\n",
      "Epoch 35/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2723 - tp: 2450.5556 - fp: 455.0556 - tn: 2455.8778 - fn: 460.3778 - accuracy: 0.8342 - precision: 0.8350 - recall: 0.8330 - auc: 0.9292 - val_loss: 0.4540 - val_tp: 782.0000 - val_fp: 220.0000 - val_tn: 783.0000 - val_fn: 221.0000 - val_accuracy: 0.7802 - val_precision: 0.7804 - val_recall: 0.7797 - val_auc: 0.8859\n",
      "Epoch 36/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2675 - tp: 2466.1556 - fp: 443.2111 - tn: 2467.7222 - fn: 444.7778 - accuracy: 0.8393 - precision: 0.8398 - recall: 0.8384 - auc: 0.9315 - val_loss: 0.4476 - val_tp: 792.0000 - val_fp: 213.0000 - val_tn: 790.0000 - val_fn: 211.0000 - val_accuracy: 0.7886 - val_precision: 0.7881 - val_recall: 0.7896 - val_auc: 0.8903\n",
      "Epoch 37/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2623 - tp: 2487.7444 - fp: 429.0778 - tn: 2481.8556 - fn: 423.1889 - accuracy: 0.8463 - precision: 0.8458 - recall: 0.8471 - auc: 0.9345 - val_loss: 0.4377 - val_tp: 792.0000 - val_fp: 209.0000 - val_tn: 794.0000 - val_fn: 211.0000 - val_accuracy: 0.7906 - val_precision: 0.7912 - val_recall: 0.7896 - val_auc: 0.8949\n",
      "Epoch 38/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2571 - tp: 2491.7889 - fp: 423.3556 - tn: 2487.5778 - fn: 419.1444 - accuracy: 0.8466 - precision: 0.8465 - recall: 0.8466 - auc: 0.9358 - val_loss: 0.4348 - val_tp: 793.0000 - val_fp: 204.0000 - val_tn: 799.0000 - val_fn: 210.0000 - val_accuracy: 0.7936 - val_precision: 0.7954 - val_recall: 0.7906 - val_auc: 0.8975\n",
      "Epoch 39/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2510 - tp: 2500.2111 - fp: 407.1556 - tn: 2503.7778 - fn: 410.7222 - accuracy: 0.8509 - precision: 0.8513 - recall: 0.8502 - auc: 0.9386 - val_loss: 0.4351 - val_tp: 794.0000 - val_fp: 206.0000 - val_tn: 797.0000 - val_fn: 209.0000 - val_accuracy: 0.7931 - val_precision: 0.7940 - val_recall: 0.7916 - val_auc: 0.8988\n",
      "Epoch 40/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.2463 - tp: 2514.6889 - fp: 395.5556 - tn: 2515.3778 - fn: 396.2444 - accuracy: 0.8558 - precision: 0.8560 - recall: 0.8555 - auc: 0.9413 - val_loss: 0.4248 - val_tp: 803.0000 - val_fp: 201.0000 - val_tn: 802.0000 - val_fn: 200.0000 - val_accuracy: 0.8001 - val_precision: 0.7998 - val_recall: 0.8006 - val_auc: 0.9039\n",
      "Epoch 41/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2402 - tp: 2532.2111 - fp: 380.1000 - tn: 2530.8333 - fn: 378.7222 - accuracy: 0.8618 - precision: 0.8618 - recall: 0.8618 - auc: 0.9438 - val_loss: 0.4219 - val_tp: 799.0000 - val_fp: 201.0000 - val_tn: 802.0000 - val_fn: 204.0000 - val_accuracy: 0.7981 - val_precision: 0.7990 - val_recall: 0.7966 - val_auc: 0.9058\n",
      "Epoch 42/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2346 - tp: 2535.8556 - fp: 373.1667 - tn: 2537.7667 - fn: 375.0778 - accuracy: 0.8629 - precision: 0.8633 - recall: 0.8622 - auc: 0.9466 - val_loss: 0.4157 - val_tp: 808.0000 - val_fp: 192.0000 - val_tn: 811.0000 - val_fn: 195.0000 - val_accuracy: 0.8071 - val_precision: 0.8080 - val_recall: 0.8056 - val_auc: 0.9101\n",
      "Epoch 43/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2282 - tp: 2554.1667 - fp: 362.7333 - tn: 2548.2000 - fn: 356.7667 - accuracy: 0.8683 - precision: 0.8680 - recall: 0.8687 - auc: 0.9498 - val_loss: 0.4135 - val_tp: 815.0000 - val_fp: 190.0000 - val_tn: 813.0000 - val_fn: 188.0000 - val_accuracy: 0.8116 - val_precision: 0.8109 - val_recall: 0.8126 - val_auc: 0.9124\n",
      "Epoch 44/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2238 - tp: 2561.1889 - fp: 356.5333 - tn: 2554.4000 - fn: 349.7444 - accuracy: 0.8703 - precision: 0.8697 - recall: 0.8710 - auc: 0.9514 - val_loss: 0.4085 - val_tp: 816.0000 - val_fp: 186.0000 - val_tn: 817.0000 - val_fn: 187.0000 - val_accuracy: 0.8141 - val_precision: 0.8144 - val_recall: 0.8136 - val_auc: 0.9137\n",
      "Epoch 45/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2191 - tp: 2567.0333 - fp: 343.4667 - tn: 2567.4667 - fn: 343.9000 - accuracy: 0.8734 - precision: 0.8737 - recall: 0.8728 - auc: 0.9535 - val_loss: 0.3885 - val_tp: 830.0000 - val_fp: 173.0000 - val_tn: 830.0000 - val_fn: 173.0000 - val_accuracy: 0.8275 - val_precision: 0.8275 - val_recall: 0.8275 - val_auc: 0.9222\n",
      "Epoch 46/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2140 - tp: 2576.3111 - fp: 327.4778 - tn: 2583.4556 - fn: 334.6222 - accuracy: 0.8783 - precision: 0.8802 - recall: 0.8757 - auc: 0.9556 - val_loss: 0.3792 - val_tp: 830.0000 - val_fp: 170.0000 - val_tn: 833.0000 - val_fn: 173.0000 - val_accuracy: 0.8290 - val_precision: 0.8300 - val_recall: 0.8275 - val_auc: 0.9252\n",
      "Epoch 47/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2075 - tp: 2592.8778 - fp: 316.2778 - tn: 2594.6556 - fn: 318.0556 - accuracy: 0.8841 - precision: 0.8849 - recall: 0.8829 - auc: 0.9586 - val_loss: 0.3741 - val_tp: 833.0000 - val_fp: 168.0000 - val_tn: 835.0000 - val_fn: 170.0000 - val_accuracy: 0.8315 - val_precision: 0.8322 - val_recall: 0.8305 - val_auc: 0.9280\n",
      "Epoch 48/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2022 - tp: 2598.9556 - fp: 308.4778 - tn: 2602.4556 - fn: 311.9778 - accuracy: 0.8861 - precision: 0.8873 - recall: 0.8846 - auc: 0.9605 - val_loss: 0.3661 - val_tp: 835.0000 - val_fp: 163.0000 - val_tn: 840.0000 - val_fn: 168.0000 - val_accuracy: 0.8350 - val_precision: 0.8367 - val_recall: 0.8325 - val_auc: 0.9304\n",
      "Epoch 49/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1970 - tp: 2611.2111 - fp: 302.8222 - tn: 2608.1111 - fn: 299.7222 - accuracy: 0.8901 - precision: 0.8898 - recall: 0.8904 - auc: 0.9628 - val_loss: 0.3767 - val_tp: 835.0000 - val_fp: 165.0000 - val_tn: 838.0000 - val_fn: 168.0000 - val_accuracy: 0.8340 - val_precision: 0.8350 - val_recall: 0.8325 - val_auc: 0.9285\n",
      "Epoch 50/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1925 - tp: 2622.2333 - fp: 295.0556 - tn: 2615.8778 - fn: 288.7000 - accuracy: 0.8928 - precision: 0.8922 - recall: 0.8937 - auc: 0.9640 - val_loss: 0.3599 - val_tp: 840.0000 - val_fp: 160.0000 - val_tn: 843.0000 - val_fn: 163.0000 - val_accuracy: 0.8390 - val_precision: 0.8400 - val_recall: 0.8375 - val_auc: 0.9341\n",
      "Epoch 51/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1879 - tp: 2626.6778 - fp: 285.7889 - tn: 2625.1444 - fn: 284.2556 - accuracy: 0.8966 - precision: 0.8968 - recall: 0.8962 - auc: 0.9660 - val_loss: 0.3538 - val_tp: 845.0000 - val_fp: 157.0000 - val_tn: 846.0000 - val_fn: 158.0000 - val_accuracy: 0.8430 - val_precision: 0.8433 - val_recall: 0.8425 - val_auc: 0.9371\n",
      "Epoch 52/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.1820 - tp: 2641.0333 - fp: 275.2889 - tn: 2635.6444 - fn: 269.9000 - accuracy: 0.9006 - precision: 0.9003 - recall: 0.9009 - auc: 0.9679 - val_loss: 0.3377 - val_tp: 851.0000 - val_fp: 147.0000 - val_tn: 856.0000 - val_fn: 152.0000 - val_accuracy: 0.8509 - val_precision: 0.8527 - val_recall: 0.8485 - val_auc: 0.9420\n",
      "Epoch 53/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1760 - tp: 2650.3556 - fp: 263.9444 - tn: 2646.9889 - fn: 260.5778 - accuracy: 0.9049 - precision: 0.9049 - recall: 0.9047 - auc: 0.9702 - val_loss: 0.3316 - val_tp: 856.0000 - val_fp: 144.0000 - val_tn: 859.0000 - val_fn: 147.0000 - val_accuracy: 0.8549 - val_precision: 0.8560 - val_recall: 0.8534 - val_auc: 0.9443\n",
      "Epoch 54/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1710 - tp: 2658.2667 - fp: 258.3111 - tn: 2652.6222 - fn: 252.6667 - accuracy: 0.9075 - precision: 0.9071 - recall: 0.9080 - auc: 0.9722 - val_loss: 0.3342 - val_tp: 854.0000 - val_fp: 145.0000 - val_tn: 858.0000 - val_fn: 149.0000 - val_accuracy: 0.8534 - val_precision: 0.8549 - val_recall: 0.8514 - val_auc: 0.9441\n",
      "Epoch 55/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.1666 - tp: 2662.6111 - fp: 248.6667 - tn: 2662.2667 - fn: 248.3222 - accuracy: 0.9099 - precision: 0.9102 - recall: 0.9095 - auc: 0.9734 - val_loss: 0.3450 - val_tp: 850.0000 - val_fp: 150.0000 - val_tn: 853.0000 - val_fn: 153.0000 - val_accuracy: 0.8490 - val_precision: 0.8500 - val_recall: 0.8475 - val_auc: 0.9417\n",
      "Epoch 56/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1628 - tp: 2670.2778 - fp: 243.2222 - tn: 2667.7111 - fn: 240.6556 - accuracy: 0.9120 - precision: 0.9119 - recall: 0.9121 - auc: 0.9741 - val_loss: 0.3430 - val_tp: 849.0000 - val_fp: 152.0000 - val_tn: 851.0000 - val_fn: 154.0000 - val_accuracy: 0.8475 - val_precision: 0.8482 - val_recall: 0.8465 - val_auc: 0.9427\n",
      "Epoch 57/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1599 - tp: 2673.1778 - fp: 240.2556 - tn: 2670.6778 - fn: 237.7556 - accuracy: 0.9128 - precision: 0.9129 - recall: 0.9127 - auc: 0.9750 - val_loss: 0.3352 - val_tp: 854.0000 - val_fp: 153.0000 - val_tn: 850.0000 - val_fn: 149.0000 - val_accuracy: 0.8495 - val_precision: 0.8481 - val_recall: 0.8514 - val_auc: 0.9445\n",
      "Epoch 58/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1571 - tp: 2677.4444 - fp: 233.6778 - tn: 2677.2556 - fn: 233.4889 - accuracy: 0.9148 - precision: 0.9152 - recall: 0.9142 - auc: 0.9758 - val_loss: 0.3522 - val_tp: 850.0000 - val_fp: 156.0000 - val_tn: 847.0000 - val_fn: 153.0000 - val_accuracy: 0.8460 - val_precision: 0.8449 - val_recall: 0.8475 - val_auc: 0.9404\n",
      "Epoch 59/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1520 - tp: 2688.4444 - fp: 227.3222 - tn: 2683.6111 - fn: 222.4889 - accuracy: 0.9175 - precision: 0.9174 - recall: 0.9177 - auc: 0.9767 - val_loss: 0.3407 - val_tp: 851.0000 - val_fp: 150.0000 - val_tn: 853.0000 - val_fn: 152.0000 - val_accuracy: 0.8495 - val_precision: 0.8501 - val_recall: 0.8485 - val_auc: 0.9449\n",
      "Epoch 60/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.1470 - tp: 2694.8778 - fp: 216.5000 - tn: 2694.4333 - fn: 216.0556 - accuracy: 0.9205 - precision: 0.9205 - recall: 0.9204 - auc: 0.9781 - val_loss: 0.3552 - val_tp: 849.0000 - val_fp: 154.0000 - val_tn: 849.0000 - val_fn: 154.0000 - val_accuracy: 0.8465 - val_precision: 0.8465 - val_recall: 0.8465 - val_auc: 0.9419\n",
      "Epoch 61/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1425 - tp: 2701.2111 - fp: 213.2778 - tn: 2697.6556 - fn: 209.7222 - accuracy: 0.9214 - precision: 0.9213 - recall: 0.9216 - auc: 0.9791 - val_loss: 0.3559 - val_tp: 849.0000 - val_fp: 155.0000 - val_tn: 848.0000 - val_fn: 154.0000 - val_accuracy: 0.8460 - val_precision: 0.8456 - val_recall: 0.8465 - val_auc: 0.9420\n",
      "Epoch 62/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1412 - tp: 2699.7667 - fp: 208.0444 - tn: 2702.8889 - fn: 211.1667 - accuracy: 0.9220 - precision: 0.9225 - recall: 0.9213 - auc: 0.9793 - val_loss: 0.3539 - val_tp: 852.0000 - val_fp: 149.0000 - val_tn: 854.0000 - val_fn: 151.0000 - val_accuracy: 0.8504 - val_precision: 0.8511 - val_recall: 0.8495 - val_auc: 0.9439\n",
      "Epoch 63/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1369 - tp: 2706.4111 - fp: 201.7111 - tn: 2709.2222 - fn: 204.5222 - accuracy: 0.9243 - precision: 0.9247 - recall: 0.9237 - auc: 0.9801 - val_loss: 0.3705 - val_tp: 848.0000 - val_fp: 158.0000 - val_tn: 845.0000 - val_fn: 155.0000 - val_accuracy: 0.8440 - val_precision: 0.8429 - val_recall: 0.8455 - val_auc: 0.9402\n",
      "Epoch 64/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1343 - tp: 2709.8667 - fp: 200.6000 - tn: 2710.3333 - fn: 201.0667 - accuracy: 0.9247 - precision: 0.9251 - recall: 0.9243 - auc: 0.9806 - val_loss: 0.3774 - val_tp: 847.0000 - val_fp: 161.0000 - val_tn: 842.0000 - val_fn: 156.0000 - val_accuracy: 0.8420 - val_precision: 0.8403 - val_recall: 0.8445 - val_auc: 0.9387\n",
      "Epoch 65/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1314 - tp: 2713.2111 - fp: 191.6667 - tn: 2719.2667 - fn: 197.7222 - accuracy: 0.9266 - precision: 0.9274 - recall: 0.9256 - auc: 0.9809 - val_loss: 0.3673 - val_tp: 854.0000 - val_fp: 152.0000 - val_tn: 851.0000 - val_fn: 149.0000 - val_accuracy: 0.8500 - val_precision: 0.8489 - val_recall: 0.8514 - val_auc: 0.9423\n",
      "Epoch 66/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1278 - tp: 2717.1111 - fp: 187.5222 - tn: 2723.4111 - fn: 193.8222 - accuracy: 0.9280 - precision: 0.9293 - recall: 0.9266 - auc: 0.9819 - val_loss: 0.3664 - val_tp: 854.0000 - val_fp: 155.0000 - val_tn: 848.0000 - val_fn: 149.0000 - val_accuracy: 0.8485 - val_precision: 0.8464 - val_recall: 0.8514 - val_auc: 0.9429\n",
      "Epoch 67/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.1273 - tp: 2721.0778 - fp: 185.0444 - tn: 2725.8889 - fn: 189.8556 - accuracy: 0.9296 - precision: 0.9302 - recall: 0.9289 - auc: 0.9820 - val_loss: 0.3549 - val_tp: 865.0000 - val_fp: 149.0000 - val_tn: 854.0000 - val_fn: 138.0000 - val_accuracy: 0.8569 - val_precision: 0.8531 - val_recall: 0.8624 - val_auc: 0.9455\n",
      "Epoch 68/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1275 - tp: 2721.0667 - fp: 189.2667 - tn: 2721.6667 - fn: 189.8667 - accuracy: 0.9292 - precision: 0.9294 - recall: 0.9290 - auc: 0.9817 - val_loss: 0.3104 - val_tp: 886.0000 - val_fp: 126.0000 - val_tn: 877.0000 - val_fn: 117.0000 - val_accuracy: 0.8789 - val_precision: 0.8755 - val_recall: 0.8833 - val_auc: 0.9563\n",
      "Epoch 69/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1347 - tp: 2701.5889 - fp: 208.2111 - tn: 2702.7222 - fn: 209.3444 - accuracy: 0.9216 - precision: 0.9216 - recall: 0.9217 - auc: 0.9796 - val_loss: 0.2480 - val_tp: 909.0000 - val_fp: 98.0000 - val_tn: 905.0000 - val_fn: 94.0000 - val_accuracy: 0.9043 - val_precision: 0.9027 - val_recall: 0.9063 - val_auc: 0.9698\n",
      "Epoch 70/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1311 - tp: 2717.7333 - fp: 192.8111 - tn: 2718.1222 - fn: 193.2000 - accuracy: 0.9293 - precision: 0.9295 - recall: 0.9290 - auc: 0.9822 - val_loss: 0.2469 - val_tp: 911.0000 - val_fp: 97.0000 - val_tn: 906.0000 - val_fn: 92.0000 - val_accuracy: 0.9058 - val_precision: 0.9038 - val_recall: 0.9083 - val_auc: 0.9702\n",
      "Epoch 71/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.1228 - tp: 2728.7444 - fp: 181.9111 - tn: 2729.0222 - fn: 182.1889 - accuracy: 0.9327 - precision: 0.9328 - recall: 0.9325 - auc: 0.9842 - val_loss: 0.2570 - val_tp: 909.0000 - val_fp: 101.0000 - val_tn: 902.0000 - val_fn: 94.0000 - val_accuracy: 0.9028 - val_precision: 0.9000 - val_recall: 0.9063 - val_auc: 0.9684\n",
      "Epoch 72/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1154 - tp: 2743.9222 - fp: 172.8556 - tn: 2738.0778 - fn: 167.0111 - accuracy: 0.9370 - precision: 0.9359 - recall: 0.9382 - auc: 0.9858 - val_loss: 0.2658 - val_tp: 906.0000 - val_fp: 103.0000 - val_tn: 900.0000 - val_fn: 97.0000 - val_accuracy: 0.9003 - val_precision: 0.8979 - val_recall: 0.9033 - val_auc: 0.9674\n",
      "Epoch 73/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1103 - tp: 2748.6444 - fp: 162.6111 - tn: 2748.3222 - fn: 162.2889 - accuracy: 0.9395 - precision: 0.9393 - recall: 0.9398 - auc: 0.9869 - val_loss: 0.2693 - val_tp: 906.0000 - val_fp: 100.0000 - val_tn: 903.0000 - val_fn: 97.0000 - val_accuracy: 0.9018 - val_precision: 0.9006 - val_recall: 0.9033 - val_auc: 0.9674\n",
      "Epoch 74/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1061 - tp: 2756.4778 - fp: 158.0778 - tn: 2752.8556 - fn: 154.4556 - accuracy: 0.9419 - precision: 0.9411 - recall: 0.9428 - auc: 0.9876 - val_loss: 0.2853 - val_tp: 900.0000 - val_fp: 105.0000 - val_tn: 898.0000 - val_fn: 103.0000 - val_accuracy: 0.8963 - val_precision: 0.8955 - val_recall: 0.8973 - val_auc: 0.9651\n",
      "Epoch 75/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1009 - tp: 2763.2667 - fp: 151.5000 - tn: 2759.4333 - fn: 147.6667 - accuracy: 0.9437 - precision: 0.9427 - recall: 0.9448 - auc: 0.9885 - val_loss: 0.2889 - val_tp: 899.0000 - val_fp: 103.0000 - val_tn: 900.0000 - val_fn: 104.0000 - val_accuracy: 0.8968 - val_precision: 0.8972 - val_recall: 0.8963 - val_auc: 0.9645\n",
      "Epoch 76/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.0972 - tp: 2771.5111 - fp: 145.9222 - tn: 2765.0111 - fn: 139.4222 - accuracy: 0.9463 - precision: 0.9451 - recall: 0.9477 - auc: 0.9891 - val_loss: 0.2974 - val_tp: 899.0000 - val_fp: 111.0000 - val_tn: 892.0000 - val_fn: 104.0000 - val_accuracy: 0.8928 - val_precision: 0.8901 - val_recall: 0.8963 - val_auc: 0.9630\n",
      "Epoch 77/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.0930 - tp: 2780.9444 - fp: 142.7000 - tn: 2768.2333 - fn: 129.9889 - accuracy: 0.9486 - precision: 0.9463 - recall: 0.9511 - auc: 0.9902 - val_loss: 0.3081 - val_tp: 898.0000 - val_fp: 116.0000 - val_tn: 887.0000 - val_fn: 105.0000 - val_accuracy: 0.8898 - val_precision: 0.8856 - val_recall: 0.8953 - val_auc: 0.9617\n",
      "Epoch 78/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.0887 - tp: 2788.6889 - fp: 130.3222 - tn: 2780.6111 - fn: 122.2444 - accuracy: 0.9524 - precision: 0.9509 - recall: 0.9541 - auc: 0.9907 - val_loss: 0.2878 - val_tp: 910.0000 - val_fp: 104.0000 - val_tn: 899.0000 - val_fn: 93.0000 - val_accuracy: 0.9018 - val_precision: 0.8974 - val_recall: 0.9073 - val_auc: 0.9660\n",
      "Epoch 79/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.0876 - tp: 2790.4444 - fp: 124.2889 - tn: 2786.6444 - fn: 120.4889 - accuracy: 0.9537 - precision: 0.9531 - recall: 0.9544 - auc: 0.9906 - val_loss: 0.2846 - val_tp: 911.0000 - val_fp: 102.0000 - val_tn: 901.0000 - val_fn: 92.0000 - val_accuracy: 0.9033 - val_precision: 0.8993 - val_recall: 0.9083 - val_auc: 0.9668\n",
      "Epoch 80/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.0841 - tp: 2795.5000 - fp: 120.1222 - tn: 2790.8111 - fn: 115.4333 - accuracy: 0.9554 - precision: 0.9545 - recall: 0.9564 - auc: 0.9912 - val_loss: 0.2759 - val_tp: 914.0000 - val_fp: 98.0000 - val_tn: 905.0000 - val_fn: 89.0000 - val_accuracy: 0.9068 - val_precision: 0.9032 - val_recall: 0.9113 - val_auc: 0.9688\n",
      "4\n",
      "Epoch 1/80\n",
      "89/89 [==============================] - 3s 23ms/step - loss: 0.6090 - tp: 3014.4778 - fp: 911.7556 - tn: 3002.1778 - fn: 899.4556 - accuracy: 0.7725 - precision: 0.7715 - recall: 0.7746 - auc: 0.8716 - val_loss: 0.6346 - val_tp: 608.0000 - val_fp: 394.0000 - val_tn: 609.0000 - val_fn: 395.0000 - val_accuracy: 0.6067 - val_precision: 0.6068 - val_recall: 0.6062 - val_auc: 0.7415\n",
      "Epoch 2/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.4400 - tp: 2087.5778 - fp: 822.6222 - tn: 2088.3111 - fn: 823.3556 - accuracy: 0.7259 - precision: 0.7261 - recall: 0.7253 - auc: 0.8399 - val_loss: 0.6762 - val_tp: 568.0000 - val_fp: 431.0000 - val_tn: 572.0000 - val_fn: 435.0000 - val_accuracy: 0.5683 - val_precision: 0.5686 - val_recall: 0.5663 - val_auc: 0.7155\n",
      "Epoch 3/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.4440 - tp: 2046.4333 - fp: 866.4889 - tn: 2044.4444 - fn: 864.5000 - accuracy: 0.7053 - precision: 0.7052 - recall: 0.7060 - auc: 0.8289 - val_loss: 0.6112 - val_tp: 592.0000 - val_fp: 409.0000 - val_tn: 594.0000 - val_fn: 411.0000 - val_accuracy: 0.5912 - val_precision: 0.5914 - val_recall: 0.5902 - val_auc: 0.7442\n",
      "Epoch 4/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.4449 - tp: 2044.7556 - fp: 864.7333 - tn: 2046.2000 - fn: 866.1778 - accuracy: 0.7038 - precision: 0.7039 - recall: 0.7037 - auc: 0.8280 - val_loss: 0.5880 - val_tp: 623.0000 - val_fp: 385.0000 - val_tn: 618.0000 - val_fn: 380.0000 - val_accuracy: 0.6186 - val_precision: 0.6181 - val_recall: 0.6211 - val_auc: 0.7645\n",
      "Epoch 5/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.4385 - tp: 2061.7444 - fp: 850.8222 - tn: 2060.1111 - fn: 849.1889 - accuracy: 0.7136 - precision: 0.7135 - recall: 0.7141 - auc: 0.8359 - val_loss: 0.6085 - val_tp: 603.0000 - val_fp: 398.0000 - val_tn: 605.0000 - val_fn: 400.0000 - val_accuracy: 0.6022 - val_precision: 0.6024 - val_recall: 0.6012 - val_auc: 0.7514\n",
      "Epoch 6/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.4404 - tp: 2062.6444 - fp: 843.4222 - tn: 2067.5111 - fn: 848.2889 - accuracy: 0.7054 - precision: 0.7058 - recall: 0.7042 - auc: 0.8311 - val_loss: 0.6115 - val_tp: 625.0000 - val_fp: 377.0000 - val_tn: 626.0000 - val_fn: 378.0000 - val_accuracy: 0.6236 - val_precision: 0.6238 - val_recall: 0.6231 - val_auc: 0.7636\n",
      "Epoch 7/80\n",
      "89/89 [==============================] - 1s 13ms/step - loss: 0.4308 - tp: 2092.1333 - fp: 813.7667 - tn: 2097.1667 - fn: 818.8000 - accuracy: 0.7232 - precision: 0.7240 - recall: 0.7214 - auc: 0.8432 - val_loss: 0.5983 - val_tp: 622.0000 - val_fp: 377.0000 - val_tn: 626.0000 - val_fn: 381.0000 - val_accuracy: 0.6221 - val_precision: 0.6226 - val_recall: 0.6201 - val_auc: 0.7642\n",
      "Epoch 8/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.4314 - tp: 2104.5444 - fp: 811.9222 - tn: 2099.0111 - fn: 806.3889 - accuracy: 0.7198 - precision: 0.7193 - recall: 0.7210 - auc: 0.8401 - val_loss: 0.5883 - val_tp: 651.0000 - val_fp: 350.0000 - val_tn: 653.0000 - val_fn: 352.0000 - val_accuracy: 0.6500 - val_precision: 0.6503 - val_recall: 0.6491 - val_auc: 0.7792\n",
      "Epoch 9/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.4232 - tp: 2123.3778 - fp: 784.0667 - tn: 2126.8667 - fn: 787.5556 - accuracy: 0.7337 - precision: 0.7341 - recall: 0.7326 - auc: 0.8497 - val_loss: 0.5774 - val_tp: 653.0000 - val_fp: 348.0000 - val_tn: 655.0000 - val_fn: 350.0000 - val_accuracy: 0.6520 - val_precision: 0.6523 - val_recall: 0.6510 - val_auc: 0.7821\n",
      "Epoch 10/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.4230 - tp: 2135.0222 - fp: 772.1889 - tn: 2138.7444 - fn: 775.9111 - accuracy: 0.7341 - precision: 0.7345 - recall: 0.7331 - auc: 0.8483 - val_loss: 0.5756 - val_tp: 671.0000 - val_fp: 335.0000 - val_tn: 668.0000 - val_fn: 332.0000 - val_accuracy: 0.6675 - val_precision: 0.6670 - val_recall: 0.6690 - val_auc: 0.7902\n",
      "Epoch 11/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.4164 - tp: 2152.2333 - fp: 761.9111 - tn: 2149.0222 - fn: 758.7000 - accuracy: 0.7408 - precision: 0.7405 - recall: 0.7415 - auc: 0.8554 - val_loss: 0.5661 - val_tp: 676.0000 - val_fp: 322.0000 - val_tn: 681.0000 - val_fn: 327.0000 - val_accuracy: 0.6765 - val_precision: 0.6774 - val_recall: 0.6740 - val_auc: 0.7941\n",
      "Epoch 12/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.4146 - tp: 2161.8000 - fp: 748.3667 - tn: 2162.5667 - fn: 749.1333 - accuracy: 0.7434 - precision: 0.7435 - recall: 0.7432 - auc: 0.8554 - val_loss: 0.5698 - val_tp: 685.0000 - val_fp: 315.0000 - val_tn: 688.0000 - val_fn: 318.0000 - val_accuracy: 0.6844 - val_precision: 0.6850 - val_recall: 0.6830 - val_auc: 0.7962\n",
      "Epoch 13/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.4092 - tp: 2170.1444 - fp: 736.3111 - tn: 2174.6222 - fn: 740.7889 - accuracy: 0.7468 - precision: 0.7473 - recall: 0.7459 - auc: 0.8602 - val_loss: 0.5548 - val_tp: 700.0000 - val_fp: 304.0000 - val_tn: 699.0000 - val_fn: 303.0000 - val_accuracy: 0.6974 - val_precision: 0.6972 - val_recall: 0.6979 - val_auc: 0.8055\n",
      "Epoch 14/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.4059 - tp: 2177.0667 - fp: 731.0889 - tn: 2179.8444 - fn: 733.8667 - accuracy: 0.7489 - precision: 0.7492 - recall: 0.7483 - auc: 0.8615 - val_loss: 0.5538 - val_tp: 703.0000 - val_fp: 296.0000 - val_tn: 707.0000 - val_fn: 300.0000 - val_accuracy: 0.7029 - val_precision: 0.7037 - val_recall: 0.7009 - val_auc: 0.8071\n",
      "Epoch 15/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.4008 - tp: 2196.4333 - fp: 718.5111 - tn: 2192.4222 - fn: 714.5000 - accuracy: 0.7551 - precision: 0.7549 - recall: 0.7554 - auc: 0.8655 - val_loss: 0.5427 - val_tp: 710.0000 - val_fp: 292.0000 - val_tn: 711.0000 - val_fn: 293.0000 - val_accuracy: 0.7084 - val_precision: 0.7086 - val_recall: 0.7079 - val_auc: 0.8141\n",
      "Epoch 16/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3964 - tp: 2206.0556 - fp: 712.4889 - tn: 2198.4444 - fn: 704.8778 - accuracy: 0.7573 - precision: 0.7567 - recall: 0.7586 - auc: 0.8673 - val_loss: 0.5563 - val_tp: 704.0000 - val_fp: 296.0000 - val_tn: 707.0000 - val_fn: 299.0000 - val_accuracy: 0.7034 - val_precision: 0.7040 - val_recall: 0.7019 - val_auc: 0.8069\n",
      "Epoch 17/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.3929 - tp: 2213.4222 - fp: 698.8889 - tn: 2212.0444 - fn: 697.5111 - accuracy: 0.7587 - precision: 0.7586 - recall: 0.7590 - auc: 0.8683 - val_loss: 0.5408 - val_tp: 720.0000 - val_fp: 283.0000 - val_tn: 720.0000 - val_fn: 283.0000 - val_accuracy: 0.7178 - val_precision: 0.7178 - val_recall: 0.7178 - val_auc: 0.8200\n",
      "Epoch 18/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3843 - tp: 2231.2889 - fp: 680.1111 - tn: 2230.8222 - fn: 679.6444 - accuracy: 0.7665 - precision: 0.7666 - recall: 0.7662 - auc: 0.8745 - val_loss: 0.5221 - val_tp: 731.0000 - val_fp: 277.0000 - val_tn: 726.0000 - val_fn: 272.0000 - val_accuracy: 0.7263 - val_precision: 0.7252 - val_recall: 0.7288 - val_auc: 0.8278\n",
      "Epoch 19/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.3788 - tp: 2241.7333 - fp: 667.6444 - tn: 2243.2889 - fn: 669.2000 - accuracy: 0.7704 - precision: 0.7707 - recall: 0.7699 - auc: 0.8773 - val_loss: 0.5228 - val_tp: 729.0000 - val_fp: 275.0000 - val_tn: 728.0000 - val_fn: 274.0000 - val_accuracy: 0.7263 - val_precision: 0.7261 - val_recall: 0.7268 - val_auc: 0.8306\n",
      "Epoch 20/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3720 - tp: 2253.7111 - fp: 658.5222 - tn: 2252.4111 - fn: 657.2222 - accuracy: 0.7742 - precision: 0.7743 - recall: 0.7741 - auc: 0.8808 - val_loss: 0.5066 - val_tp: 737.0000 - val_fp: 270.0000 - val_tn: 733.0000 - val_fn: 266.0000 - val_accuracy: 0.7328 - val_precision: 0.7319 - val_recall: 0.7348 - val_auc: 0.8388\n",
      "Epoch 21/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.3648 - tp: 2265.0111 - fp: 645.5000 - tn: 2265.4333 - fn: 645.9222 - accuracy: 0.7786 - precision: 0.7785 - recall: 0.7787 - auc: 0.8850 - val_loss: 0.5141 - val_tp: 737.0000 - val_fp: 272.0000 - val_tn: 731.0000 - val_fn: 266.0000 - val_accuracy: 0.7318 - val_precision: 0.7304 - val_recall: 0.7348 - val_auc: 0.8386\n",
      "Epoch 22/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.3586 - tp: 2281.2556 - fp: 633.2111 - tn: 2277.7222 - fn: 629.6778 - accuracy: 0.7829 - precision: 0.7825 - recall: 0.7836 - auc: 0.8876 - val_loss: 0.5089 - val_tp: 734.0000 - val_fp: 275.0000 - val_tn: 728.0000 - val_fn: 269.0000 - val_accuracy: 0.7288 - val_precision: 0.7275 - val_recall: 0.7318 - val_auc: 0.8409\n",
      "Epoch 23/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.3533 - tp: 2284.9889 - fp: 629.9667 - tn: 2280.9667 - fn: 625.9444 - accuracy: 0.7832 - precision: 0.7827 - recall: 0.7839 - auc: 0.8895 - val_loss: 0.5086 - val_tp: 735.0000 - val_fp: 270.0000 - val_tn: 733.0000 - val_fn: 268.0000 - val_accuracy: 0.7318 - val_precision: 0.7313 - val_recall: 0.7328 - val_auc: 0.8441\n",
      "Epoch 24/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3470 - tp: 2292.0444 - fp: 618.7889 - tn: 2292.1444 - fn: 618.8889 - accuracy: 0.7859 - precision: 0.7859 - recall: 0.7859 - auc: 0.8932 - val_loss: 0.4911 - val_tp: 746.0000 - val_fp: 261.0000 - val_tn: 742.0000 - val_fn: 257.0000 - val_accuracy: 0.7418 - val_precision: 0.7408 - val_recall: 0.7438 - val_auc: 0.8537\n",
      "Epoch 25/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3410 - tp: 2301.1444 - fp: 609.6889 - tn: 2301.2444 - fn: 609.7889 - accuracy: 0.7883 - precision: 0.7882 - recall: 0.7883 - auc: 0.8958 - val_loss: 0.4962 - val_tp: 740.0000 - val_fp: 259.0000 - val_tn: 744.0000 - val_fn: 263.0000 - val_accuracy: 0.7398 - val_precision: 0.7407 - val_recall: 0.7378 - val_auc: 0.8519\n",
      "Epoch 26/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3351 - tp: 2316.1333 - fp: 598.6889 - tn: 2312.2444 - fn: 594.8000 - accuracy: 0.7912 - precision: 0.7907 - recall: 0.7919 - auc: 0.8983 - val_loss: 0.4894 - val_tp: 752.0000 - val_fp: 251.0000 - val_tn: 752.0000 - val_fn: 251.0000 - val_accuracy: 0.7498 - val_precision: 0.7498 - val_recall: 0.7498 - val_auc: 0.8588\n",
      "Epoch 27/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3280 - tp: 2331.1333 - fp: 578.5556 - tn: 2332.3778 - fn: 579.8000 - accuracy: 0.7986 - precision: 0.7988 - recall: 0.7981 - auc: 0.9029 - val_loss: 0.4810 - val_tp: 753.0000 - val_fp: 252.0000 - val_tn: 751.0000 - val_fn: 250.0000 - val_accuracy: 0.7498 - val_precision: 0.7493 - val_recall: 0.7507 - val_auc: 0.8618\n",
      "Epoch 28/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3221 - tp: 2351.2222 - fp: 558.5444 - tn: 2352.3889 - fn: 559.7111 - accuracy: 0.8029 - precision: 0.8033 - recall: 0.8023 - auc: 0.9052 - val_loss: 0.4654 - val_tp: 765.0000 - val_fp: 237.0000 - val_tn: 766.0000 - val_fn: 238.0000 - val_accuracy: 0.7632 - val_precision: 0.7635 - val_recall: 0.7627 - val_auc: 0.8710\n",
      "Epoch 29/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3134 - tp: 2371.5889 - fp: 537.3111 - tn: 2373.6222 - fn: 539.3444 - accuracy: 0.8113 - precision: 0.8117 - recall: 0.8106 - auc: 0.9104 - val_loss: 0.4747 - val_tp: 762.0000 - val_fp: 240.0000 - val_tn: 763.0000 - val_fn: 241.0000 - val_accuracy: 0.7602 - val_precision: 0.7605 - val_recall: 0.7597 - val_auc: 0.8675\n",
      "Epoch 30/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3077 - tp: 2384.0889 - fp: 524.8667 - tn: 2386.0667 - fn: 526.8444 - accuracy: 0.8146 - precision: 0.8150 - recall: 0.8141 - auc: 0.9123 - val_loss: 0.4637 - val_tp: 776.0000 - val_fp: 229.0000 - val_tn: 774.0000 - val_fn: 227.0000 - val_accuracy: 0.7727 - val_precision: 0.7721 - val_recall: 0.7737 - val_auc: 0.8755\n",
      "Epoch 31/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.3004 - tp: 2401.4556 - fp: 507.9333 - tn: 2403.0000 - fn: 509.4778 - accuracy: 0.8207 - precision: 0.8210 - recall: 0.8202 - auc: 0.9167 - val_loss: 0.4515 - val_tp: 783.0000 - val_fp: 222.0000 - val_tn: 781.0000 - val_fn: 220.0000 - val_accuracy: 0.7797 - val_precision: 0.7791 - val_recall: 0.7807 - val_auc: 0.8805\n",
      "Epoch 32/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2921 - tp: 2411.7222 - fp: 494.0667 - tn: 2416.8667 - fn: 499.2111 - accuracy: 0.8253 - precision: 0.8258 - recall: 0.8246 - auc: 0.9204 - val_loss: 0.4393 - val_tp: 790.0000 - val_fp: 217.0000 - val_tn: 786.0000 - val_fn: 213.0000 - val_accuracy: 0.7856 - val_precision: 0.7845 - val_recall: 0.7876 - val_auc: 0.8870\n",
      "Epoch 33/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2861 - tp: 2430.4111 - fp: 479.1889 - tn: 2431.7444 - fn: 480.5222 - accuracy: 0.8318 - precision: 0.8315 - recall: 0.8323 - auc: 0.9236 - val_loss: 0.4280 - val_tp: 797.0000 - val_fp: 211.0000 - val_tn: 792.0000 - val_fn: 206.0000 - val_accuracy: 0.7921 - val_precision: 0.7907 - val_recall: 0.7946 - val_auc: 0.8921\n",
      "Epoch 34/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.2803 - tp: 2447.4333 - fp: 470.8111 - tn: 2440.1222 - fn: 463.5000 - accuracy: 0.8361 - precision: 0.8350 - recall: 0.8377 - auc: 0.9261 - val_loss: 0.4214 - val_tp: 803.0000 - val_fp: 211.0000 - val_tn: 792.0000 - val_fn: 200.0000 - val_accuracy: 0.7951 - val_precision: 0.7919 - val_recall: 0.8006 - val_auc: 0.8959\n",
      "Epoch 35/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2740 - tp: 2457.5000 - fp: 461.5333 - tn: 2449.4000 - fn: 453.4333 - accuracy: 0.8395 - precision: 0.8382 - recall: 0.8414 - auc: 0.9289 - val_loss: 0.4043 - val_tp: 806.0000 - val_fp: 197.0000 - val_tn: 806.0000 - val_fn: 197.0000 - val_accuracy: 0.8036 - val_precision: 0.8036 - val_recall: 0.8036 - val_auc: 0.9042\n",
      "Epoch 36/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.2669 - tp: 2462.6444 - fp: 443.2111 - tn: 2467.7222 - fn: 448.2889 - accuracy: 0.8439 - precision: 0.8444 - recall: 0.8431 - auc: 0.9329 - val_loss: 0.4040 - val_tp: 808.0000 - val_fp: 196.0000 - val_tn: 807.0000 - val_fn: 195.0000 - val_accuracy: 0.8051 - val_precision: 0.8048 - val_recall: 0.8056 - val_auc: 0.9050\n",
      "Epoch 37/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2619 - tp: 2474.4889 - fp: 435.3778 - tn: 2475.5556 - fn: 436.4444 - accuracy: 0.8472 - precision: 0.8473 - recall: 0.8471 - auc: 0.9349 - val_loss: 0.3983 - val_tp: 814.0000 - val_fp: 191.0000 - val_tn: 812.0000 - val_fn: 189.0000 - val_accuracy: 0.8106 - val_precision: 0.8100 - val_recall: 0.8116 - val_auc: 0.9083\n",
      "Epoch 38/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2571 - tp: 2486.6111 - fp: 431.7444 - tn: 2479.1889 - fn: 424.3222 - accuracy: 0.8495 - precision: 0.8486 - recall: 0.8508 - auc: 0.9370 - val_loss: 0.3882 - val_tp: 818.0000 - val_fp: 185.0000 - val_tn: 818.0000 - val_fn: 185.0000 - val_accuracy: 0.8156 - val_precision: 0.8156 - val_recall: 0.8156 - val_auc: 0.9134\n",
      "Epoch 39/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.2508 - tp: 2497.5889 - fp: 417.0667 - tn: 2493.8667 - fn: 413.3444 - accuracy: 0.8539 - precision: 0.8532 - recall: 0.8549 - auc: 0.9403 - val_loss: 0.3827 - val_tp: 819.0000 - val_fp: 185.0000 - val_tn: 818.0000 - val_fn: 184.0000 - val_accuracy: 0.8161 - val_precision: 0.8157 - val_recall: 0.8166 - val_auc: 0.9156\n",
      "Epoch 40/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2458 - tp: 2501.8333 - fp: 409.6889 - tn: 2501.2444 - fn: 409.1000 - accuracy: 0.8551 - precision: 0.8549 - recall: 0.8554 - auc: 0.9421 - val_loss: 0.3799 - val_tp: 821.0000 - val_fp: 181.0000 - val_tn: 822.0000 - val_fn: 182.0000 - val_accuracy: 0.8190 - val_precision: 0.8194 - val_recall: 0.8185 - val_auc: 0.9180\n",
      "Epoch 41/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.2410 - tp: 2506.5000 - fp: 396.5222 - tn: 2514.4111 - fn: 404.4333 - accuracy: 0.8575 - precision: 0.8585 - recall: 0.8561 - auc: 0.9444 - val_loss: 0.3788 - val_tp: 820.0000 - val_fp: 182.0000 - val_tn: 821.0000 - val_fn: 183.0000 - val_accuracy: 0.8180 - val_precision: 0.8184 - val_recall: 0.8175 - val_auc: 0.9186\n",
      "Epoch 42/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.2368 - tp: 2525.0444 - fp: 388.0556 - tn: 2522.8778 - fn: 385.8889 - accuracy: 0.8613 - precision: 0.8609 - recall: 0.8618 - auc: 0.9459 - val_loss: 0.3692 - val_tp: 823.0000 - val_fp: 174.0000 - val_tn: 829.0000 - val_fn: 180.0000 - val_accuracy: 0.8235 - val_precision: 0.8255 - val_recall: 0.8205 - val_auc: 0.9242\n",
      "Epoch 43/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.2302 - tp: 2532.1889 - fp: 374.8222 - tn: 2536.1111 - fn: 378.7444 - accuracy: 0.8657 - precision: 0.8664 - recall: 0.8648 - auc: 0.9495 - val_loss: 0.3681 - val_tp: 825.0000 - val_fp: 174.0000 - val_tn: 829.0000 - val_fn: 178.0000 - val_accuracy: 0.8245 - val_precision: 0.8258 - val_recall: 0.8225 - val_auc: 0.9242\n",
      "Epoch 44/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.2270 - tp: 2537.6889 - fp: 372.4778 - tn: 2538.4556 - fn: 373.2444 - accuracy: 0.8663 - precision: 0.8663 - recall: 0.8661 - auc: 0.9500 - val_loss: 0.3554 - val_tp: 835.0000 - val_fp: 166.0000 - val_tn: 837.0000 - val_fn: 168.0000 - val_accuracy: 0.8335 - val_precision: 0.8342 - val_recall: 0.8325 - val_auc: 0.9299\n",
      "Epoch 45/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2218 - tp: 2546.8333 - fp: 360.7667 - tn: 2550.1667 - fn: 364.1000 - accuracy: 0.8701 - precision: 0.8705 - recall: 0.8696 - auc: 0.9528 - val_loss: 0.3558 - val_tp: 834.0000 - val_fp: 168.0000 - val_tn: 835.0000 - val_fn: 169.0000 - val_accuracy: 0.8320 - val_precision: 0.8323 - val_recall: 0.8315 - val_auc: 0.9298\n",
      "Epoch 46/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2178 - tp: 2556.6000 - fp: 354.1000 - tn: 2556.8333 - fn: 354.3333 - accuracy: 0.8724 - precision: 0.8723 - recall: 0.8724 - auc: 0.9540 - val_loss: 0.3446 - val_tp: 842.0000 - val_fp: 161.0000 - val_tn: 842.0000 - val_fn: 161.0000 - val_accuracy: 0.8395 - val_precision: 0.8395 - val_recall: 0.8395 - val_auc: 0.9343\n",
      "Epoch 47/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2128 - tp: 2564.6222 - fp: 345.8444 - tn: 2565.0889 - fn: 346.3111 - accuracy: 0.8755 - precision: 0.8756 - recall: 0.8753 - auc: 0.9564 - val_loss: 0.3437 - val_tp: 844.0000 - val_fp: 159.0000 - val_tn: 844.0000 - val_fn: 159.0000 - val_accuracy: 0.8415 - val_precision: 0.8415 - val_recall: 0.8415 - val_auc: 0.9353\n",
      "Epoch 48/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.2090 - tp: 2579.1444 - fp: 337.3556 - tn: 2573.5778 - fn: 331.7889 - accuracy: 0.8791 - precision: 0.8784 - recall: 0.8800 - auc: 0.9578 - val_loss: 0.3420 - val_tp: 842.0000 - val_fp: 155.0000 - val_tn: 848.0000 - val_fn: 161.0000 - val_accuracy: 0.8425 - val_precision: 0.8445 - val_recall: 0.8395 - val_auc: 0.9361\n",
      "Epoch 49/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2050 - tp: 2587.4667 - fp: 325.7222 - tn: 2585.2111 - fn: 323.4667 - accuracy: 0.8825 - precision: 0.8823 - recall: 0.8829 - auc: 0.9592 - val_loss: 0.3375 - val_tp: 845.0000 - val_fp: 150.0000 - val_tn: 853.0000 - val_fn: 158.0000 - val_accuracy: 0.8465 - val_precision: 0.8492 - val_recall: 0.8425 - val_auc: 0.9383\n",
      "Epoch 50/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.2009 - tp: 2591.0667 - fp: 321.4889 - tn: 2589.4444 - fn: 319.8667 - accuracy: 0.8839 - precision: 0.8838 - recall: 0.8840 - auc: 0.9607 - val_loss: 0.3324 - val_tp: 849.0000 - val_fp: 148.0000 - val_tn: 855.0000 - val_fn: 154.0000 - val_accuracy: 0.8495 - val_precision: 0.8516 - val_recall: 0.8465 - val_auc: 0.9405\n",
      "Epoch 51/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1968 - tp: 2600.7000 - fp: 311.9000 - tn: 2599.0333 - fn: 310.2333 - accuracy: 0.8867 - precision: 0.8867 - recall: 0.8867 - auc: 0.9623 - val_loss: 0.3319 - val_tp: 850.0000 - val_fp: 145.0000 - val_tn: 858.0000 - val_fn: 153.0000 - val_accuracy: 0.8514 - val_precision: 0.8543 - val_recall: 0.8475 - val_auc: 0.9412\n",
      "Epoch 52/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1928 - tp: 2606.3889 - fp: 306.5556 - tn: 2604.3778 - fn: 304.5444 - accuracy: 0.8890 - precision: 0.8888 - recall: 0.8892 - auc: 0.9637 - val_loss: 0.3256 - val_tp: 854.0000 - val_fp: 141.0000 - val_tn: 862.0000 - val_fn: 149.0000 - val_accuracy: 0.8554 - val_precision: 0.8583 - val_recall: 0.8514 - val_auc: 0.9438\n",
      "Epoch 53/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.1890 - tp: 2614.1667 - fp: 294.6000 - tn: 2616.3333 - fn: 296.7667 - accuracy: 0.8925 - precision: 0.8928 - recall: 0.8920 - auc: 0.9650 - val_loss: 0.3218 - val_tp: 855.0000 - val_fp: 139.0000 - val_tn: 864.0000 - val_fn: 148.0000 - val_accuracy: 0.8569 - val_precision: 0.8602 - val_recall: 0.8524 - val_auc: 0.9455\n",
      "Epoch 54/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1841 - tp: 2623.3444 - fp: 286.9889 - tn: 2623.9444 - fn: 287.5889 - accuracy: 0.8957 - precision: 0.8959 - recall: 0.8955 - auc: 0.9669 - val_loss: 0.3252 - val_tp: 855.0000 - val_fp: 139.0000 - val_tn: 864.0000 - val_fn: 148.0000 - val_accuracy: 0.8569 - val_precision: 0.8602 - val_recall: 0.8524 - val_auc: 0.9449\n",
      "Epoch 55/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1803 - tp: 2634.7111 - fp: 277.4444 - tn: 2633.4889 - fn: 276.2222 - accuracy: 0.8995 - precision: 0.8998 - recall: 0.8990 - auc: 0.9682 - val_loss: 0.3205 - val_tp: 858.0000 - val_fp: 138.0000 - val_tn: 865.0000 - val_fn: 145.0000 - val_accuracy: 0.8589 - val_precision: 0.8614 - val_recall: 0.8554 - val_auc: 0.9464\n",
      "Epoch 56/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1765 - tp: 2643.1778 - fp: 271.9222 - tn: 2639.0111 - fn: 267.7556 - accuracy: 0.9019 - precision: 0.9021 - recall: 0.9017 - auc: 0.9694 - val_loss: 0.3155 - val_tp: 862.0000 - val_fp: 132.0000 - val_tn: 871.0000 - val_fn: 141.0000 - val_accuracy: 0.8639 - val_precision: 0.8672 - val_recall: 0.8594 - val_auc: 0.9486\n",
      "Epoch 57/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1723 - tp: 2649.4333 - fp: 262.2556 - tn: 2648.6778 - fn: 261.5000 - accuracy: 0.9056 - precision: 0.9060 - recall: 0.9051 - auc: 0.9707 - val_loss: 0.3165 - val_tp: 864.0000 - val_fp: 132.0000 - val_tn: 871.0000 - val_fn: 139.0000 - val_accuracy: 0.8649 - val_precision: 0.8675 - val_recall: 0.8614 - val_auc: 0.9491\n",
      "Epoch 58/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1686 - tp: 2653.0778 - fp: 259.0444 - tn: 2651.8889 - fn: 257.8556 - accuracy: 0.9066 - precision: 0.9069 - recall: 0.9062 - auc: 0.9719 - val_loss: 0.3154 - val_tp: 866.0000 - val_fp: 134.0000 - val_tn: 869.0000 - val_fn: 137.0000 - val_accuracy: 0.8649 - val_precision: 0.8660 - val_recall: 0.8634 - val_auc: 0.9499\n",
      "Epoch 59/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1644 - tp: 2661.1111 - fp: 254.2556 - tn: 2656.6778 - fn: 249.8222 - accuracy: 0.9087 - precision: 0.9084 - recall: 0.9090 - auc: 0.9733 - val_loss: 0.3092 - val_tp: 869.0000 - val_fp: 132.0000 - val_tn: 871.0000 - val_fn: 134.0000 - val_accuracy: 0.8674 - val_precision: 0.8681 - val_recall: 0.8664 - val_auc: 0.9520\n",
      "Epoch 60/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.1606 - tp: 2666.0889 - fp: 251.6444 - tn: 2659.2889 - fn: 244.8444 - accuracy: 0.9099 - precision: 0.9092 - recall: 0.9107 - auc: 0.9744 - val_loss: 0.3151 - val_tp: 868.0000 - val_fp: 133.0000 - val_tn: 870.0000 - val_fn: 135.0000 - val_accuracy: 0.8664 - val_precision: 0.8671 - val_recall: 0.8654 - val_auc: 0.9507\n",
      "Epoch 61/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.1566 - tp: 2672.2333 - fp: 243.8000 - tn: 2667.1333 - fn: 238.7000 - accuracy: 0.9126 - precision: 0.9119 - recall: 0.9135 - auc: 0.9755 - val_loss: 0.3098 - val_tp: 870.0000 - val_fp: 131.0000 - val_tn: 872.0000 - val_fn: 133.0000 - val_accuracy: 0.8684 - val_precision: 0.8691 - val_recall: 0.8674 - val_auc: 0.9522\n",
      "Epoch 62/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.1527 - tp: 2676.5444 - fp: 236.5111 - tn: 2674.4222 - fn: 234.3889 - accuracy: 0.9146 - precision: 0.9145 - recall: 0.9148 - auc: 0.9766 - val_loss: 0.3098 - val_tp: 871.0000 - val_fp: 127.0000 - val_tn: 876.0000 - val_fn: 132.0000 - val_accuracy: 0.8709 - val_precision: 0.8727 - val_recall: 0.8684 - val_auc: 0.9526\n",
      "Epoch 63/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1487 - tp: 2686.0667 - fp: 228.5889 - tn: 2682.3444 - fn: 224.8667 - accuracy: 0.9179 - precision: 0.9172 - recall: 0.9187 - auc: 0.9779 - val_loss: 0.3007 - val_tp: 878.0000 - val_fp: 123.0000 - val_tn: 880.0000 - val_fn: 125.0000 - val_accuracy: 0.8764 - val_precision: 0.8771 - val_recall: 0.8754 - val_auc: 0.9555\n",
      "Epoch 64/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1447 - tp: 2692.9667 - fp: 223.2333 - tn: 2687.7000 - fn: 217.9667 - accuracy: 0.9201 - precision: 0.9197 - recall: 0.9206 - auc: 0.9790 - val_loss: 0.3063 - val_tp: 879.0000 - val_fp: 123.0000 - val_tn: 880.0000 - val_fn: 124.0000 - val_accuracy: 0.8769 - val_precision: 0.8772 - val_recall: 0.8764 - val_auc: 0.9542\n",
      "Epoch 65/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1408 - tp: 2702.3444 - fp: 215.7556 - tn: 2695.1778 - fn: 208.5889 - accuracy: 0.9231 - precision: 0.9225 - recall: 0.9237 - auc: 0.9801 - val_loss: 0.3012 - val_tp: 882.0000 - val_fp: 117.0000 - val_tn: 886.0000 - val_fn: 121.0000 - val_accuracy: 0.8814 - val_precision: 0.8829 - val_recall: 0.8794 - val_auc: 0.9556\n",
      "Epoch 66/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1376 - tp: 2703.5556 - fp: 209.1333 - tn: 2701.8000 - fn: 207.3778 - accuracy: 0.9240 - precision: 0.9242 - recall: 0.9239 - auc: 0.9808 - val_loss: 0.3029 - val_tp: 885.0000 - val_fp: 112.0000 - val_tn: 891.0000 - val_fn: 118.0000 - val_accuracy: 0.8853 - val_precision: 0.8877 - val_recall: 0.8824 - val_auc: 0.9556\n",
      "Epoch 67/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.1327 - tp: 2713.0222 - fp: 201.0000 - tn: 2709.9333 - fn: 197.9111 - accuracy: 0.9277 - precision: 0.9275 - recall: 0.9278 - auc: 0.9822 - val_loss: 0.2972 - val_tp: 887.0000 - val_fp: 113.0000 - val_tn: 890.0000 - val_fn: 116.0000 - val_accuracy: 0.8858 - val_precision: 0.8870 - val_recall: 0.8843 - val_auc: 0.9576\n",
      "Epoch 68/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.1296 - tp: 2717.1556 - fp: 195.9333 - tn: 2715.0000 - fn: 193.7778 - accuracy: 0.9288 - precision: 0.9289 - recall: 0.9286 - auc: 0.9829 - val_loss: 0.3043 - val_tp: 887.0000 - val_fp: 116.0000 - val_tn: 887.0000 - val_fn: 116.0000 - val_accuracy: 0.8843 - val_precision: 0.8843 - val_recall: 0.8843 - val_auc: 0.9565\n",
      "Epoch 69/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1256 - tp: 2723.9556 - fp: 184.1667 - tn: 2726.7667 - fn: 186.9778 - accuracy: 0.9327 - precision: 0.9336 - recall: 0.9316 - auc: 0.9840 - val_loss: 0.3025 - val_tp: 887.0000 - val_fp: 116.0000 - val_tn: 887.0000 - val_fn: 116.0000 - val_accuracy: 0.8843 - val_precision: 0.8843 - val_recall: 0.8843 - val_auc: 0.9575\n",
      "Epoch 70/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.1217 - tp: 2731.5111 - fp: 179.0333 - tn: 2731.9000 - fn: 179.4222 - accuracy: 0.9347 - precision: 0.9352 - recall: 0.9340 - auc: 0.9848 - val_loss: 0.2984 - val_tp: 888.0000 - val_fp: 115.0000 - val_tn: 888.0000 - val_fn: 115.0000 - val_accuracy: 0.8853 - val_precision: 0.8853 - val_recall: 0.8853 - val_auc: 0.9589\n",
      "Epoch 71/80\n",
      "89/89 [==============================] - 1s 16ms/step - loss: 0.1178 - tp: 2738.7667 - fp: 171.2667 - tn: 2739.6667 - fn: 172.1667 - accuracy: 0.9372 - precision: 0.9378 - recall: 0.9365 - auc: 0.9857 - val_loss: 0.2980 - val_tp: 889.0000 - val_fp: 115.0000 - val_tn: 888.0000 - val_fn: 114.0000 - val_accuracy: 0.8858 - val_precision: 0.8855 - val_recall: 0.8863 - val_auc: 0.9591\n",
      "Epoch 72/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1138 - tp: 2744.3889 - fp: 167.0333 - tn: 2743.9000 - fn: 166.5444 - accuracy: 0.9391 - precision: 0.9396 - recall: 0.9385 - auc: 0.9865 - val_loss: 0.2924 - val_tp: 893.0000 - val_fp: 114.0000 - val_tn: 889.0000 - val_fn: 110.0000 - val_accuracy: 0.8883 - val_precision: 0.8868 - val_recall: 0.8903 - val_auc: 0.9609\n",
      "Epoch 73/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.1102 - tp: 2749.3222 - fp: 160.1889 - tn: 2750.7444 - fn: 161.6111 - accuracy: 0.9410 - precision: 0.9417 - recall: 0.9402 - auc: 0.9873 - val_loss: 0.2909 - val_tp: 894.0000 - val_fp: 111.0000 - val_tn: 892.0000 - val_fn: 109.0000 - val_accuracy: 0.8903 - val_precision: 0.8896 - val_recall: 0.8913 - val_auc: 0.9617\n",
      "Epoch 74/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1063 - tp: 2756.0333 - fp: 153.5778 - tn: 2757.3556 - fn: 154.9000 - accuracy: 0.9434 - precision: 0.9442 - recall: 0.9424 - auc: 0.9881 - val_loss: 0.2904 - val_tp: 895.0000 - val_fp: 110.0000 - val_tn: 893.0000 - val_fn: 108.0000 - val_accuracy: 0.8913 - val_precision: 0.8905 - val_recall: 0.8923 - val_auc: 0.9624\n",
      "Epoch 75/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.1025 - tp: 2762.6222 - fp: 146.6778 - tn: 2764.2556 - fn: 148.3111 - accuracy: 0.9459 - precision: 0.9468 - recall: 0.9450 - auc: 0.9889 - val_loss: 0.2803 - val_tp: 900.0000 - val_fp: 104.0000 - val_tn: 899.0000 - val_fn: 103.0000 - val_accuracy: 0.8968 - val_precision: 0.8964 - val_recall: 0.8973 - val_auc: 0.9648\n",
      "Epoch 76/80\n",
      "89/89 [==============================] - 1s 15ms/step - loss: 0.0984 - tp: 2765.4778 - fp: 143.8444 - tn: 2767.0889 - fn: 145.4556 - accuracy: 0.9467 - precision: 0.9476 - recall: 0.9456 - auc: 0.9897 - val_loss: 0.2800 - val_tp: 901.0000 - val_fp: 103.0000 - val_tn: 900.0000 - val_fn: 102.0000 - val_accuracy: 0.8978 - val_precision: 0.8974 - val_recall: 0.8983 - val_auc: 0.9654\n",
      "Epoch 77/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.0947 - tp: 2774.7222 - fp: 139.8778 - tn: 2771.0556 - fn: 136.2111 - accuracy: 0.9491 - precision: 0.9490 - recall: 0.9492 - auc: 0.9904 - val_loss: 0.2850 - val_tp: 897.0000 - val_fp: 104.0000 - val_tn: 899.0000 - val_fn: 106.0000 - val_accuracy: 0.8953 - val_precision: 0.8961 - val_recall: 0.8943 - val_auc: 0.9648\n",
      "Epoch 78/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.0912 - tp: 2780.3000 - fp: 134.5333 - tn: 2776.4000 - fn: 130.6333 - accuracy: 0.9508 - precision: 0.9504 - recall: 0.9512 - auc: 0.9909 - val_loss: 0.2736 - val_tp: 907.0000 - val_fp: 93.0000 - val_tn: 910.0000 - val_fn: 96.0000 - val_accuracy: 0.9058 - val_precision: 0.9070 - val_recall: 0.9043 - val_auc: 0.9679\n",
      "Epoch 79/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.0877 - tp: 2788.2111 - fp: 127.0333 - tn: 2783.9000 - fn: 122.7222 - accuracy: 0.9535 - precision: 0.9531 - recall: 0.9540 - auc: 0.9916 - val_loss: 0.2696 - val_tp: 909.0000 - val_fp: 87.0000 - val_tn: 916.0000 - val_fn: 94.0000 - val_accuracy: 0.9098 - val_precision: 0.9127 - val_recall: 0.9063 - val_auc: 0.9690\n",
      "Epoch 80/80\n",
      "89/89 [==============================] - 1s 14ms/step - loss: 0.0839 - tp: 2792.1000 - fp: 118.6556 - tn: 2792.2778 - fn: 118.8333 - accuracy: 0.9561 - precision: 0.9564 - recall: 0.9557 - auc: 0.9923 - val_loss: 0.2579 - val_tp: 913.0000 - val_fp: 82.0000 - val_tn: 921.0000 - val_fn: 90.0000 - val_accuracy: 0.9143 - val_precision: 0.9176 - val_recall: 0.9103 - val_auc: 0.9712\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d9b12cb12f27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0mhistories_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mhistories_byfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0mmodels_byfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'histories_byfold' is not defined"
     ]
    }
   ],
   "source": [
    "######### train test split ###############\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "######################\n",
    "# Set training process params, class weights (get class weights from the train/test split, below)\n",
    "batch_size = 64 # 67\n",
    "epochs = 80 # 50\n",
    "\n",
    "number_models= 5\n",
    "\n",
    "\n",
    "###################\n",
    "# construct metrics\n",
    "metrics = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "###################\n",
    "\n",
    "\n",
    "# full list of models and histories\n",
    "models=list()\n",
    "histories=list()\n",
    "histories_all = list()\n",
    "\n",
    "\n",
    "\n",
    "##################### ##################### ##################### \n",
    "# CNN MODEL\n",
    "##################### ##################### ##################### \n",
    "\n",
    "\n",
    "X_cnn, X_val, y_cnn, y_val, file_cnn, file_val = train_test_split(X, y, file, stratify = y, test_size=0.15, random_state=0)\n",
    "\n",
    "\n",
    "# compute class weights an assign to variable for model below\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y),y)\n",
    "weight = {0: class_weights[0], 1: class_weights[1]}\n",
    "print(weight)\n",
    "\n",
    "# scale Xs and convert Ys to categorical\n",
    "X_cnn, X_val = X_cnn/255, X_val/255\n",
    "y_cnn, y_val = to_categorical(y_cnn), to_categorical(y_val)\n",
    "\n",
    "\n",
    "\n",
    "# run ensemble CNN model for each kfold\n",
    "for i in range(0,number_models):\n",
    "  print(i)\n",
    "  model = createModel()\n",
    "  model.compile(optimizer='adamax', loss=keras.losses.BinaryCrossentropy(), metrics=metrics)\n",
    "  history = model.fit(X_cnn, y_cnn,\n",
    "                      batch_size=batch_size, \n",
    "                      epochs=epochs, verbose=1, class_weight = weight,\n",
    "                      validation_data = (X_val, y_val),\n",
    "                      # callbacks=[early_stopping], # this stops the training when the metric listed in model.compile has stopped improving\n",
    "                      shuffle=False)\n",
    "  \n",
    "  # append to revolving models and histories list, in order to later append to full list of models and history\n",
    "  models.append(model)\n",
    "  histories.append(history.history)\n",
    "  # append all histories for each model in each fold, to plot later\n",
    "  histories_all.append(history.history)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-4zjuDp2rhu",
    "outputId": "48b665c8-61d8-42b3-91e3-319a60f00e5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/COLAB/train_using_all_data/ensemblemodel_-0/assets\n",
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/COLAB/train_using_all_data/ensemblemodel_-1/assets\n",
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/COLAB/train_using_all_data/ensemblemodel_-2/assets\n",
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/COLAB/train_using_all_data/ensemblemodel_-3/assets\n",
      "INFO:tensorflow:Assets written to: /content/drive/MyDrive/COLAB/train_using_all_data/ensemblemodel_-4/assets\n"
     ]
    }
   ],
   "source": [
    "# save histories and models\n",
    "import pickle\n",
    "\n",
    "for model in range(0,5):\n",
    "  path = 'ML_models/ensemblemodel' + '-' + str(model)\n",
    "  models[model].save(path)\n",
    "\n",
    "with open(\"ML_models/ensemblemodel_histories.dat\", \"wb\") as f:\n",
    "  pickle.dump(histories, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubnm5rDaUB6X"
   },
   "source": [
    "# MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7jEW_o21T-6a",
    "outputId": "84be6c12-3868-4276-eaec-44a05e5aeb75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "####################################\n",
    "###### scale and classify! ######\n",
    "####################################\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# define and fit scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "\n",
    "################## define and run model itself, after you've found good params ########\n",
    "mlp = MLPClassifier(hidden_layer_sizes= (100, 50),\n",
    "                    activation = 'relu',\n",
    "                    solver = 'lbfgs',\n",
    "                    alpha = 1e-5,\n",
    "                    learning_rate = 'constant',\n",
    "                    random_state = 0, max_iter=5000)\n",
    "\n",
    "pipe = Pipeline(steps =[('scaler',scaler) , ('MLPClassifier', mlp)])\n",
    "\n",
    "\n",
    "\n",
    "pipes = list()\n",
    "\n",
    "# reshape X array to 2-dimensions\n",
    "nsamples, nx, ny = Xmlp.shape\n",
    "Xmlp = Xmlp.reshape((nsamples, nx*ny))\n",
    "\n",
    "# resample training data\n",
    "over = SMOTE(sampling_strategy = .1)\n",
    "under = RandomUnderSampler(sampling_strategy=1)\n",
    "Xmlp, y = over.fit_resample(Xmlp, y)\n",
    "Xmlp, y = under.fit_resample(Xmlp, y)\n",
    "\n",
    "# run it\n",
    "\n",
    "for i in range(0,5):\n",
    "    \n",
    "    pipe.fit(Xmlp, y)\n",
    "    \n",
    "    pipes.append(pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "T0n51vNWWLA0"
   },
   "outputs": [],
   "source": [
    "# save the models\n",
    "import pickle as pkl\n",
    "\n",
    "path  = '/ML_models/MLP/'\n",
    "file = path+'mlp_models.pkl'\n",
    "with open(file, 'wb') as f:\n",
    "    pkl.dump(pipes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqf7m78Gs0EQ"
   },
   "source": [
    "# Plot accuracy and loss for full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "MvmSHrI4ABH5",
    "outputId": "6cd854c0-6f2d-4f1f-b101-7e955b94e22a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "hists = histories_all\n",
    "\n",
    "# fig size\n",
    "mpl.rcParams['figure.figsize'] = (6, 5)\n",
    "\n",
    "# create figure and axis objects with subplots()\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# make a plot\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Accuracy\",color=\"black\")\n",
    "\n",
    "ax2=ax.twinx()\n",
    "ax2.set_ylim(0,2.6)\n",
    "ax2.set_ylabel(\"Loss\",color=\"black\")\n",
    "\n",
    "for h in range(0,5):\n",
    "  a, = ax.plot(hists[h]['accuracy'], color=\"black\")\n",
    "  l, = ax2.plot(hists[h]['loss'], color=\"#626262\")\n",
    "\n",
    "for h in range(0,5):\n",
    "  va, = ax.plot(hists[h]['val_accuracy'], color=\"blue\", alpha=0.2)\n",
    "  vl, = ax2.plot(hists[h]['val_loss'], color=\"red\", alpha=0.2)\n",
    "\n",
    "plt.legend(handles = [a, va, l, vl], labels = ['Acc (train)', 'Acc (val)', 'Loss (train)', 'Loss (val)'], loc='upper center', \n",
    "             bbox_to_anchor=(0.5, -0.2),fancybox=False, shadow=False, ncol=4)\n",
    "\n",
    "\n",
    "# save the plot as a file\n",
    "fig.savefig('/content/drive/MyDrive/COLAB/accloss_all.pdf',\n",
    "            format='pdf',\n",
    "            bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_using_all_data",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
