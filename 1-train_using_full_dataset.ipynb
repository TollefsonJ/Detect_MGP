{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvtVyNKKiXL0"
   },
   "source": [
    "# First, set up the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RulgKgstigzv",
    "outputId": "6d9fce91-68d7-46c4-9a87-07bea4e8c48e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdAOVtxXiXL5"
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HbPt5qCSiXL_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "path = \"ML_training/training_data/\"\n",
    "X = np.load(path+'X.npy')\n",
    "y = np.load(path+'y.npy')\n",
    "file = np.load(path+'file.npy')\n",
    "\n",
    "# set numpy seed for model\n",
    "np.random.seed(0) # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6gHXmgA73DN"
   },
   "outputs": [],
   "source": [
    "# convert to grayscale (if you want)\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "X = rgb2gray(X)\n",
    "Xmlp = X\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmQnZWLfiXNu"
   },
   "source": [
    "# Define CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCt0sV5UiXNw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIE7FnXLiXN4"
   },
   "outputs": [],
   "source": [
    "# Convolutional Neural Network https://machinelearningmastery.com/keras-functional-api-deep-learning/\n",
    "\n",
    "# Convolutional Neural Network\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, AveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "input_shape = (X.shape[1], X.shape[2], X.shape[3])\n",
    "\n",
    "nClasses = 2\n",
    "\n",
    "def createModel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#    model.add(Dropout(0.25))\n",
    "\n",
    "#    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#    model.add(Dropout(0.25))\n",
    "\n",
    "#    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#    model.add(Dropout(0.25))\n",
    "\n",
    "#    model.add(Conv2D(64, (1, 1), padding='same', activation='relu'))\n",
    " #   model.add(Conv2D(64, (1, 1), activation='relu'))\n",
    " #   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    " #   model.add(Dense(1032, activation='relu', kernel_regularizer='l2'))\n",
    "  #  model.add(Dropout(0.5))\n",
    "    model.add(Dense(nClasses, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# plot_model(model, to_file='convolutional_neural_network.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MgJeHSdsUMkR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RRBw8y2UN0x"
   },
   "source": [
    "# Define MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUVGJ2TxUPpU"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# define and fit scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "\n",
    "################## define and run model itself, after you've found good params ########\n",
    "mlp = MLPClassifier(hidden_layer_sizes= (100, 50),\n",
    "                    activation = 'relu',\n",
    "                    solver = 'lbfgs',\n",
    "                    alpha = 1e-5,\n",
    "                    learning_rate = 'constant',\n",
    "                    random_state = 0, max_iter=5000)\n",
    "\n",
    "pipe = Pipeline(steps =[('scaler',scaler) , ('MLPClassifier', mlp)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cmOQL2F5qDG"
   },
   "source": [
    "# Train CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YZ8OZyWU5qDI",
    "outputId": "e184ba5e-568d-4519-dc3f-3cf1f4cba836"
   },
   "outputs": [],
   "source": [
    "######### train test split ###############\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "######################\n",
    "# Set training process params, class weights (get class weights from the train/test split, below)\n",
    "batch_size = 64 # 67\n",
    "epochs = 80 # 50\n",
    "\n",
    "number_models= 5\n",
    "\n",
    "\n",
    "###################\n",
    "# construct metrics\n",
    "metrics = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "###################\n",
    "\n",
    "\n",
    "# full list of models and histories\n",
    "models=list()\n",
    "histories=list()\n",
    "histories_all = list()\n",
    "\n",
    "\n",
    "\n",
    "##################### ##################### ##################### \n",
    "# CNN MODEL\n",
    "##################### ##################### ##################### \n",
    "\n",
    "\n",
    "X_cnn, X_val, y_cnn, y_val, file_cnn, file_val = train_test_split(X, y, file, stratify = y, test_size=0.15, random_state=0)\n",
    "\n",
    "\n",
    "# compute class weights an assign to variable for model below\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y),y)\n",
    "weight = {0: class_weights[0], 1: class_weights[1]}\n",
    "print(weight)\n",
    "\n",
    "# scale Xs and convert Ys to categorical\n",
    "X_cnn, X_val = X_cnn/255, X_val/255\n",
    "y_cnn, y_val = to_categorical(y_cnn), to_categorical(y_val)\n",
    "\n",
    "\n",
    "\n",
    "# run ensemble CNN model for each kfold\n",
    "for i in range(0,number_models):\n",
    "  print(i)\n",
    "  model = createModel()\n",
    "  model.compile(optimizer='adamax', loss=keras.losses.BinaryCrossentropy(), metrics=metrics)\n",
    "  history = model.fit(X_cnn, y_cnn,\n",
    "                      batch_size=batch_size, \n",
    "                      epochs=epochs, verbose=1, class_weight = weight,\n",
    "                      validation_data = (X_val, y_val),\n",
    "                      # callbacks=[early_stopping], # this stops the training when the metric listed in model.compile has stopped improving\n",
    "                      shuffle=False)\n",
    "  \n",
    "  # append to revolving models and histories list, in order to later append to full list of models and history\n",
    "  models.append(model)\n",
    "  histories.append(history.history)\n",
    "  # append all histories for each model in each fold, to plot later\n",
    "  histories_all.append(history.history)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f-4zjuDp2rhu",
    "outputId": "48b665c8-61d8-42b3-91e3-319a60f00e5c"
   },
   "outputs": [],
   "source": [
    "# save histories and models\n",
    "import pickle\n",
    "\n",
    "for model in range(0,5):\n",
    "  path = 'ML_models/ensemblemodel' + '-' + str(model)\n",
    "  models[model].save(path)\n",
    "\n",
    "with open(\"ML_models/ensemblemodel_histories.dat\", \"wb\") as f:\n",
    "  pickle.dump(histories, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubnm5rDaUB6X"
   },
   "source": [
    "# MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7jEW_o21T-6a",
    "outputId": "84be6c12-3868-4276-eaec-44a05e5aeb75"
   },
   "outputs": [],
   "source": [
    "\n",
    "####################################\n",
    "###### scale and classify! ######\n",
    "####################################\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# define and fit scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "\n",
    "################## define and run model itself, after you've found good params ########\n",
    "mlp = MLPClassifier(hidden_layer_sizes= (100, 50),\n",
    "                    activation = 'relu',\n",
    "                    solver = 'lbfgs',\n",
    "                    alpha = 1e-5,\n",
    "                    learning_rate = 'constant',\n",
    "                    random_state = 0, max_iter=5000)\n",
    "\n",
    "pipe = Pipeline(steps =[('scaler',scaler) , ('MLPClassifier', mlp)])\n",
    "\n",
    "\n",
    "\n",
    "pipes = list()\n",
    "\n",
    "# reshape X array to 2-dimensions\n",
    "nsamples, nx, ny = Xmlp.shape\n",
    "Xmlp = Xmlp.reshape((nsamples, nx*ny))\n",
    "\n",
    "# resample training data\n",
    "over = SMOTE(sampling_strategy = .1)\n",
    "under = RandomUnderSampler(sampling_strategy=1)\n",
    "Xmlp, y = over.fit_resample(Xmlp, y)\n",
    "Xmlp, y = under.fit_resample(Xmlp, y)\n",
    "\n",
    "# run it\n",
    "\n",
    "for i in range(0,5):\n",
    "    \n",
    "    pipe.fit(Xmlp, y)\n",
    "    \n",
    "    pipes.append(pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0n51vNWWLA0"
   },
   "outputs": [],
   "source": [
    "# save the models\n",
    "import pickle as pkl\n",
    "\n",
    "path  = '/ML_models/MLP/'\n",
    "file = path+'mlp_models.pkl'\n",
    "with open(file, 'wb') as f:\n",
    "    pkl.dump(pipes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqf7m78Gs0EQ"
   },
   "source": [
    "# Plot accuracy and loss for full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "MvmSHrI4ABH5",
    "outputId": "6cd854c0-6f2d-4f1f-b101-7e955b94e22a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "hists = histories_all\n",
    "\n",
    "# fig size\n",
    "mpl.rcParams['figure.figsize'] = (6, 5)\n",
    "\n",
    "# create figure and axis objects with subplots()\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# make a plot\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Accuracy\",color=\"black\")\n",
    "\n",
    "ax2=ax.twinx()\n",
    "ax2.set_ylim(0,2.6)\n",
    "ax2.set_ylabel(\"Loss\",color=\"black\")\n",
    "\n",
    "for h in range(0,5):\n",
    "  a, = ax.plot(hists[h]['accuracy'], color=\"black\")\n",
    "  l, = ax2.plot(hists[h]['loss'], color=\"#626262\")\n",
    "\n",
    "for h in range(0,5):\n",
    "  va, = ax.plot(hists[h]['val_accuracy'], color=\"blue\", alpha=0.2)\n",
    "  vl, = ax2.plot(hists[h]['val_loss'], color=\"red\", alpha=0.2)\n",
    "\n",
    "plt.legend(handles = [a, va, l, vl], labels = ['Acc (train)', 'Acc (val)', 'Loss (train)', 'Loss (val)'], loc='upper center', \n",
    "             bbox_to_anchor=(0.5, -0.2),fancybox=False, shadow=False, ncol=4)\n",
    "\n",
    "\n",
    "# save the plot as a file\n",
    "fig.savefig('/content/drive/MyDrive/COLAB/accloss_all.pdf',\n",
    "            format='pdf',\n",
    "            bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_using_all_data",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
